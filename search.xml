<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Binary Search and LinkedList LEETCODE 100 DAY1]]></title>
    <url>%2F2020%2F06%2F22%2FBinary-Search-and-LinkedList-LEETCODE-100-DAY1%2F</url>
    <content type="text"><![CDATA[74. Search a 2D MatrixWrite an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties: Integers in each row are sorted from left to right. The first integer of each row is greater than the last integer of the previous row. Example 1: 12345678Input:matrix = [ [1, 3, 5, 7], [10, 11, 16, 20], [23, 30, 34, 50]]target = 3Output: true Example 2: 12345678Input:matrix = [ [1, 3, 5, 7], [10, 11, 16, 20], [23, 30, 34, 50]]target = 13Output: false 12345678910111213141516171819202122class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; if (matrix.length == 0 || matrix[0].length == 0) return false; int row = matrix.length; int col = matrix[0].length; int start = 0; int end = row * col - 1; while (start &lt;= end) &#123; int mid = start + (end - start) / 2; int value = matrix[mid / col][mid % col]; if (value == target) &#123; return true; &#125; else if (value &lt; target) &#123; start = mid + 1; &#125; else &#123; end = mid - 1; &#125; &#125; return false; &#125;&#125; 240.Search a 2D Matrix II1234567891011121314151617class Solution &#123; public boolean searchMatrix(int[][] matrix, int target) &#123; if (matrix.length == 0 || matrix[0].length == 0) return false; int row = 0; int col = matrix[0].length - 1; while (col &gt;= 0 &amp;&amp; row &lt;= matrix.length - 1) &#123; if (target == matrix[row][col]) &#123; return true; &#125; else if (target &lt; matrix[row][col]) &#123; col--; &#125; else &#123; row++; &#125; &#125; return false; &#125;&#125; 35. Search Insert PositionGiven a sorted array and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order. You may assume no duplicates in the array. Example 1: 12Input: [1,3,5,6], 5Output: 2 Example 2: 12Input: [1,3,5,6], 2Output: 1 Example 3: 12Input: [1,3,5,6], 7Output: 4 Example 4: 12Input: [1,3,5,6], 0Output: 0 12345678910111213141516171819202122232425262728// 首先，插入位置有可能在数组的末尾（题目中的示例 3），需要单独判断；// 其次，如果待插入元素比最后一个元素严格小，并且在这个数组中有和插入元素一样的元素，返回任意一个位置即可；// 否则，插入的位置应该是严格大于 target 的第 1 个元素的位置。//因此，严格小于 target 的元素一定不是解，根据这个思路，可以写出如下代码。class Solution &#123; public int searchInsert(int[] nums, int target) &#123; int len = nums.length; if (len == 0) &#123; return 0; &#125; if (nums[len - 1] &lt; target) &#123; return len; &#125; int left = 0; int right = len - 1; while (left &lt; right) &#123; int mid = (left + right) &gt;&gt;&gt; 1; // 严格小于 target 的元素一定不是解 if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else &#123; right = mid; &#125; &#125; return left; &#125;&#125; [374. Guess Number Higher or Lower]https://leetcode.com/problems/guess-number-higher-or-lower/We are playing the Guess Game. The game is as follows: I pick a number from 1 to n\. You have to guess which number I picked. Every time you guess wrong, I’ll tell you whether the number is higher or lower. You call a pre-defined API guess(int num) which returns 3 possible results (-1, 1, or 0): 123-1 : My number is lower 1 : My number is higher 0 : Congrats! You got it! Example : 12Input: n = 10, pick = 6Output: 6 12345678910111213141516public class Solution extends GuessGame &#123; public int guessNumber(int n) &#123; int left = 1; int right = n; while (left &lt; right) &#123; int mid = (left + right + 1) &gt;&gt;&gt; 1; int guessNum = guess(mid); if (guessNum == -1) &#123; right = mid - 1;// 中位数比猜的数大，因此比中位数大的数包括中位数都不是目标元素 &#125; else &#123; left = mid; &#125; &#125; return left; &#125;&#125; 278. First Bad VersionYou are a product manager and currently leading a team to develop a new product. Unfortunately, the latest version of your product fails the quality check. Since each version is developed based on the previous version, all the versions after a bad version are also bad. Suppose you have n versions [1, 2, ..., n] and you want to find out the first bad one, which causes all the following ones to be bad. You are given an API bool isBadVersion(version) which will return whether version is bad. Implement a function to find the first bad version. You should minimize the number of calls to the API. Example: 1234567Given n = 5, and version = 4 is the first bad version.call isBadVersion(3) -&gt; falsecall isBadVersion(5) -&gt; truecall isBadVersion(4) -&gt; trueThen 4 is the first bad version. 123456789101112131415161718/* The isBadVersion API is defined in the parent class VersionControl. boolean isBadVersion(int version); */public class Solution extends VersionControl &#123; public int firstBadVersion(int n) &#123; int left = 1; int right = n; while (left &lt; right) &#123; int mid = left + (right - left) / 2; if(isBadVersion(mid)) &#123; right = mid; &#125; else &#123; left = mid + 1; &#125; &#125; return left; &#125;&#125; 34. Find First and Last Position of Element in Sorted ArrayGiven an array of integers nums sorted in ascending order, find the starting and ending position of a given target value. Your algorithm’s runtime complexity must be in the order of O(log n). If the target is not found in the array, return [-1, -1]. Example 1: 12Input: nums = [5,7,7,8,8,10], target = 8Output: [3,4] Example 2: 12Input: nums = [5,7,7,8,8,10], target = 6Output: [-1,-1] 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; public int[] searchRange(int[] nums, int target) &#123; if (nums == null || nums.length ==0) return new int[]&#123;-1, -1&#125;; int start = findFirst(nums, target); if(start == -1) return new int[]&#123;-1, -1&#125;; int end = findLast(nums, target); return new int[]&#123;start, end&#125;; &#125; public int findFirst(int[] nums, int target) &#123; int start = 0; int end = nums.length - 1; while (start + 1 &lt; end) &#123; int mid = start + (end - start) / 2; if(nums[mid] &lt; target) &#123; start = mid; &#125; else &#123; end = mid; &#125; &#125; if(nums[start] == target) return start; if(nums[end] == target) return end; return -1; &#125; public int findLast(int[] nums, int target) &#123; int start = 0; int end = nums.length - 1; while (start + 1 &lt; end) &#123; int mid = start + (end - start) / 2; if(nums[mid] &gt; target) &#123; end = mid; &#125; else &#123; start = mid; &#125; &#125; if(nums[end] == target) return end; if(nums[start] == target) return start; return -1; &#125;&#125; 162.Find Peak ElementA peak element is an element that is greater than its neighbors. Given an input array nums, where nums[i] ≠ nums[i+1], find a peak element and return its index. The array may contain multiple peaks, in that case return the index to any one of the peaks is fine. You may imagine that nums[-1] = nums[n] = -∞. Example 1: 123Input: nums = [1,2,3,1]Output: 2Explanation: 3 is a peak element and your function should return the index number 2. Example 2: 1234Input: nums = [1,2,1,3,5,6,4]Output: 1 or 5 Explanation: Your function can return either index number 1 where the peak element is 2, or index number 5 where the peak element is 6. 12345678910111213141516class Solution &#123; public int findPeakElement(int[] nums) &#123; int start = 0; int end = nums.length - 1; while (start &lt;= end) &#123; if (start == end) return start; int mid = start + (end - start) / 2; if(nums[mid] &gt;= nums[mid + 1]) &#123; end = mid; &#125; else &#123; start = mid + 1; &#125; &#125; return start; &#125;&#125; 141. Linked List CycleGiven a linked list, determine if it has a cycle in it. To represent a cycle in the given linked list, we use an integer pos which represents the position (0-indexed) in the linked list where tail connects to. If pos is -1, then there is no cycle in the linked list. Example 1: 123Input: head = [3,2,0,-4], pos = 1Output: trueExplanation: There is a cycle in the linked list, where tail connects to the second node. Example 2: 123Input: head = [1,2], pos = 0Output: trueExplanation: There is a cycle in the linked list, where tail connects to the first node. Example 3: 123Input: head = [1], pos = -1Output: falseExplanation: There is no cycle in the linked list. Follow up: Can you solve it using O(1) (i.e. constant) memory? 123456789101112131415public class Solution &#123; public boolean hasCycle(ListNode head) &#123; if(head == null || head.next == null) return false; ListNode fast = head; ListNode slow = head; while (fast != null &amp;&amp; fast.next != null) &#123; slow = slow.next; fast = fast.next.next; if (slow == fast) &#123; return true; &#125; &#125; return false; &#125;&#125; 142. Linked List Cycle IIGiven a linked list, return the node where the cycle begins. If there is no cycle, return null. To represent a cycle in the given linked list, we use an integer pos which represents the position (0-indexed) in the linked list where tail connects to. If pos is -1, then there is no cycle in the linked list. Note: Do not modify the linked list. Example 1: 123Input: head = [3,2,0,-4], pos = 1Output: tail connects to node index 1Explanation: There is a cycle in the linked list, where tail connects to the second node. Example 2: 123Input: head = [1,2], pos = 0Output: tail connects to node index 0Explanation: There is a cycle in the linked list, where tail connects to the first node. Example 3: 123Input: head = [1], pos = -1Output: no cycleExplanation: There is no cycle in the linked list. Follow-up:Can you solve it without using extra space? 1234567891011121314151617181920public class Solution &#123; public ListNode detectCycle(ListNode head) &#123; if (head == null || head.next == null) return null; ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null) &#123; slow = slow.next; fast = fast.next.next; if (fast == slow) &#123; ListNode slow2 = head; while(slow != slow2) &#123; slow = slow.next; slow2 = slow2.next; &#125; return slow; &#125; &#125; return null; &#125;&#125; 83. Remove Duplicates from Sorted ListGiven a sorted linked list, delete all duplicates such that each element appear only once. Example 1: 12Input: 1-&gt;1-&gt;2Output: 1-&gt;2 Example 2: 12Input: 1-&gt;1-&gt;2-&gt;3-&gt;3Output: 1-&gt;2-&gt;3 1234567891011121314class Solution &#123; public ListNode deleteDuplicates(ListNode head) &#123; if (head == null || head.next == null) return head; ListNode cur = head; while (cur.next != null) &#123; if(cur.next.val == cur.val) &#123; cur.next = cur.next.next; &#125; else &#123; cur = cur.next;// movre forward when do not have replcaited item; &#125; &#125; return head; &#125;&#125; 82. Remove Duplicates from Sorted List IIGiven a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list. Return the linked list sorted as well. Example 1: 12Input: 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5Output: 1-&gt;2-&gt;5 Example 2: 12Input: 1-&gt;1-&gt;1-&gt;2-&gt;3Output: 2-&gt;3 123456789101112131415161718192021class Solution &#123; public ListNode deleteDuplicates(ListNode head) &#123; if(head == null || head.next == null) return head; ListNode dummy = new ListNode(0); //删除当前节点的方法是在将要删除的节点前面再加一个dummy节点，这样才能指向dummy.next.next,也就是删除dummy.next。 dummy.next = head;//这样才能删除头指针节点 ListNode p = dummy; while (p.next != null &amp;&amp; p.next.next != null) &#123; if(p.next.val == p.next.next.val) &#123; //用来删除全部的重复节点，保存一下重复值 int sameNum = p.next.val; while (p.next != null &amp;&amp; p.next.val == sameNum) &#123; p.next = p.next.next; &#125; &#125; else &#123; p = p.next; &#125; &#125; return dummy.next; &#125;&#125;]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BFS AND DFS]]></title>
    <url>%2F2020%2F06%2F05%2FBFS-AND-DFS%2F</url>
    <content type="text"><![CDATA[BFS图的BFS1162. 地图分析对于图的BFS也是一样滴～ 与Tree的BFS区别如下：1、tree只有1个root，而图可以有多个源点，所以首先需要把多个源点都入队。2、tree是有向的因此不需要标志是否访问过，而对于无向图来说，必须得标志是否访问过！并且为了防止某个节点多次入队，需要在入队之前就将其设置成已访问！ 作者：sweetiee链接：https://leetcode-cn.com/problems/as-far-from-land-as-possible/solution/jian-dan-java-miao-dong-tu-de-bfs-by-sweetiee/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; public int maxDistance(int[][] grid) &#123; int[] dx = &#123;0, 0, 1, -1&#125;; int[] dy = &#123;1, -1, 0, 0&#125;; Queue&lt;int[]&gt; queue = new ArrayDeque&lt;&gt;(); int m = grid.length, n = grid[0].length; // 先把所有的陆地都入队。 for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (grid[i][j] == 1) &#123; queue.offer(new int[] &#123;i, j&#125;); &#125; &#125; &#125; // 从各个陆地开始，一圈一圈的遍历海洋，最后遍历到的海洋就是离陆地最远的海洋。 boolean hasOcean = false; int[] point = null; while (!queue.isEmpty()) &#123; point = queue.poll(); int x = point[0], y = point[1]; // 取出队列的元素，将其四周的海洋入队。 for (int i = 0; i &lt; 4; i++) &#123; int newX = x + dx[i]; int newY = y + dy[i]; if (newX &lt; 0 || newX &gt;= m || newY &lt; 0 || newY &gt;= n || grid[newX][newY] != 0) &#123; continue; &#125; grid[newX][newY] = grid[x][y] + 1; // 这里我直接修改了原数组，因此就不需要额外的数组来标志是否访问 hasOcean = true; queue.offer(new int[] &#123;newX, newY&#125;); &#125; &#125; // 没有陆地或者没有海洋，返回-1。 if (point == null || !hasOcean) &#123; return -1; &#125; // 返回最后一次遍历到的海洋的距离。 return grid[point[0]][point[1]] - 1; &#125;&#125; BFS遍历矩阵12345678910111213141516171819202122232425class Solution &#123; public int[] spiralOrder(int[][] matrix) &#123; if (matrix == null || matrix.length == 0 || matrix[0].length == 0) &#123; return new int[0]; &#125; int rows = matrix.length, columns = matrix[0].length; boolean[][] visited = new boolean[rows][columns]; int total = rows * columns; int[] order = new int[total]; int row = 0, column = 0; int[][] directions = &#123;&#123;0, 1&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;-1, 0&#125;&#125;; int directionIndex = 0; for (int i = 0; i &lt; total; i++) &#123; order[i] = matrix[row][column]; visited[row][column] = true; int nextRow = row + directions[directionIndex][0], nextColumn = column + directions[directionIndex][1]; if (nextRow &lt; 0 || nextRow &gt;= rows || nextColumn &lt; 0 || nextColumn &gt;= columns || visited[nextRow][nextColumn]) &#123; directionIndex = (directionIndex + 1) % 4; &#125; row += directions[directionIndex][0]; column += directions[directionIndex][1]; &#125; return order; &#125;&#125; 参考目录 甜姨 小号算法目录 大象🐘]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Binary Search.]]></title>
    <url>%2F2020%2F06%2F04%2FBinary-Search%2F</url>
    <content type="text"><![CDATA[1234567891011121314public int binarySearch(int[] array, int des) &#123; int low = 0, high = array.length - 1; while (low &lt;= high) &#123; int mid = low + (high - low) / 2;//int mid = (left + right) &gt;&gt; 1; if (des == array[mid]) &#123; return mid; &#125; else if (des &lt; array[mid]) &#123; high = mid - 1; &#125; else &#123; low = mid + 1; &#125; &#125; return -1;&#125; 1234567891011121314151617181920212223242526public class Solution &#123; public int mySqrt(int x) &#123; if (x == 0) &#123; return 0; &#125; // 注意：针对特殊测试用例，例如 2147395599 // 要把搜索的范围设置成长整型 long left = 1; long right = x / 2; while (left &lt; right) &#123; // 注意：这里一定取右中位数，如果取左中位数，代码会进入死循环 // long mid = left + (right - left + 1) / 2; long mid = (left + right + 1) &gt;&gt;&gt; 1; long square = mid * mid; if (square &gt; x) &#123; right = mid - 1; &#125; else &#123; left = mid; &#125; &#125; // 因为一定存在，因此无需后处理 return (int) left; &#125;&#125; 二分查找 Binary Search Solution in Leetcode 二分查找细节详解_labuladong]]></content>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Everything About TreeMap]]></title>
    <url>%2F2020%2F03%2F21%2FEverything-About-TreeMap%2F</url>
    <content type="text"><![CDATA[概述文章的内容基于JDK1.7进行分析，之所以选用这个版本，是因为1.8的有些类做了改动，增加了阅读的难度，虽然是1.7，但是对于1.8做了重大改动的内容，文章也会进行说明。 TreeMap实现了SotredMap接口，它是有序的集合。而且是一个红黑树结构，每个key-value都作为一个红黑树的节点。如果在调用TreeMap的构造函数时没有指定比较器，则根据key执行自然排序。这点会在接下来的代码中做说明，如果指定了比较器则按照比较器来进行排序。 数据结构继承关系123public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable &#123;&#125; 实现接口1Serializable, Cloneable, Map&lt;K,V&gt;, NavigableMap&lt;K,V&gt;, SortedMap&lt;K,V&gt; 基本属性1234private final Comparator&lt;? super K&gt; comparator; //比较器，是自然排序，还是定制排序 ，使用final修饰，表明一旦赋值便不允许改变private transient Entry&lt;K,V&gt; root = null; //红黑树的根节点private transient int size = 0; //TreeMap中存放的键值对的数量private transient int modCount = 0; //修改的次数 源码解析由于TreeMap中源码较长，接下来将分段解析部分源码。既然是红黑树存储，肯定要有数据结构（Node）节点的。看一下TreeMap中关于节点的定义部分。 数据结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; K key; //键 V value; //值 Entry&lt;K,V&gt; left = null; //左孩子节点 Entry&lt;K,V&gt; right = null; //右孩子节点 Entry&lt;K,V&gt; parent; //父节点 boolean color = BLACK; //节点的颜色，在红黑树种，只有两种颜色，红色和黑色 //构造方法，用指定的key,value ,parent初始化，color默认为黑色 Entry(K key, V value, Entry&lt;K,V&gt; parent) &#123; this.key = key; this.value = value; this.parent = parent; &#125; //返回key public K getKey() &#123; return key; &#125; //返回该节点对应的value public V getValue() &#123; return value; &#125; //替换节点的值，并返回旧值 public V setValue(V value) &#123; V oldValue = this.value; this.value = value; return oldValue; &#125; //重写equals()方法 public boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; //两个节点的key相等，value相等，这两个节点才相等 return valEquals(key,e.getKey()) &amp;&amp; valEquals(value,e.getValue()); &#125; //重写hashCode()方法 public int hashCode() &#123; int keyHash = (key==null ? 0 : key.hashCode()); int valueHash = (value==null ? 0 : value.hashCode()); //key和vale hash值得异或运算，相同则为零，不同则为1 return keyHash ^ valueHash; &#125; //重写toString()方法 public String toString() &#123; return key + "=" + value; &#125;&#125; 构造方法1234567891011121314151617181920212223242526//构造方法，comparator用键的顺序做比较public TreeMap() &#123; comparator = null;&#125;//构造方法，提供比较器，用指定比较器排序public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; his.comparator = comparator;&#125;//将m中的元素转化daoTreeMap中，按照键的顺序做比较排序public TreeMap(Map&lt;? extends K, ? extends V&gt; m) &#123; comparator = null; putAll(m);&#125;//构造方法，指定的参数为SortedMap//采用m的比较器排序public TreeMap(SortedMap&lt;K, ? extends V&gt; m) &#123; comparator = m.comparator(); try &#123; buildFromSorted(m.size(), m.entrySet().iterator(), null, null); &#125; catch (java.io.IOException cannotHappen) &#123; &#125; catch (ClassNotFoundException cannotHappen) &#123; &#125;&#125; TreeMap提供了四个构造方法，实现了方法的重载。无参构造方法中比较器的值为null,采用自然排序的方法，如果指定了比较器则称之为定制排序. 自然排序：TreeMap的所有key必须实现Comparable接口，所有的key都是同一个类的对象 定制排序：创建TreeMap对象传入了一个Comparator对象，该对象负责对TreeMap中所有的key进行排序，采用定制排序不要求Map的key实现Comparable接口。等下面分析到比较方法的时候在分析这两种比较有何不同。 对于Map来说，使用的最多的就是put()/get()/remove()等方法，下面依次进行分析 put()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; //红黑树的根节点 if (t == null) &#123; //红黑树是否为空 compare(key, key); // type (and possibly null) check //构造根节点，因为根节点没有父节点，传入null值。 root = new Entry&lt;&gt;(key, value, null); size = 1; //size值加1 modCount++; //改变修改的次数 return null; //返回null &#125; int cmp; Entry&lt;K,V&gt; parent; //定义节点 // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; //获取比较器 if (cpr != null) &#123; //如果定义了比较器，采用自定义比较器进行比较 do &#123; parent = t; //将红黑树根节点赋值给parent cmp = cpr.compare(key, t.key); //比较key, 与根节点的大小 if (cmp &lt; 0) //如果key &lt; t.key , 指向左子树 t = t.left; //t = t.left , t == 它的做孩子节点 else if (cmp &gt; 0) t = t.right; //如果key &gt; t.key , 指向它的右孩子节点 else return t.setValue(value); //如果它们相等，替换key的值 &#125; while (t != null); //循环遍历 &#125; else &#123; //自然排序方式，没有指定比较器 if (key == null) throw new NullPointerException(); //抛出异常 Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; //类型转换 do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) // key &lt; t.key t = t.left; //左孩子 else if (cmp &gt; 0) // key &gt; t.key t = t.right; //右孩子 else return t.setValue(value); //t == t.key , 替换value值 &#125; while (t != null); &#125; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); //创建新节点，并制定父节点 //根据比较结果，决定新节点为父节点的左孩子或者右孩子 if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); //新插入节点后重新调整红黑树 size++; modCount++; return null;&#125;//比较方法，如果comparator==null ,采用comparable.compartTo进行比较，否则采用指定比较器比较大小final int compare(Object k1, Object k2) &#123; return comparator==null ? ((Comparable&lt;? super K&gt;)k1).compareTo((K)k2) : comparator.compare((K)k1, (K)k2);&#125;private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; //插入的节点默认的颜色为红色 x.color = RED; // //情形1： 新节点x 是树的根节点，没有父节点不需要任何操作 //情形2： 新节点x 的父节点颜色是黑色的，也不需要任何操作 while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; //情形3：新节点x的父节点颜色是红色的 //判断x的节点的父节点位置，是否属于左孩子 if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; //获取x节点的父节点的兄弟节点，上面语句已经判断出x节点的父节点为左孩子，所以直接取右孩子 Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); //判断是否x节点的父节点的兄弟节点为红色。 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); // x节点的父节点设置为黑色 setColor(y, BLACK); // y节点的颜色设置为黑色 setColor(parentOf(parentOf(x)), RED); // x.parent.parent设置为红色 x = parentOf(parentOf(x)); // x == x.parent.parent ,进行遍历。 &#125; else &#123; //x的父节点的兄弟节点是黑色或者缺少的 if (x == rightOf(parentOf(x))) &#123; //判断x节点是否为父节点的右孩子 x = parentOf(x); //x == 父节点 rotateLeft(x); //左旋转操作 &#125; //x节点是其父的左孩子 setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); //上面两句将x.parent 和x.parent.parent的颜色做调换 rotateRight(parentOf(parentOf(x))); //进行右旋转 &#125; &#125; else &#123; Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); //y 是x 节点的祖父节点的左孩子 if (colorOf(y) == RED) &#123; //判断颜色 setColor(parentOf(x), BLACK); //父节点设置为黑色 setColor(y, BLACK); //父节点的兄弟节点设置为黑色 setColor(parentOf(parentOf(x)), RED); //祖父节点设置为红色 x = parentOf(parentOf(x)); //将祖父节点作为新插入的节点，遍历调整 &#125; else &#123; if (x == leftOf(parentOf(x))) &#123; //x 是其父亲的左孩子 x = parentOf(x); rotateRight(x); //以父节点为旋转点，进行右旋操作 &#125; setColor(parentOf(x), BLACK); //父节点为设置为黑色 setColor(parentOf(parentOf(x)), RED); //祖父节点设置为红色 rotateLeft(parentOf(parentOf(x))); //以父节点为旋转点，进行左旋操作 &#125; &#125; &#125; root.color = BLACK; //通过节点位置的调整，最终将红色的节点条调换到了根节点的位置，根节点重新设置为黑色&#125; 红黑树是一个更高效的检索二叉树，有如下特点： 每个节点只能是红色或者黑色 根节点永远是黑色的 所有的叶子的子节点都是空节点，并且都是黑色的 每个红色节点的两个子节点都是黑色的（不会有两个连续的红色节点） 从任一个节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点（叶子节点到根节点的黑色节点数量每条路径都相同） 上面的代码，详细的标注了每条语句的作用，但是我相信，如果你没有一定的功力，即使注释已经很详细了，你也会是一脸懵逼 ，二脸懵逼，全脑懵逼中，下面配合图片来梳理一下代码所表示的含义：当一个默认为红色的节点插入树中，其实对应的是7中可能发生的情况，分别进行叙述： 情形1：新插入的节点时红黑树的根节点，没有父节点，无需任何的操作，直接将颜色设置为黑色就可以了 情形2：新节点的父节点颜色是黑色的，新插入的节点是红色的。也无需任何的操作。因为新节点的插入并没有影响到红黑书的特点 情形3：新节点的父节点（左孩子节点）颜色是红色的，而父节点的兄弟节点颜色也是红色的。那么情况就出现了，此时插入的节点就违反了红黑树的特点4 ，需要对红黑树进行调整。 操作看下图：调整操作如上图，将父节点和父节点的兄弟节点，都修改为红色，然后将祖父节点修改为红色，因为修改了祖父节点的颜色，祖父节点可能会发生颜色的冲突，所以将新插入的节点修改为祖父节点，在进行调整。 情形4：父节点（左孩子节点）的颜色为红色，父节点的兄弟节点的颜色为黑色或者为null，新插入的节点为父节点的右孩子节点。如下图：此时以父节点为旋转点，就新插入的节点进行左旋操作。便变成了情形5对应的情况，将执行情形5的操作 情形5：父节点（左孩子节点）的颜色为红色，父节点的兄弟节点颜色为黑色或者null,新插入节点为父亲的左孩子节点。如下图： 情形6 和情形7的操作与情形4和情形5的操作相同，它们之前的区别是父节点为有孩子节点，再次不再赘述。 remove()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149public V remove(Object key) &#123; Entry&lt;K,V&gt; p = getEntry(key); //根据key查找节点，并返回该节点 if (p == null) return null; V oldValue = p.value; //获取key对应的值 deleteEntry(p); //删除节点 return oldValue; //返回key对应的值&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; //根据键寻找节点，有非为两种方式，如果定制了比较器，采用定制排序方式，否则使用自然排序 if (comparator != null) return getEntryUsingComparator(key); //循环遍历树，寻找和key相等的节点 if (key == null) throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; while (p != null) &#123; //循环遍历树，寻找和key相等的节点 int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125;//删除节点private void deleteEntry(Entry&lt;K,V&gt; p) &#123; modCount++; //记录修改的次数 size--; //数量减1 //当前节点的两个孩子都不为空 if (p.left != null &amp;&amp; p.right != null) &#123; //寻找继承者，继承者为当前节点的右孩子节点或者右孩子节点的最小左孩子 Entry&lt;K,V&gt; s = successor(p); p.key = s.key; //key - value 的替换 ，并没有替换颜色 p.value = s.value; p = s; //指向继承者 &#125; // p has 2 children // Start fixup at replacement node, if it exists. //开始修复树结构，继承者的左孩子不为空，返回左孩子，否则返回右孩子 //不可能存在左右两个孩子都存在的情况，successor寻找的就是最小节点，它的左孩子节点为null Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); if (replacement != null) &#123; // Link replacement to parent //已经被选为继承者，当前拥有的一切放弃，所以将孩子交给爷爷抚养 replacement.parent = p.parent; //p节点没有父节点，则指向根节点 if (p.parent == null) root = replacement; //如果p为左孩子，如果p为左孩子，则将p.parent.left = p.left else if (p == p.parent.left) p.parent.left = replacement; else p.parent.right = replacement; //删除p节点到左右分支，和父节点的引用 p.left = p.right = p.parent = null; // Fix replacement if (p.color == BLACK) //恢复颜色分配 fixAfterDeletion(replacement); &#125; else if (p.parent == null) &#123; // return if we are the only node. //红黑书中父节点为空的只能是根节点。 root = null; &#125; else &#123; // No children. Use self as phantom replacement and unlink. if (p.color == BLACK) fixAfterDeletion(p); if (p.parent != null) &#123; if (p == p.parent.left) p.parent.left = null; else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125;&#125;private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; //不是根节点，颜色为黑色，调整结构 while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; //判断x是否为左孩子 if (x == leftOf(parentOf(x))) &#123; //x的兄弟节点 Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); //若兄弟节点是红色 if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); //设置兄弟节点变为黑色 setColor(parentOf(x), RED); //父节点设置为红色 rotateLeft(parentOf(x)); //左旋父节点 sib = rightOf(parentOf(x)); //重新设置x的兄弟节点 &#125; if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; setColor(sib, RED); //兄弟节点的两个孩子都是黑色的重新设置兄弟节点的颜色，修改为红色 x = parentOf(x); //将x定位到父节点 &#125; else &#123; if (colorOf(rightOf(sib)) == BLACK) &#123; //兄弟节点的右孩子是黑色的，左孩子是红色的 setColor(leftOf(sib), BLACK); //设置左孩子节点为黑色 setColor(sib, RED); //兄弟节点为红色 rotateRight(sib); //右旋 sib = rightOf(parentOf(x)); //右旋后重新设置兄弟节点 &#125; setColor(sib, colorOf(parentOf(x))); //兄弟节点颜色设置和父节点的颜色相同 setColor(parentOf(x), BLACK); //父节点设置为黑色 setColor(rightOf(sib), BLACK); //将兄弟节点的有孩子设置为黑色 rotateLeft(parentOf(x)); //左旋 x = root; //设置x为根节点 &#125; &#125; else &#123; // symmetric //x为父节点的右节点，参考上面的操作 Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); setColor(parentOf(x), RED); rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); &#125; if (colorOf(rightOf(sib)) == BLACK &amp;&amp;colorOf(leftOf(sib)) == BLACK) &#123; setColor(sib, RED); x = parentOf(x); &#125; else &#123; if (colorOf(leftOf(sib)) == BLACK) &#123; setColor(rightOf(sib), BLACK); setColor(sib, RED); rotateLeft(sib); sib = leftOf(parentOf(x)); &#125; setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(leftOf(sib), BLACK); rotateRight(parentOf(x)); x = root; &#125; &#125; &#125; setColor(x, BLACK);&#125; 删除红黑树的操作比插入操作要稍微麻烦一点，分为两步： 以排序二叉树的方法删除指定节点。删除的节点存在三种情况： 被删除节点，没有左右孩子节点，直接删除即可 被删除节点，有一个孩子节点，那么让它的孩子节点指向它的父节点即可 本删除的节点，有两个非空的孩子节点，那么需要找到该节点的前驱或者后继节点，更换元素值，在将前驱或者后继节点删除（任意一个节点的前驱或者后继都必定至多有一个非空的子节点，可以按照前面的两种情形进行操作） 进行颜色的调换和树的旋转，满足红黑树的特征 下面来分情形讨论一下可能发生的情况： 情形1：被删除的节点为根节点或者颜色为空色，此时删除该节点不影响红黑树的特点。无需操作 情形2：被删除节点为黑色，兄弟节点为红色，如下图：若删除上图中的x节点，将缺少一个黑节点，与红黑树的性质冲突，所以修改sib颜色为黑色，设置p节点为红色，并进行左旋操作。在进行后续的处理。 情形3：被删除节点为黑色，x节点的兄弟节点的子节点都是黑色，如下图：x节点是黑色的，兄弟节点（黑色的）的子节点也是黑色的，p节点的颜色无法确定，有可能是红色的，也有可能是黑色的。如果是红色的直接设置为黑色即可，如果为黑色的，则需要将x定位的p节点，在进行处理。 情形4：被删除节点为黑色，x的兄弟节点的右自子节点为黑色。如下图：情形4的调整为了转变成情形5的情况，来进行处理。 情形5：被删除节点为黑色，x的兄弟节点右子节点为红色。如下图：sib的左子节点的颜色不确定，可能是红色也可能是黑色，但是对它并没有什么影响，因为变换前后它的上层分支的黑色节点数并没有改变。 上面的情形只是针对删除的节点是左孩子的情况，进行的分析，被删除的节点也可能是右分支。情况完全相同只不过左右顺序发生了颠倒，不再进行复述。 至此TreeMap中实现的最重要已经说完了。 下面简单说一下一些方法的作用 firstEntry() 返回Map中最小的key higherEntry(Object key ) 返回该Map中位于key后一位的key-value lowerEntry(Object key ) 返回该Map中唯一key前一位的key-value tailMap(Object key , boolean inclusive) 返回该Map的子Map 总结 关于红黑树的节点插入操作，首先是改变新节点，新节点的父节点，祖父节点，和新节点的颜色，能在当前分支通过节点的旋转改变的，则通过此种操作，来满足红黑书的特点。 如果当前相关节点的旋转解决不了红黑树的冲突，则通过将红色的节点移动到根节点解决，最后在将根节点设置为黑色]]></content>
      <tags>
        <tag>Analyst of SourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Everything About ConcurrentHashMap]]></title>
    <url>%2F2020%2F03%2F21%2FEverything-About-ConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[概述ConcurrentHashMap常用于并发编程，这里就从源码上来分析一下ConcurrentHashMap数据结构和底层原理。 在开始之前先介绍一个算法， 这个算法和Concurrent的实现是分不开的。CAS算法： CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。 CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B 从思想上来说，Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。 ConcurrentHashMap是一个线程安全的Map集合，可以应对高并发的场景，保证线程安全。相比较HashTable，它的锁粒度更加的细化，因为HashTable的方法都是用Synchronized修饰的，效率灰常的底下。 1.8之前ConcurrentHashMap使用锁分段技术，将数据分成一段段的存储，每一个数据段配置一把锁，相互之间不影响，而1.8之后摒弃了Segment（锁段）的概念，启用了全新的实现，也就是利用CAS+Synchronized来保证并发更新的安全，底层采用的依然是数组+链表+红黑树。 本篇文章是基于JDK1.8 。 数据结构继承关系123public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable ConcurrentHashMap 继承了AbstractMap ,并且实现了ConcurrentMap接口。 与HashMap比对： 相同点：都集成了AbstractMap接口 不同点：HashMap实现了Map接口，ConcurrentHashMap实现了ConcurrentMap接口，而ConcurrentMap继承了Map接口，使用default关键字定义了一些方法 。 从继承关系上看ConcurrentHashMap与HashMap并没有太大的区别。 基本属性12345678910111213141516private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //最大容量2的30次方private static final int DEFAULT_CAPACITY = 16; //默认容量 1&lt;&lt;4private static final float LOAD_FACTOR = 0.75f; //负载因子static final int TREEIFY_THRESHOLD = 8; //链表转为红黑树static final int UNTREEIFY_THRESHOLD = 6; //树转列表static final int MIN_TREEIFY_CAPACITY = 64; //private static final int MIN_TRANSFER_STRIDE = 16;private static int RESIZE_STAMP_BITS = 16;private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;static final int MOVED = -1; // forwarding nodes 的hash值static final int TREEBIN = -2; // roots of trees 的hash值static final int RESERVED = -3; // transient reservations 的hash值static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hashstatic final int NCPU = Runtime.getRuntime().availableProcessors(); //可用处理器数量 重点说一下 sizeCtrl 属性，这个属性在 ConcurrentHashMap 中扮演者重要的角色。 12345678//表初始化或者扩容的一个控制标识位//负数代表正在进行初始化或者扩容的操作// -1 代表初始化// -N 代表有n-1个线程在进行扩容操作//正数或者0表示没有进行初始化操作，这个数值表示初始化或者下一次要扩容的大小。//transient 修饰的属性不会被序列化，volatile保证可见性private transient volatile int sizeCtl; 构造方法123456789101112//无参构造方法，没有进行任何操作public ConcurrentHashMap() &#123;&#125;//指定初始化大小构造方法，判断参数的合法性，并创建了计算初始化的大小public ConcurrentHashMap(int initialCapacity) &#123;&#125;//将指定的集合转化为ConcurrentHashMappublic ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123;&#125;//指定初始化大小和负载因子的构造方法public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1); &#125;//指定初始化大小，负载因子和concurrentLevel并发更新线程的数量，也可以理解为segment的个数public ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) &#123;&#125; ConcurrentHashMap的构造方法并没做太多的工作，主要是进行了参数的合法性校验，和初始值大小的转换。这个方法 tableSizeFor()说明一下， 主要的功能就是将指定的初始化参数转换为2的幂次方形式， 如果初始化参数为9 ，转换后初始大小为16 。 内部数据结构Node首当其冲，因为它是ConcurrentHashMap的核心，它包装了key-value的键值对，所有插入的数据都包装在这里面，与HashMap很相似，但是有一些差别： 12345678910111213static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125;&#125; value 和 next使用了volatile修饰，保证了线程之间的可见性。也不允许调用setValue()方法直接改变Node的值。并增加了find()方法辅助map.get()方法。 TreeNode树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。而且TreeNode在ConcurrentHashMap集成自Node类，而并非HashMap中的集成自LinkedHashMap.Entry类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。 TreeBin这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。 ForwardingNode一个用于连接两个table的节点类。它包含一个nextTable指针，用于指向下一张表。而且这个节点的key value next指针全部为null，它的hash值为-1. 这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找 ConcurrentHashMap常用方法initTable 初始化方法初始化方法是很重要的一个方法，因为在ConcurrentHashMap的构造方法中只是简单的进行了一些参数校验和参数转换的操作。整个Map的初始化是在插入元素的时候触发的。这一点在下面的put方法中会进行说明。 12345678910111213141516171819202122232425262728293031323334//执行初始化操作，单线程操作private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) //sizeCtl &lt; 0 表示有线程正在进行初始化操作，从运行状态变为就绪状态。 Thread.yield(); // lost initialization race; just spin //设置SIZECTL的值为-1，阻塞其他线程的操作 //该方法有四个参数 //第一个参数：需要改变的对象 //第二个参数：偏移量 //第三个参数：期待的值 //第四个参数：更新后的值 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; //再次检查是否有线程进行了初始化操作 if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") //初始化Node对象数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //sc的值设置为n的0.75倍 sc = n - (n &gt;&gt;&gt; 2); //相当于n*0.75 &#125; &#125; finally &#123; sizeCtl = sc; //更改sizeCtl的值 &#125; break; //中断循坏返回 &#125; &#125; return tab; //返回初始化的值&#125; 扩容方法当ConcurrentHashMap 容量不足的时候，需要对table进行扩容，这个方法是支持多个线程并发扩容的，我们所说的扩容，从本质上来说，无非是从一个数组到另外一个数组的拷贝。 扩容方法分为两个部分： 创建扩容后的新数组，容量变为原来的两倍 ，新数组的创建时单线程完成 将原来的数组元素复制到新的数组中，这个是多线程操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182//帮助扩容final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp;(nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp;(sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; //tab = table ,nextTab 一个Node&lt;Key,Value&gt;[]类型的变量 private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; //n 是tab的长度 ， stride 初始值为0 int n = tab.length, stride; //判断cpu处理多线程的能力，如果小于16就直接赋值为16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings("unchecked") //构造一个容量是原来两倍的Node&lt;K ,V&gt; 类型数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; //赋值 &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; //赋值 transferIndex = n; //将数组长度赋值给transferIndex &#125; int nextn = nextTab.length; //获取新数组的长度 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); //创建fwd节点 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab //使用for循环来处理每个槽位中的链表元素，CAS设置transferIndex属性值，并初始化i和bound值 // i 指当前的槽位序号，bound值需要处理的边界，先处理槽位为15的节点 for (int i = 0, bound = 0;;) &#123; //创建两个变量，一个为Node&lt;K,V&gt; 类型，一个为int类型 Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; //将transferIndex的值赋值给 nextIndex ,并判断nextIndex的值是否小于等于0 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; //更新nextIndex的值 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; // if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; //如果table已经复制结束 if (finishing) &#123; nextTable = null; //清空nextTable table = nextTab; //把nextTab 赋值给 table sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); //阈值设置为容量的1.5倍 return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; //CAS算法获取某个数组节点，为空就设置为fwd else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //如果某个节点的hash为-1，跳过 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; //对头节点加锁，禁止其他线程进入 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //构造两个链表 ，将该节点的列表拆分为两个部分，一个是原链表的排列顺序，一个是反序 Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; // fh 当前节点的hash值 若 &gt;= 0 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; //将当前节点赋值给 lastRun 节点 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; //差分列表操作 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //在nextTab 的i 位置上放置ln节点 setTabAt(nextTab, i, ln); //在nextTab 的 i+n 位置上放置 hn节点 setTabAt(nextTab, i + n, hn); //在tab节点i位置上插入插入forwardNode节点，表示该节点已经处理 setTabAt(tab, i, fwd); advance = true; &#125; //对TreeBin对象进行处理，过程与上面有些类似 //也把节点分类，分别插入到lo和hi为头节点的链表中 // else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; //如果扩容后 不在需要tree结构，反向转换成链表结构 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; put方法put操作是最长用的方法，接下来看一下put()方法的具体实现： put()要求键值都不能为空 需要经过两次散列， 是数据均匀分散，减少碰撞的次数 判断tab是否进行了初始化，没有则调用initTable进行初始化操作（单线程） 数组i的位置没有元素存在，直接放入 如果i的位置在进行MOVE操作，也就是在进行扩容操作，则多线程帮助扩容 如果i的位置有元素存在，则在该节点加锁Synchronized，判断是链表还是红黑树，按照相应的插入规则插入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //key|value == null 抛出异常 //ConcurrentHashMap不允许键或者值为null的这种情况发生 //这一点和HashMap有区别 if (key == null || value == null) throw new NullPointerException(); //散列在散列， 让数据均匀分布，减少碰撞次数 int hash = spread(key.hashCode()); --&gt;static final int spread(int h) &#123;return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125; int binCount = 0; //死循环 相当于while(true) ,将table赋值给 tab for (Node&lt;K,V&gt;[] tab = table;;) &#123; //创建一个Node类型的变量f , int 类型的变量 n i fh Node&lt;K,V&gt; f; int n, i, fh; //判断tab是否为null ,是否进行了初始化操作，如果没有执行初始化，执行初始化操作 if (tab == null || (n = tab.length) == 0) tab = initTable(); //tabAt 获取值 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //添加到table中 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; //退出循环 // no lock when adding to empty bin &#125; //node的hash值为 -1 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //key 相等，使用新值替换旧值 if (e.hash == hash &amp;&amp;((ek = e.key) == key ||(ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //放在链表的尾部 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key,value, null); break; &#125; &#125; &#125; //红黑树替换 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; Get方法Get方法也是最长用的方法，元素放入了，总要取出来 根据传入的key,获取相应的hash值 然后判断当前的table数组是否为空 计算指定的key在table中存储的位置 链表或者红黑树转换相依的方法处理 不存在则返回null 123456789101112131415161718192021public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //eh&lt; 0 表示红黑树节点 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //链表遍历 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 总结JDK6，7中的ConcurrentHashmap主要使用Segment来实现减小锁粒度，把HashMap分割成若干个Segment，在put的时候需要锁住Segment，get时候不加锁，使用volatile来保证可见性，当要统计全局时（比如size），首先会尝试多次计算modcount来确定，这几次尝试中，是否有其他线程进行了修改操作，如果没有，则直接返回size。如果有，则需要依次锁住所有的Segment来计算。 jdk7中ConcurrentHashmap中，当长度过长，碰撞会很频繁，链表的增改删查操作都会消耗很长的时间，影响性能，所以jdk8 中完全重写了concurrentHashmap,代码量从原来的1000多行变成了 6000多 行，实现上也和原来的分段式存储有很大的区别。 主要设计上的变化有以下几点: 不采用segment而采用node，锁住node来实现减小锁粒度。 设计了MOVED状态 当resize的中过程中 线程2还在put数据，线程2会帮助resize。 使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 sizeCtl的不同值来代表不同含义，起到了控制的作用。 参考： http://blog.csdn.net/u010723709/article/details/48007881]]></content>
      <tags>
        <tag>Analyst of SourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Everything About HashSet]]></title>
    <url>%2F2020%2F03%2F21%2FEverything-About-HashSet%2F</url>
    <content type="text"><![CDATA[概述文章的内容基于JDK1.7进行分析，之所以选用这个版本，是因为1.8的有些类做了改动，增加了阅读的难度，虽然是1.7，但是对于1.8做了重大改动的内容，文章也会进行说明。 HashSet是Set接口的典型实现，HashSet按照Hash算法来存储集合中的元素。存在以下特点： 不能保证元素的顺序，元素是无序的 HashSet不是同步的，需要外部保持线程之间的同步问题 集合元素值允许为null 数据结构继承关系1234java.lang.Object java.util.AbstractCollection&lt;E&gt; java.util.AbstractSet&lt;E&gt; java.util.HashSet&lt;E&gt; 实现接口1Serializable, Cloneable, Iterable&lt;E&gt;, Collection&lt;E&gt;, Set&lt;E&gt; 基本属性12private transient HashMap&lt;E,Object&gt; map; //map集合，HashSet存放元素的容器private static final Object PRESENT = new Object(); //map，中键对应的value值 重要方法深度解析构造方法123456789101112131415161718192021//无参构造方法，完成map的创建public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;//指定集合转化为HashSet, 完成map的创建public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;//指定初始化大小，和负载因子public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;//指定初始化大小public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;//指定初始化大小和负载因子，dummy 无实际意义HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 通过构造函数，不难发现，HashSet的底层是采用HashMap实现的。 Add()方法123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; PRESENT为HashSet类中定义的一个使用static final 修饰的常量，并无实际的意义，HashSet的add方法调用HashMap的put()方法实现，如果键已经存在，map.put()放回的是旧值，添加失败，如果添加成功map.put()方法返回的是null ,HashSet.add()方法返回true,要添加的元素可作为map中的key 。 remove()123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 删除方法，调用map.remove()方法实现，map.remove()能找到指定的key,则返回key对应的value,对于Hashset而言，它所有的key对应的值都是PRESENT。 源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; static final long serialVersionUID = -5024744406713321676L; //序列化版本号 private transient HashMap&lt;E,Object&gt; map; //HashMap变量，用于存放HashSet的值 private static final Object PRESENT = new Object(); //map中的值 //构造方法 public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; //构造方法，将指定的集合转化为HashSet public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; //构造方法，指定初始化的大小和负载因子 public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125; //指定初始化大小 public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125; //构造方法，采用default修饰，只能是同一个包下的成员访问。包不相同无法访问 HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; //HashSet的遍历操作 //通过这个方法可以发现，HashSet调用了HashMap存放，因为HashSet并不是键值对存储，所以它只是把它的值做了Map中的键，在遍历HashSet的集合元素时，实际上是遍历的Map中Key的集合。 public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125; //返回集合中元素的容量 public int size() &#123; return map.size(); &#125; //判断是否为空 public boolean isEmpty() &#123; return map.isEmpty(); &#125; //是否包含指定的元素 public boolean contains(Object o) &#123; return map.containsKey(o); &#125; //添加元素，添加的元素作为了Map中的key,value使用了一个常量表示 public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; //删除元素 public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125; //清空集合 public void clear() &#123; map.clear(); &#125; //克隆方法 public Object clone() &#123; try &#123; HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); return newSet; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(); &#125; &#125; //写入输出流操作。 private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException &#123; // Write out any hidden serialization magic s.defaultWriteObject(); // Write out HashMap capacity and load factor s.writeInt(map.capacity()); s.writeFloat(map.loadFactor()); // Write out size s.writeInt(map.size()); // Write out all elements in the proper order. for (E e : map.keySet()) s.writeObject(e); &#125; //从输入流中读取对象 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // Read in any hidden serialization magic s.defaultReadObject(); // Read in HashMap capacity and load factor and create backing HashMap int capacity = s.readInt(); float loadFactor = s.readFloat(); map = (((HashSet)this) instanceof LinkedHashSet ? new LinkedHashMap&lt;E,Object&gt;(capacity, loadFactor) : new HashMap&lt;E,Object&gt;(capacity, loadFactor)); // Read in size int size = s.readInt(); // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; E e = (E) s.readObject(); map.put(e, PRESENT); &#125; &#125;&#125; 总结 HashSet的底层通过HashMap实现的。而HashMap在1.7之前使用的是数组+链表实现，在1.8+使用的数组+链表+红黑树实现。其实也可以这样理解，HashSet的底层实现和HashMap使用的是相同的方式，因为Map是无序的，因此HashSet也无法保证顺序。 HashSet的方法，也是借助HashMap的方法来实现的。]]></content>
      <tags>
        <tag>Analyst of SourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-2In TaiwanTech]]></title>
    <url>%2F2020%2F02%2F17%2F2019-2In-TaiwanTech%2F</url>
    <content type="text"><![CDATA[大四上學期的成績單 後面再補內容，已經錯過實習和秋招了。現在抓緊搞搞春招。 學校的課實在太多，30學分忙8過來 回家以后发现钙hub也打不开了…..除了科学上网的解决方法，另外一种就是设置静态IP地址 图床也加载不出来了，这里推荐SM SM的图床服务 新年新FLAG专业技术 按照zuochengyun大哥的建议读JDK重要包的源代码,java.lang,java.util.java.io Spring源码, 学习分布式缓存技术. PASS THE FRM Certification RANK1 语言水平 日语达到N3水平 如何自学备考日语N3？ TOEFL破百 📚书单 Thinking In Java Bruce Eckel 的《Java 编程思想》（Thinking in Java），非常有名的经典书籍。这本书的特点是，不仅仅介绍 Java 编程的基础知识点，也会思考编程中的各种选择与判断，包括穿插设计模式的使用，作者从理论到实践意义从不同的角度进行探讨，构建稳固的 Java 编程知识体系。 Effective Java 这本书的英文第三版已经在国内上市，涵盖了 Java 7 到 Java 9 的各种新特性。严格来说，这本书不算是一本基础书籍，但当你有一定基础后，还是非常建议通读一下的。关于这本书的阅读，我的建议是边学习边回顾，在吸收书中的经验时，多去想想自己在实际应用中是如何处理的。虽然《Effective Java》的具体章节可能是从某个点出发，但可以说都是对 Java、JVM、面向对象等各种知识的综合运用，对于设计和实现高质量的代码很有帮助。 Java 并发编程实战 作者全是响当当的人物，比如 Brian Goetz，我多次在专栏里引用他的观点，众多强力作者也保证了书的质量。抛开作者光环，这本书的内容全部建立在理论之上，先讲清道理再谈实践，可以真正让你知其然也知其所以然。这本书更加侧重并发编程中有哪些问题，如何来深刻地理解和定义问题，如何利用可靠的手段指导工程实践，并没有过分纠结于并发类库的源码层面。 深入理解 Java 虚拟机 性能优化 性能优化，我推荐 Charlie Hunt 和 Binu John 所著的《Java 性能优化权威指南》（Java Performance），也是我上次在直播时向大家推荐的。Java 之父 James Gosling。 Spring实战 可以说 Spring 等相关框架已经成为业务开发的事实标准，系统性地掌握 Spring 框架的设计和实践，是必需的技能之一。 Netty实战 Netty 在性能、可扩展性等方面的突出表现，已经得到充分验证，作为基础的通信框架，已经广泛应用在各种互联网架构、游戏等领域，甚至可以说，如果没有仔细分析过 Netty，对 NIO 等方面的理解很可能还在很肤浅的阶段。 Cloud Native Java Java 应用程序架构处于飞快的演进之中，微服务等新的架构应用越来越广泛，即使未必是使用 Spring Boot、Spring Cloud 等框架，但是系统的学习其设计思想和实践技术，绝对是有必要的。当然如果你在实践中使用 Dubbo 等框架，也可以选择相关书籍。前沿领域的变化非常快，很多风靡一时的开源软件，在实践中逐渐被证明存在各种弊端，或者厂商停止维护。所以这部分的学习，我建议不要盲目追新，最好是关注于分布式设计中的问题和解决的思路，做到触类旁通，并且注重书籍之外的学习渠道。下面两本并不算是 Java 书籍，但 Java 程序员进阶少不了对互联网主流架构的学习，了解分布式架构、缓存、消息中间件等令人眼花缭乱的技术，对于有志于成为架构师的 Java 工程师来说非常有帮助。 大型分布式网站架构设计与实践 这本书总结了作者在构建安全、可稳定性、高扩展性、高并发的分布式网站方面的心得。 深入分布式缓存：从原理到实战 这本书融合了原理、架构和一线互联网公司的案例实践，值得参考。]]></content>
      <tags>
        <tag>TaiwanTech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Garbage Collection In JVM]]></title>
    <url>%2F2020%2F02%2F15%2FGarbage-Collection-In-JVM%2F</url>
    <content type="text"><![CDATA[为什么我们要了解JVM 私有线程区域： 栈：函数当前运行过程中的一些函数变量。存对象的引用类型和地址 本地方法栈：存放C++运行时的native栈。 程序计数器：指向当前程序运行的位置。线程共享区域： 堆：存对象(最终)，老年代。 方法区：存储元数据信息，在JDK1.7前作永久代，1.8以后改为元数据空间，存储静态变量和常量、类加载器。 Java的基础数据和指针都是值类型，所以直接存到内存里面去，不是去存地址寻址。 GC GC Root本地方法栈,方法区,栈不能被删除 删除方法 标记清理，==会产生内存碎片==。 标记整理(删了后面的顶上来，减少内存碎片)，==前移空间移动代价太大==。 复制算法(分为两个区)，不直接删除，不被删除的复制到新区，==需要2倍的内存==。 实际：Minor GC当在 Eden 区分配内存不足时，则会发生 minorGC ，由于 Java 对象多数是朝生夕灭的特性，所以 minorGC通常会比较频繁，效率也比较高。 年轻代：E区(伊甸园，满了触发YoungGC,用复制算法)，，两个Survive区(S0.S1) 8：1：1，两个S区交替工作（E+S1到S0,E+S0到S1）。每次Young GC完年龄会加一，满15岁就直接都去老年代区了。ParNew垃圾收集器(复制)。Full GC 老年代：只有一块，存满15岁到去老年代区的对象。和大对象，Old满了就和年轻的一起Full GC,发生STOPPED WORLD,整个Java程序直接暂停，就用标记清理或者标记整理。CMS垃圾收集器(标记清理)。 和GC Root无关的才能被删除]]></content>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Principle of JVM]]></title>
    <url>%2F2020%2F02%2F08%2FPrinciple-of-JVM%2F</url>
    <content type="text"><![CDATA[JVM原理速记复习Java虚拟机总结思维导图面试必备 Java虚拟机一、运行时数据区域线程私有程序计数器记录正在执行的虚拟机字节码指令的地址（如果正在执行的是Native方法则为空），是唯一一个没有规定OOM（OutOfMemoryError）的区域。Java虚拟机栈每个Java方法在执行的同时会创建一个栈桢用于存储局部变量表、操作数栈、动态链接、方法出口等信息。从方法调用直到执行完成的过程，对应着一个栈桢在Java虚拟机栈中入栈和出栈的过程。（局部变量包含基本数据类型、对象引用reference和returnAddress类型）本地方法栈本地方法栈与Java虚拟机栈类似，它们之间的区别只不过是本地方法栈为Native方法服务。线程公有Java堆（GC区）（Java Head）几乎所有的对象实例都在这里分配内存，是垃圾收集器管理的主要区域。分为新生代和老年代。对于新生代又分为Eden空间、From Survivor空间、To Survivor空间。JDK1.7 方法区（永久代）用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。对这块区域进行垃圾回收的主要目的是对常量池的回收和对类的卸载，但是一般难以实现。HotSpot虚拟机把它当做永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素的影响，并且每次Full GC之后永久代的大小都会改变，所以经常抛出OOM异常。从JDK1.8开始，移除永久代，并把方法区移至元空间。运行时常量池是方法区的一部分Class文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。允许动态生成，例如String类的intern()JDK1.8 元空间原本存在方法区（永久代）的数据，一部分移到了Java堆里面，一部分移到了本地内存里面（即元空间）。元空间存储类的元信息，静态变量和常量池等放入堆中。直接内存在NIO中，会使用Native函数库直接分配堆外内存。二、HotSpot虚拟机对象的创建当虚拟机遇到一条new指令时检查参数能否在常量池中找到符号引用，并检查这个符号引用代表的类是否已经被加载、解析和初始过，没有的话先执行相应的类加载过程。在类加载检查通过之后，接下来虚拟机将为新生对象分配内存。内存分配完成之后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）。对对象头进行必要的设置。执行构造方法按照程序员的意愿进行初始化。对象的内存布局对象头第一部分用于存储对象自身的运行时数据，如哈希码、GC分代年龄、锁状态标识、线程持有的锁、偏向线程ID、偏向实现戳等。第二部分是类型指针，即对象指向它的类元数据的指针（如果使用直接对象指针访问），虚拟机通过这个指针来确定这个对象是哪个类的实例。如果对象是一个Java数组的话，还需要第三部分记录数据长度的数据。实例数据是对象真正存储的有效信息，也就是在代码中定义的各种类型的字段内容。对齐填充不是必然存在的，仅仅起着占位符的作用。HotSpot需要对象的大小必须是8字节的整数倍。对象的访问定位句柄访问在Java堆中划分出一块内存作为句柄池。Java栈上的对象引用reference中存储的就是对象的句柄地址，而句柄中包含了到对象实例数据的指针和到对象类型数据的指针。对象实例数据在Java堆中，对象类型数据在方法区（永久代）中。优点：在对象被移动时只会改变句柄中的实例数据指针，而对象引用本身不需要修改。直接指针访问（HotSpot使用）Java栈上的对象引用reference中存储的就是对象的直接地址。在堆中的对象实例数据就需要包含到对象类型数据的指针。优点：节省了一次指针定位的时间开销，速度更快。三、垃圾收集概述垃圾收集主要是针对Java堆和方法区。程序计数器、Java虚拟机栈个本地方法栈三个区域属于线程私有，线程或方法结束之后就会消失，因此不需要对这三个区域进行垃圾回收。判断对象是否可以被回收第一次标记（缓刑）引用计数算法给对象添加一个引用计数器，当对象增加一个引用时引用计数值++，引用失效时引用计数值–，引用计数值为0时对象可以被回收。但是它难以解决对象之间的相互循环引用的情况，此时这个两个对象引用计数值为1，但是永远无法用到这两个对象。 可达性分析算法（Java使用） 以一系列GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连是，则证明此对象不可用，可以被回收。GC Roots对象包括虚拟机栈（栈桢中的本地变量表）中引用的对象。方法区中共类静态属性引用的对象。方法区中常量引用的对象。本地方法栈中JNI（即一般说的Native方法）引用的对象。第二次标记当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过。如果对象在finalize方法中重新与引用链上的任何一个对象建立关联则将不会被回收。finalize()任何一个对象的finalize()方法都只会被系统调用一次。它的出现是一个妥协，运行代价高昂，不确定性大，无法保证各个对象的调用顺序。finalize()能做的所有工作使用try-finally或者其他方式都可以做的更好，完全可以忘记在这个函数的存在。方法区的回收在方法区进行垃圾回收的性价比一般比较低。主要回收两部分，废弃常量和无用的类。满足无用的类三个判断条件才仅仅代表可以进行回收，不是必然关系，可以使用-Xnoclassgc参数控制。该类的所有实例都已经被回收，也就是Java堆中不存在该类的任何实例。加载该类的ClassLoader已经被回收。该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问到该类的方法。引用类型强引用使用new一个新对象的方式来创建强引用。只要强引用还存在，被引用的对象则永远不会被回收。软引用使用SoftReference类来实现软引用。用来描述一些还有用但是并非必须的对象，被引用的对象在将要发生内存溢出异常之前会被回收。弱引用使用WeakReference类来实现弱引用。强度比软引用更弱一些，被引用的对象在下一次垃圾收集时会被回收。虚引用使用PhantomReference类来实现虚引用。最弱的引用关系，不会对被引用的对象生存时间构成影响，也无法通过虚引用来取得一个对象实例。唯一目的就是能在这个对象被收集器回收时收到一个系统通知。垃圾收集算法标记 - 清除首先标记出所有需要回收的对象，在标记完成后统一回收被标记的对象并取消标记。不足：效率问题，标记和清除两个过程的效率都不高。空间问题，标记清除之后会产生大量不连续的内存碎片，没有连续内存容纳较大对象而不得不提前触发另一次垃圾收集。标记 - 整理和标记 - 清除算法一样，但标记之后让所有存活对象都向一段移动，然后直接清理掉端边界以外的内存。解决了标记 - 清除算法的空间问题，但需要移动大量对象，还是存在效率问题。复制将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用多的内存空间一次清理掉。代价是将内存缩小为原来的一般，太高了。现在商业虚拟机都采用这种算法用于新生代。因为新生代中的对象98%都是朝生暮死，所以将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor空间。当回收时，如果另外一块Survivor空间没有足够的空间存放存活下来的对象时，这些对象将直接通过分配担保机制进入老年代。分代收集一般把Java堆分为新生代和老年代。在新生代中使用复制算法，在老年代中使用标记 -清除 或者 标记 - 整理 算法来进行回收。HotSpot的算法实现枚举根节点（GC Roots）目前主流Java虚拟机使用的都是准确式GC。GC停顿的时候，虚拟机可以通过OopMap数据结构（映射表）知道，在对象内的什么偏移量上是什么类型的数据，而且特定的位置记录着栈和寄存器中哪些位置是引用。因此可以快速且准确的完成GC Roots枚举。安全点为了节省GC的空间成本，并不会为每条指令都生成OopMap，只是在“特定的位置”记录OopMap，这些位置称为安全点。程序执行只有到达安全点时才能暂停，到达安全点有两种方案。抢断式中断（几乎不使用）。GC时，先把所有线程中断，如果有线程不在安全点，就恢复该线程，让他跑到安全点。主动式中断（主要使用）。GC时，设置一个标志，各个线程执行到安全点时轮询这个标志，发现标志为直则挂起线程。但是当线程sleep或blocked时无法响应JVM的中断请求走到安全点中断挂起，所以引出安全区域。安全区域安全区域是指在一段代码片段之中，引用关系不会发生变化，是扩展的安全点。线程进入安全区域时表示自己进入了安全区域，这个发生GC时，JVM就不需要管这个线程。线程离开安全区域时，检查系统是否完成GC过程，没有就等待可以离开安全区域的信号为止，否者继续执行。垃圾收集器新生代serial收集器它是单线程收集器，只会使用一个线程进行垃圾收集工作，更重要的是它在进行垃圾收集时，必须暂停其他所有的工作线程。优点：对比其他单线程收集器简单高效，对于单个CPU环境来说，没有线程交互的开销，因此拥有最高的单线程收集效率。它是Client场景下默认新生代收集器，因为在该场景下内存一般来说不会很大。 parnew收集器 它是Serial收集器的多线程版本，公用了相当多的代码。 在单CPU环境中绝对不会有比Serial收集器更好的效果，甚至在2个CPU环境中也不能百分之百超越。它是Server场景下默认的新生代收集器，主要因为除了Serial收集器，只用它能与CMS收集器配合使用。 parallel scavenge收集器 “吞吐优先”收集器，与ParNew收集器差不多。 但是其他收集器的目标是尽可能缩短垃圾收集时用户线程停顿的时间，而它的目标是达到一个可控制的吞吐量。这里的吞吐量指CPU用于运行用户程序的时间占总时间的比值。老年代serial old收集器是Serial收集器老年代版本。也是给Client场景下的虚拟机使用的。 parallel old收集器 是Parallel Scavenge收集器的老年代版本。 在注重吞吐量已经CPU资源敏感的场合，都可以优先考虑Parallel Scavenge和Parallel Old收集器。 cms收集器 Concurrent Mark Sweep收集器是一种以获取最短回收停顿时间为目标的收集器。 运作过程 初始标记（最短）。仍需要暂停用户线程。只是标记一下GC Roots能直接关联到的对象，速度很快并发标记（耗时最长）。进行GC Roots Tracing（根搜索算法）的过程。重新标记。修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。比初始标记长但远小于并发标记时间。并发清除1 和4 两个步骤并没有带上并发两个字，即这两个步骤仍要暂停用户线程。 优缺点 并发收集、低停顿。CMS收集器对CPU资源非常敏感。虽然不会导致用户线程停顿，但是占用CPU资源会使应用程序变慢。无法处理浮动垃圾。在并发清除阶段新垃圾还会不断的产生，所以GC时要控制“-XX:CMSinitiatingOccupancyFraction参数”预留足够的内存空间给这些垃圾，当预留内存无法满足程序需要时就会出现”Concurrent Mode Failure“失败，临时启动Serial Old收集。由于使用标记 - 清除算法，收集之后会产生大量空间碎片。g1收集器Garbage First是一款面向服务端应用的垃圾收集器运作过程初始标记并发标记最终标记删选标记五、类加载机制概述虚拟机把描述类的数据从Class问价加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。Java应用程序的高度灵活性就是依赖运行期动态加载和动态连接实现的。类的生命周期加载 -&gt; 连接（验证 -&gt; 准备 -&gt; 解析） -&gt; 初始化 -&gt; 使用 - &gt;卸载类初始化时机主动引用虚拟机规范中没有强制约束何时进行加载，但是规定了有且只有五种情况必须对类进行初始化（加载、验证、准备都会随之发生）遇到new、getstatic、putstatic、invokestatic这四条字节码指令时没有初始化。反射调用时没有初始化。发现其父类没有初始化则先触发其父类的初始化。包含psvm（mian（）方法）的那个类。动态语言支持时，REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄。被动引用除上面五种情况之外，所有引用类的方式都不会触发初始化，称为被动引用。通过子类引用父类的静态字段，不会导致子类的初始化。通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承Object的子类，其中包含数组的属性和方法，用户只能使用public的length和clone()。常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。类加载过程加载通过类的全限定名来获取定义此类的二进制字节流。将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。在内存中生成一个代表这个类的java.lang.Class对象（HotSpot将其存放在方法区中），作为方法区这个类的各种数据的访问入口。验证为了确保Class文件的字节类中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。可以通过-Xverify:none关闭大部分类验证。文件格式验证。确保输入字节流能正确的解析并存储于方法区，后面的3个验证全部基于方法区的存储结构进行，不会再操作字节流。元数据验证。对字节码描述信息进行语义分析，确保其符合Java语法规范。（Java语法验证）字节码验证。最复杂，通过数据流和控制流分析，确定程序语义时合法的、符合逻辑的。可以通过参数关闭。（验证指令跳转范围，类型转换有效等）符号引用验证。将符号引用转化为直接引用，发生在第三个阶段——解析阶段中发生。准备类变量是被static修饰的变量，准备阶段为类变量分配内存并设置零值（final直接设置初始值），使用的是方法区的内存。解析将常量池内的符号引用替换为直接引用的过程。其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的动态绑定。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄、和调用点限定符。初始化初始化阶段才真正执行类中定义的Java程序代码，是执行类构造器()方法的过程。在准备阶段，类变量已经给过零值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其他资源。()类构造器方法。是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的的语句合并产生的。不需要显式调用父类构造器，JVM会保证在子类clinit执行之前，父类的clinit已经执行完成。接口中不能使用静态语句块但仍可以有类变量的赋值操作。当没有使用父接口中定义的变量时子接口的c 接口中不能使用静态语句块但仍可以有类变量的赋值操作。当没有使用父接口中定义的变量时子接口的clinit不需要先执行父接口的clinit方法。接口的实现类也不会执行接口的clinit方法。 虚拟机会保证clinit在多线程环境中被正确的加锁、同步。其他线性唤醒之后不会再进入clinit方法，同一个类加载器下，一个类型只会初始化一次。 &lt;init&gt;() 对象构造器方法。Java对象被创建时才会进行实例化操作，对非静态变量解析初始化。会显式的调用父类的init方法，对象实例化过程中对实例域的初始化操作全部在init方法中进行。类（加载） 器类与类加载器类加载器实现类的加载动作。类加载器和这个类本身一同确立这个类的唯一性，每个类加载器都有独立的类命名空间。在同一个类加载器加载的情况下才会有两个类相等。相等包括类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()、instanceof关键字。类加载器分类启动类加载器由C++语言实现，是虚拟机的一部分。负责将JAVA_HOME/lib目录中，或者被-Xbootclasspath参数指定的路径，但是文件名要能被虚拟机识别，名字不符合无法被启动类加载器加载。启动类加载器无法被Java程序直接引用。扩展类加载器由Java语言实现，负责加载JAVA_HOME/lib/ext目录，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。应用程序类加载器由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称他为系统类加载器。负责加载用户类路径（ClassPath）上所指定的类库，一般情况下这个就是程序中默认的类加载器。自定义类加载器由用户自己实现。如果不想打破双亲委派模型，那么只需要重写findClass方法即可。否则就重写整个loadClass方法。双亲委派模型双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器。父子不会以继承的关系类实现，而是都是使用组合关系来服用父加载器的代码。在java.lang.ClassLoader的loadClass()方法中实现。工作过程一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成（它的搜索范围中没有找到所需要的类）时才尝试自己加载好处Java类随着它的类加载器一起具备了一种带有优先级的层次关系，从而使得基础类库得到同意。四、内存分配与回收策略Minor GC 和 Full GCMinor GC发生在新生代的垃圾收集动作，因为新生代对象存活时间很短，因此Minor GC会频繁执行，执行速度快。时机Eden不足Full GC发生在老年区的GC，出现Full GC时往往伴随着Minor GC，比Minor GC慢10倍以上。时机调用System.gc()只是建议虚拟机执行Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。老年代空间不足常见场景就是大对象和长期存活对象进入老年代。尽量避免创建过大的对象以及数组，调大新生代大小，让对象尽量咋新生代中被回收，不进入老年代。JDK1.7 之前方法区空间不足当系统中要加载的类、反射的类和常量较多时，永久代可能会被占满，在未配置CMS GC的情况下也会执行Full GC，如果空间仍然不够则会抛出OOM异常。可采用增大方法区空间或转为使用CMS GC。空间分配担保失败发生Minor GC时分配担保的两个判断失败Concurrent Mode FailureCMS GC 并发清理阶段用户线程还在执行，不断有新的浮动垃圾产生，当预留空间不足时报Concurrent Mode Failure错误并触发Full GC。内存分配策略对象优先在Eden分配大多数情况下，对象在新生代Eden上分配，当Eden空间不够时，发起Minor GC，当另外一个Survivor空间不足时则将存活对象通过分配担保机制提前转移到老年代。大对象直接进入老年代配置参数-XX:PretenureSizeThreshold，大于此值得对象直接在老年代分配，避免在Eden和Survivor之间的大量内存复制。长期存活对象进入老年代虚拟机为每个对象定义了一个Age计数器，对象在Eden出生并经过Minor GC存活转移到另一个Survivor空间中时Age++，增加到默认16则转移到老年代。动态对象年龄绑定虚拟机并不是永远要求对象的年龄必须到达MaxTenuringThreshold才能晋升老年代，如果在Survivor中相同年龄所有对象大小总和大于Survivor空间的一半，则年龄大于或等于该年龄的对象直接进入老年代。空间分配担保在发生Minor GC之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代的所有对象，如果条件成立，那么Minor GC可以认为是安全的。可以通过HandlePromotionFailure参数设置允许冒险，此时虚拟机将与历代晋升到老年区对象的平均大小比较，仍小于则要进行一次Full GC。在JDK1.6.24之后HandlePromotionFailure已无作用，即虚拟机默认为true。]]></content>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Everything about ArrayList]]></title>
    <url>%2F2020%2F02%2F08%2FEverything-about-ArrayList%2F</url>
    <content type="text"><![CDATA[Java ArrayList底层实现原理源码详细分析Jdk8ArrayList是基于数组实现的，是一个动态数组，其容量能自动增长，类似于C语言中的动态申请内存，动态增长内存。 ArrayList不是线程安全的，只能用在单线程环境下，多线程环境下可以考虑用Collections.synchronizedList(List l)函数返回一个线程安全的ArrayList类，也可以使用concurrent并发包下的CopyOnWriteArrayList类。 ArrayList实现了Serializable接口，因此它支持序列化，能够通过序列化传输，实现了RandomAccess接口，支持快速随机访问，实际上就是通过下标序号进行快速访问，实现了Cloneable接口，能被克隆。 存储结构// 当前数据对象存放地方，当前对象不参与序列化// 这个关键字最主要的作用就是当序列化时，被transient修饰的内容将不会被序列化transient Object[] elementData;Object类型数组。数据域1234567891011121314151617181920212223// 序列化ID private static final long serialVersionUID = 8683452581122892189L; // 默认初始容量 private static final int DEFAULT_CAPACITY = 10; // 一个空数组，方便使用，主要用于带参构造函数初始化和读取序列化对象等。 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * 和官方文档写的一样，DEFAULTCAPACITY_EMPTY_ELEMENTDATA 和EMPTY_ELEMENTDATA 的区别 * 仅仅是为了区别用户带参为0的构造和默认构造的惰性初始模式对象。 * 当用户带参为0的构造，第一次add时，数组容量grow到1。 * 当用户使用默认构造时，第一次add时，容量直接grow到DEFAULT_CAPACITY（10）。 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; // 当前数据对象存放地方，当前对象不参与序列化 // 这个关键字最主要的作用就是当序列化时，被transient修饰的内容将不会被序列化 transient Object[] elementData; // non-private to simplify nested class access // 当前数组中元素的个数 private int size; // 数组最大可分配容量 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; // 集合数组修改次数的标识（由AbstractList继承下来）（fail-fast机制） protected transient int modCount = 0;ArrayList的无参构造函数。初始化的时候并没有真正的创建10个空间，这是惰性初始模式对象。DEFAULTCAPACITY_EMPTY_ELEMENTDATA 和EMPTY_ELEMENTDATA 的区别仅仅是为了区别用户带参为0的构造和默认构造的惰性初始模式对象。modCount用来记录ArrayList结构发生变化的次数。用于Fail-Fast机制构造函数 1234567891011121314151617181920212223242526272829303132public ArrayList() &#123; // 只有这个地方会引用DEFAULTCAPACITY_EMPTY_ELEMENTDATA this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; public ArrayList(int initialCapacity) &#123; if (initialCapacity &amp;gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 使用 EMPTY_ELEMENTDATA，在其他的多个地方可能会引用EMPTY_ELEMENTDATA this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&amp;quot;Illegal Capacity: &amp;quot;+ initialCapacity); &#125; &#125; public ArrayList(Collection&amp;lt;? extends E&amp;gt; c) &#123; // 把传入集合传化成[]数组并浅拷贝给elementData elementData = c.toArray(); // 转化后的数组长度赋给当前ArrayList的size,并判断是否为0 if ((size = elementData.length) != 0) &#123; //c.toArray可能不会返回 Object[]，可以查看 java 官方编号为 6260652 的 bug if (elementData.getClass() != Object[].class) // 若 c.toArray() 返回的数组类型不是 Object[]，则利用 Arrays.copyOf(); 来构造一个大小为 size 的 Object[] 数组 // 此时elementData是指向传入集合的内存，还需要创建新的内存区域深拷贝给elementData elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 传入数组size为零替换空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; DEFAULTCAPACITY_EMPTY_ELEMENTDATA 和EMPTY_ELEMENTDATA 的区别仅仅是为了区别用户带参为0的构造和默认构造的惰性初始模式对象。注意深拷贝和浅拷贝。带参为0的构造会惰性初始化，不为0的构造则不会惰性初始化。add()源码解析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public boolean add(E e) &#123; // 确保数组已使用长度（size）加1之后足够存下 下一个数据 ensureCapacityInternal(size + 1); // Increments modCount!! // 数组的下一个index存放传入元素。 elementData[size++] = e; // 始终返回true。 return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 这里就是DEFAULTCAPACITY_EMPTY_ELEMENTDATA 和 // EMPTY_ELEMENTDATA 最主要的区别。 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 默认构造第一次add返回10。 return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 带参为0构造第一次add返回 1 （0 + 1）。 return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; // 自增修改计数 modCount++; // overflow-conscious code // 当前数组容量小于需要的最小容量 if (minCapacity - elementData.length &amp;gt; 0) // 准备扩容数组 grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code // 获得当前数组容量 int oldCapacity = elementData.length; // 新数组容量为1.5倍的旧数组容量 int newCapacity = oldCapacity + (oldCapacity &amp;gt;&amp;gt; 1); if (newCapacity - minCapacity &amp;lt; 0) // 若 newCapacity 依旧小于 minCapacity newCapacity = minCapacity; // 判断是需要的容量是否超过最大的数组容量。 if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 在Arrays.copyOf()中会将原数组整个赋值到扩容的数组中。 elementData = Arrays.copyOf(elementData, newCapacity);&#125;扩容操作需要调用Arrays.copyOf()把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建ArrayList对象时就指定大概的容量大小，减少扩容操作的次数。add(int index, E element)源码分析123456789101112131415161718192021222324// 这是一个本地方法，由C语言实现。public static native void arraycopy(Object src, // 源数组 int srcPos, // 源数组要复制的起始位置 Object dest, // 目标数组（将原数组复制到目标数组） int destPos, // 目标数组起始位置（从目标数组的哪个下标开始复制操作） int length // 复制源数组的长度 );public void add(int index, E element) &#123; // 判断索引是否越界 rangeCheckForAdd(index); // 确保数组已使用长度（size）加1之后足够存下 下一个数据 ensureCapacityInternal(size + 1); // Increments modCount!! // 运行到这里代表数组容量满足。 // 数组从传入形参index处开始复制，复制size-index个元素（即包括index在内后面的元素全部复制）， // 从数组的index + 1处开始粘贴。 // 这时，index 和 index + 1处元素数值相同。 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 把index处的元素替换成新的元素。 elementData[index] = element; // 数组内元素长度加一。 size++;&#125;需要调用System.arraycopy()将包括index在内后面的元素都复制到index + 1位置上，该操作的时间复杂度为O(N)，可以看出ArrayList数组头增加元素的代价是非常高的。remove(int index)源码分析1234567891011121314151617public E remove(int index) &#123; // 检查index rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &amp;gt; 0) // 和 add(int index, E element)原理想通。 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 引用计数为0，会自动进行垃圾回收。 elementData[--size] = null; // clear to let GC do its work // 返回旧元素 return oldValue; &#125;需要调用System.arraycopy()将包括index + 1在内后面的元素都复制到index位置上，该操作的时间复杂度为O(N)，可以看出ArrayList数组头增加元素的代价是非常高的。Fail-Fast机制fail-fast 机制，即快速失败机制，是java集合(Collection)中的一种错误检测机制。当在迭代集合的过程中该集合在结构上发生改变的时候，就有可能会发生fail-fast，即抛出ConcurrentModificationException异常。fail-fast机制并不保证在不同步的修改下一定会抛出异常，它只是尽最大努力去抛出，所以这种机制一般仅用于检测bug。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组大小，仅仅只是设置元素的值不算结构发生变化。在进行序列化或者迭代操作时，需要比较操作前后modCount是否改变，如果改变了需要跑出ConcurrentModificationException1234567891011121314151617181920212223242526272829private class Itr implements Iterator&amp;lt;E&amp;gt; &#123; int cursor; int lastRet = -1; // 期待的修改值等于当前修改次数（modCount） int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; public E next() &#123; // 检查 expectedModCount是否等于modCount，不相同则抛出ConcurrentModificationException checkForComodification(); /** 省略此处代码 */ &#125; public void remove() &#123; if (this.lastRet &amp;lt; 0) throw new IllegalStateException(); checkForComodification(); /** 省略此处代码 */ &#125; final void checkForComodification() &#123; if (ArrayList.this.modCount == this.expectedModCount) return; throw new ConcurrentModificationException(); &#125; &#125;一个单线程环境下的fail-fast的例子123456789101112131415public static void main(String[] args) &#123; List&amp;lt;String&amp;gt; list = new ArrayList&amp;lt;&amp;gt;(); for (int i = 0 ; i &amp;lt; 10 ; i++ ) &#123; list.add(i + &amp;quot;&amp;quot;); &#125; Iterator&amp;lt;String&amp;gt; iterator = list.iterator(); int i = 0 ; while(iterator.hasNext()) &#123; if (i == 3) &#123; list.remove(3); &#125; System.out.println(iterator.next()); i ++; &#125; &#125;序列化ArrayList 实现了 java.io.Serializable 接口，但是自己定义了序列化和反序列化。因为ArrayList基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没有必要全部进行序列化。因此 elementData 数组使用 transient 修饰，可以防止被自动序列化。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; // 将当前类的非静态(non-static)和非瞬态(non-transient)字段写入流 // 在这里也会将size字段写入。 s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() // 序列化数组包含元素数量，为了向后兼容 // 两次将size写入流 s.writeInt(size); // Write out all elements in the proper order. // 按照顺序写入，只写入到数组包含元素的结尾，并不会把数组的所有容量区域全部写入 for (int i=0; i&amp;lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; // 判断是否触发Fast-Fail if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // 设置数组引用空数组。 elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff // 将流中的的非静态(non-static)和非瞬态(non-transient)字段读取到当前类 // 包含 size s.defaultReadObject(); // Read in capacity // 读入元素个数，没什么用，只是因为写出的时候写了size属性，读的时候也要按顺序来读 s.readInt(); // ignored if (size &amp;gt; 0) &#123; // be like clone(), allocate array based upon size not capacity // 根据size计算容量。 int capacity = calculateCapacity(elementData, size); // SharedSecrets 一个“共享机密”存储库，它是一种机制， // 用于调用另一个包中的实现专用方法，而不使用反射。TODO SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); // 检查是否需要扩容 ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. // 依次读取元素到数组中 for (int i=0; i&amp;lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125; &#125;ArrayList中为什么size要序列化两次？在代码中s.defaultWriteObject();中size应该也被序列化了，为什么下边还要再单独序列化一次呢？这样写是出于兼容性考虑。旧版本的JDK中，ArrayList的实现有所不同，会对length字段进行序列化。而新版的JDK中，对优化了ArrayList的实现，不再序列化length字段。这个时候，如果去掉s.writeInt(size)，那么新版本JDK序列化的对象，在旧版本中就无法正确读取，因为缺少了length字段。因此这种写法看起来多此一举，实际上却保证了兼容性。### 小结ArrayList基于数组方式实现，无容量的限制（会扩容）添加元素时可能要扩容（所以最好预判一下），删除元素时不会减少容量（若希望减少容量可以使用trimToSize()），删除元素时，将删除掉的位置元素置为null，下次gc就会回收这些元素所占的内存空间。线程不安全add(int index, E element)：添加元素到数组中指定位置的时候，需要将该位置及其后边所有的元素都整块向后复制一位get(int index)：获取指定位置上的元素时，可以通过索引直接获取（O(1)）remove(Object o)需要遍历数组remove(int index)不需要遍历数组，只需判断index是否符合条件即可，效率比remove(Object o)高contains(E)需要遍历数组 面试必会之ArrayList源码分析&amp;手写ArrayList]]></content>
      <tags>
        <tag>Analyst of SourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The data structure and algorithm behind the MySQL index]]></title>
    <url>%2F2020%2F02%2F05%2FThe-data-structure-and-algorithm-behind-the-MySQL-index%2F</url>
    <content type="text"><![CDATA[文章主要内容分为三个部分。 第一部分主要从数据结构及算法理论层面讨论MySQL数据库索引的数理基础。 第二部分结合MySQL数据库中MyISAM和InnoDB数据存储引擎中索引的架构实现讨论聚集索引、非聚集索引及覆盖索引等话题。 第三部分根据上面的理论基础，讨论MySQL中高性能使用索引的策略。 数据结构及算法基础 索引的本质 MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。 我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 看一个例子： 图1 图1展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在(O(log_2n))的复杂度内获取到相应数据。 虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现的，原因会在下文介绍。 B-Tree和B+Tree 目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。 B-Tree 为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构： d为大于1的一个正整数，称为B-Tree的度。 h为一个正整数，称为B-Tree的高度。 每个非叶子节点由n-1个key和n个指针组成，其中d&lt;=n&lt;=2d。 每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。 所有叶节点具有相同的深度，等于树高h。 key和指针互相间隔，节点两端是指针。 一个节点中的key从左到右非递减排列。 所有节点组成树结构。 每个指针要么为null，要么指向另外一个节点。 如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于(v(key_1))，其中(v(key_1))为node的第一个key的值。 如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于(v(key_m))，其中(v(key_m))为node的最后一个key的值。 如果某个指针在节点node的左右相邻key分别是(key_i)和(key_{i+1})且不为null，则其指向节点的所有key小于(v(key_{i+1}))且大于(v(key_i))。 图2是一个d=2的B-Tree示意图。 图2 由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：12345678910&lt;pre class="prettyprint linenums"&gt;BTree_Search(node, key) &#123; if(node == null) return null; foreach(node.key) &#123; if(node.key[i] == key) return node.data[i]; if(node.key[i] &amp;gt; key) return BTree_Search(point[i]-&amp;gt;node); &#125; return BTree_Search(point[i+1]-&amp;gt;node);&#125;data = BTree_Search(root, my_key);&lt;/pre&gt; 关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为(log_d((N+1)/2))，检索一个key，其查找节点个数的渐进复杂度为(O(log_dN))。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。 另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。 B+Tree B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。 与B-Tree相比，B+Tree有以下不同点： 每个节点的指针上限为2d而不是2d+1。 内节点不存储data，只存储key；叶子节点不存储指针。 图3是一个简单的B+Tree示意。 图3 由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。 一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。 带有顺序访问指针的B+Tree 一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。 图4 如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。 这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。 为什么使用B-Tree（B+Tree） 上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。 一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。 主存存取原理 目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。 图5 从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。 主存的存取过程如下： 当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。 写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。 这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。 磁盘存取原理 上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。 图6是磁盘的整体结构示意图。 图6 一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。 图7是磁盘结构的示意图。 图7 盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。 当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。 局部性原理与磁盘预读 由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理： 当一个数据被用到时，其附近的数据也通常会马上被使用。 程序运行期间所需要的数据通常比较集中。 由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。 B-/+Tree索引的性能分析 到这里终于可以分析B-/+Tree索引的性能了。 上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧： 每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。 B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为(O(h)=O(log_dN))。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。 综上所述，用B-Tree作为索引结构效率是非常高的。 而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。 上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小： (d_{max}=floor(pagesize / (keysize + datasize + pointsize))) floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。 这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。 MySQL索引实现 在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。 MyISAM索引实现 MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图： 图8 这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示： 图9 同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。 InnoDB索引实现 虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 图10 图10是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，图11为定义在Col3上的一个辅助索引： 图11 这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 下一章将具体讨论这些与索引有关的优化策略。 索引使用策略及优化 MySQL的优化主要分为结构优化（Scheme optimization）和查询优化（Query optimization）。本章讨论的高性能索引策略主要属于结构优化范畴。本章的内容完全基于上文的理论基础，实际上一旦理解了索引背后的机制，那么选择高性能的策略就变成了纯粹的推理，并且可以理解这些策略背后的逻辑。 示例数据库 为了讨论索引策略，需要一个数据量不算小的数据库作为示例。本文选用MySQL官方文档中提供的示例数据库之一：employees。这个数据库关系复杂度适中，且数据量较大。下图是这个数据库的E-R关系图（引用自MySQL官方手册）： 图12 MySQL官方文档中关于此数据库的页面为http://dev.mysql.com/doc/employee/en/employee.html。里面详细介绍了此数据库，并提供了下载地址和导入方法，如果有兴趣导入此数据库到自己的MySQL可以参考文中内容。 最左前缀原理与相关优化 高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。 这里先说一下联合索引的概念。在上文中，我们都是假设索引只引用了单个的列，实际上，MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组&lt;a1, a2, …, an&gt;，其中各个元素均为数据表的一列，实际上要严格定义索引需要用到关系代数，但是这里我不想讨论太多关系代数的话题，因为那样会显得很枯燥，所以这里就不再做严格定义。另外，单列索引可以看成联合索引元素数为1的特例。 以employees.titles表为例，下面先查看其上都有哪些索引： SHOW INDEX FROM employees.titles;+——–+————+———-+————–+————-+———–+————-+——+————+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Null | Index_type |+——–+————+———-+————–+————-+———–+————-+——+————+| titles | 0 | PRIMARY | 1 | emp_no | A | NULL | | BTREE || titles | 0 | PRIMARY | 2 | title | A | NULL | | BTREE || titles | 0 | PRIMARY | 3 | from_date | A | 443308 | | BTREE || titles | 1 | emp_no | 1 | emp_no | A | 443308 | | BTREE |+——–+————+———-+————–+————-+———–+————-+——+————+ 从结果中可以到titles表的主索引为&lt;emp_no, title, from_date&gt;，还有一个辅助索引&lt;emp_no&gt;。为了避免多个索引使事情变复杂（MySQL的SQL优化器在多索引时行为比较复杂），这里我们将辅助索引drop掉： ALTER TABLE employees.titles DROP INDEX emp_no; 这样就可以专心分析索引PRIMARY的行为了。 情况一：全列匹配。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no=’10001’ AND title=’Senior Engineer’ AND from_date=’1986-06-26’;+—-+————-+——–+——-+—————+———+———+——————-+——+——-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——————-+——+——-+| 1 | SIMPLE | titles | const | PRIMARY | PRIMARY | 59 | const,const,const | 1 | |+—-+————-+——–+——-+—————+———+———+——————-+——+——-+ 很明显，当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒： EXPLAIN SELECT * FROM employees.titles WHERE from_date=’1986-06-26’ AND emp_no=’10001’ AND title=’Senior Engineer’;+—-+————-+——–+——-+—————+———+———+——————-+——+——-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——————-+——+——-+| 1 | SIMPLE | titles | const | PRIMARY | PRIMARY | 59 | const,const,const | 1 | |+—-+————-+——–+——-+—————+———+———+——————-+——+——-+ 效果是一样的。 情况二：最左前缀匹配。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no=’10001’;+—-+————-+——–+——+—————+———+———+——-+——+——-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——+—————+———+———+——-+——+——-+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | |+—-+————-+——–+——+—————+———+———+——-+——+——-+ 当查询条件精确匹配索引的左边连续一个或几个列时，如&lt;emp_no&gt;或&lt;emp_no, title&gt;，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。 情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no=’10001’ AND from_date=’1986-06-26’;+—-+————-+——–+——+—————+———+———+——-+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——+—————+———+———+——-+——+————-+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | Using where |+—-+————-+——–+——+—————+———+———+——-+——+————-+ 此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引&lt;emp_no, from_date&gt;，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。 首先我们看下title一共有几种不同的值： SELECT DISTINCT(title) FROM employees.titles;+——————–+| title |+——————–+| Senior Engineer || Staff || Engineer || Senior Staff || Assistant Engineer || Technique Leader || Manager |+——————–+ 只有7种。在这种成为“坑”的列值比较少的情况下，可以考虑用“IN”来填补这个“坑”从而形成最左前缀： EXPLAIN SELECT * FROM employees.titlesWHERE emp_no=’10001’AND title IN (‘Senior Engineer’, ‘Staff’, ‘Engineer’, ‘Senior Staff’, ‘Assistant Engineer’, ‘Technique Leader’, ‘Manager’)AND from_date=’1986-06-26’;+—-+————-+——–+——-+—————+———+———+——+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——+——+————-+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 7 | Using where |+—-+————-+——–+——-+—————+———+———+——+——+————-+ 这次key_len为59，说明索引被用全了，但是从type和rows看出IN实际上执行了一个range查询，这里检查了7个key。看下两种查询的性能比较： SHOW PROFILES;+———-+————+——————————————————————————-+| Query_ID | Duration | Query |+———-+————+——————————————————————————-+| 10 | 0.00058000 | SELECT FROM employees.titles WHERE emp_no=’10001’ AND from_date=’1986-06-26’|| 11 | 0.00052500 | SELECT FROM employees.titles WHERE emp_no=’10001’ AND title IN … |+———-+————+——————————————————————————-+ “填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。 情况四：查询条件没有指定索引第一列。 EXPLAIN SELECT * FROM employees.titles WHERE from_date=’1986-06-26’;+—-+————-+——–+——+—————+——+———+——+——–+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——+—————+——+———+——+——–+————-+| 1 | SIMPLE | titles | ALL | NULL | NULL | NULL | NULL | 443308 | Using where |+—-+————-+——–+——+—————+——+———+——+——–+————-+ 由于不是最左前缀，索引这样的查询显然用不到索引。 情况五：匹配某列的前缀字符串。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no=’10001’ AND title LIKE ‘Senior%’;+—-+————-+——–+——-+—————+———+———+——+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——+——+————-+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 56 | NULL | 1 | Using where |+—-+————-+——–+——-+—————+———+———+——+——+————-+ 此时可以用到索引，但是如果通配符不是只出现在末尾，则无法使用索引。（原文表述有误，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀） 情况六：范围查询。 EXPLAIN SELECT * FROM employees.titles WHERE emp_no &lt; ‘10010’ and title=’Senior Engineer’;+—-+————-+——–+——-+—————+———+———+——+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——+——+————-+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 4 | NULL | 16 | Using where |+—-+————-+——–+——-+—————+———+———+——+——+————-+ 范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。 EXPLAIN SELECT * FROM employees.titlesWHERE emp_no &lt; ‘10010’AND title=’Senior Engineer’AND from_date BETWEEN ‘1986-01-01’ AND ‘1986-12-31’;+—-+————-+——–+——-+—————+———+———+——+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——+——+————-+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 4 | NULL | 16 | Using where |+—-+————-+——–+——-+—————+———+———+——+——+————-+ 可以看到索引对第二个范围索引无能为力。这里特别要说明MySQL一个有意思的地方，那就是仅用explain可能无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询，例如下面的查询： EXPLAIN SELECT * FROM employees.titlesWHERE emp_no BETWEEN ‘10001’ AND ‘10010’AND title=’Senior Engineer’AND from_date BETWEEN ‘1986-01-01’ AND ‘1986-12-31’;+—-+————-+——–+——-+—————+———+———+——+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——-+—————+———+———+——+——+————-+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 16 | Using where |+—-+————-+——–+——-+—————+———+———+——+——+————-+ 看起来是用了两个范围查询，但作用于emp_no上的“BETWEEN”实际上相当于“IN”，也就是说emp_no实际是多值精确匹配。可以看到这个查询用到了索引全部三个列。因此在MySQL中要谨慎地区分多值匹配和范围匹配，否则会对MySQL的行为产生困惑。 情况七：查询条件中含有函数或表达式。 很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）。例如： EXPLAIN SELECT * FROM employees.titles WHERE emp_no=’10001’ AND left(title, 6)=’Senior’;+—-+————-+——–+——+—————+———+———+——-+——+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——+—————+———+———+——-+——+————-+| 1 | SIMPLE | titles | ref | PRIMARY | PRIMARY | 4 | const | 1 | Using where |+—-+————-+——–+——+—————+———+———+——-+——+————-+ 虽然这个查询和情况五中功能相同，但是由于使用了函数left，则无法为title列应用索引，而情况五中用LIKE则可以。再如： EXPLAIN SELECT * FROM employees.titles WHERE emp_no - 1=’10000’;+—-+————-+——–+——+—————+——+———+——+——–+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+——–+——+—————+——+———+——+——–+————-+| 1 | SIMPLE | titles | ALL | NULL | NULL | NULL | NULL | 443308 | Using where |+—-+————-+——–+——+—————+——+———+——+——–+————-+ 显然这个查询等价于查询emp_no为10001的函数，但是由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。 索引选择性与前缀索引 既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。 第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。 另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值： Index Selectivity = Cardinality / #T 显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。例如，上文用到的employees.titles表，如果title字段经常被单独查询，是否需要建索引，我们看一下它的选择性： SELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;+————-+| Selectivity |+————-+| 0.0000 |+————-+ title的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。 有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。下面以employees.employees表为例介绍前缀索引的选择和使用。 从图12可以看到employees表只有一个索引&lt;emp_no&gt;，那么如果我们想按名字搜索一个人，就只能全表扫描了： EXPLAIN SELECT * FROM employees.employees WHERE first_name=’Eric’ AND last_name=’Anido’;+—-+————-+———–+——+—————+——+———+——+——–+————-+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+—-+————-+———–+——+—————+——+———+——+——–+————-+| 1 | SIMPLE | employees | ALL | NULL | NULL | NULL | NULL | 300024 | Using where |+—-+————-+———–+——+—————+——+———+——+——–+————-+ 如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建&lt;first_name&gt;或&lt;first_name, last_name&gt;，看下两个索引的选择性： SELECT count(DISTINCT(first_name))/count() AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.0042 |+————-+SELECT count(DISTINCT(concat(first_name, last_name)))/count() AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.9313 |+————-+ &lt;first_name&gt;显然选择性太低，&lt;first_name, last_name&gt;选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如&lt;first_name, left(last_name, 3)&gt;，看看其选择性： SELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count(*) AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.7879 |+————-+ 选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4： SELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;+————-+| Selectivity |+————-+| 0.9007 |+————-+ 这时选择性已经很理想了，而这个索引的长度只有18，比&lt;first_name, last_name&gt;短了接近一半，我们把这个前缀索引 建上： ALTER TABLE employees.employeesADD INDEX first_name_last_name4 (first_name, last_name(4)); 此时再执行一遍按名字查询，比较分析一下与建索引前的结果： SHOW PROFILES;+———-+————+———————————————————————————+| Query_ID | Duration | Query |+———-+————+———————————————————————————+| 87 | 0.11941700 | SELECT FROM employees.employees WHERE first_name=’Eric’ AND last_name=’Anido’ || 90 | 0.00092400 | SELECT FROM employees.employees WHERE first_name=’Eric’ AND last_name=’Anido’ |+———-+————+———————————————————————————+ 性能的提升是显著的，查询速度提高了120多倍。 前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。 InnoDB的主键选择与插入优化 在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。 经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。 上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。 如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示： 图13 这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置： 图14 此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。 因此，只要可以，请尽量在InnoDB上采用自增字段做主键。 后记 这篇文章断断续续写了半个月，主要内容就是上面这些了。不可否认，这篇文章在一定程度上有纸上谈兵之嫌，因为我本人对MySQL的使用属于菜鸟级别，更没有太多数据库调优的经验，在这里大谈数据库索引调优有点大言不惭。就当是我个人的一篇学习笔记了。 其实数据库索引调优是一项技术活，不能仅仅靠理论，因为实际情况千变万化，而且MySQL本身存在很复杂的机制，如查询优化策略和各种引擎的实现差异等都会使情况变得更加复杂。但同时这些理论是索引调优的基础，只有在明白理论的基础上，才能对调优策略进行合理推断并了解其背后的机制，然后结合实践中不断的实验和摸索，从而真正达到高效使用MySQL索引的目的。 另外，MySQL索引及其优化涵盖范围非常广，本文只是涉及到其中一部分。如与排序（ORDER BY）相关的索引优化及覆盖索引（Covering index）的话题本文并未涉及，同时除B-Tree索引外MySQL还根据不同引擎支持的哈希索引、全文索引等等本文也并未涉及。如果有机会，希望再对本文未涉及的部分进行补充吧。 MySQL索引背后的数据结构及算法原理 作者 张洋 | 发布于 2011-10-18]]></content>
      <tags>
        <tag>MySQL, Index, Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Difference between Process and Thread]]></title>
    <url>%2F2020%2F02%2F05%2FThe-Difference-between-Process-and-Thread%2F</url>
    <content type="text"><![CDATA[对于操作系统而言，进程是整个现代操作系统的根本，操作系統是以进程为单位执行任务。随着技术发展，在执行一些细小任务，且本身无需分配单独资源时，进程的实现机制依然会繁琐的将资源分割，这样造成浪费，而且还消耗时间，所以就有了专门的多任务技术被创造出来——线程。 线程的特点就是在不需要独立资源的情况下就可以运行。如此一来会极大节省资源开销，以及处理时间。 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 我们有如下对比图片： Tables Process 进程 Thread线程 引入目的 可以并发执行，提高资源的利用率和系统吞吐量 调高并发执行的速度，进一步提高资源的利用率和系统吞吐量 并发性 较低 较高 基本属性（调度） 资源拥有的基本单位是进程，独立调度/分配的基本单位是进程 资源拥有的基本单位是进程，独立调度/分配的基本单位是线程 基本状态 就绪；执行；等待 就绪；执行；等待 系统开销 创建/撤销/切换时开销较大 创建/撤销/切换时开销较小 系统操作 创建；撤销；切换 创建；撤销；切换 存在状态 进程控制块PCB 进程控制块PCB，进程控制块TCB 但是对于 Linux 来说，它只支持轻量级进程，不支持线程，对于 Linux 而言： 系统启动后的 第一个进程是 init，它的 PID 是 1。init 是唯一一个由系统内核直接运行的进程。 除了 init 之外，每个进程都有 父进程（PPID 标识） 每个进程还有四个 与用户和组相关的识别号1.实际用户识别号 （real user ID，RUID）2.实际组识别号 （real group ID，RGID）3.有效用户识别号 （effect user ID，EUID）4.有效组识别号 （effect group ID，EGID ######在 Linux 内核 2.4 版以前，线程的实现和管理方式就是完全按照进程方式实现的。在 2.6 版内核以后才有了单独的线程实现,为了弥补不支持线程的缺陷，Linux 引入线程组的概念，即该组中第一个轻量级进程的 PID，它被存入进程描述符的 tgid 字段中。getpid()系统调用返回当前进程的 tgid 值而不是 pid 值，因此，一个多线程应用的所有线程共享相同的 PID。 fork()系统调用是Unix下以自身进程创建子进程的系统调用，一次调用，两次返回，如果返回是0，则是子进程，如果返回值&gt;0，则是父进程（返回值是子进程的pid）,如果fork出错，返回一个负值. 在fork()的调用处，整个父进程空间会原模原样地复制到子进程中，包括指令，变量值，程序调用栈，环境变量，缓冲区，等等。 fork()函数会把它所在语句以后的语句复制到一个子进程里，单独执行。 如果printf函数最后没有&quot;\n&quot;，则输出缓冲区不会被立即清空，而fork函数会把输出缓冲区里的内容也都复制到子进程里 进程的执行过程是线状的，尽管中间会发生中断或暂停，但该进程所拥有的资源只为该线状执行过程服务。一旦发生进程上下文切换，这些资源都是要被保护起来的。 线程的改变只代表了 CPU 执行过程的改变，而没有发生进程所拥有的资源变化。 计算机内的软硬件资源的分配与线程无关，线程只能共享它所属进程的资源。 进程拥有一个完整的虚拟地址空间，不依赖于线程而独立存在；反之，线程是进程的一部分，没有自己的地址空间，与进程内的其他线程一起共享分配给该进程的所有资源。 线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源。 文章来源:进程和线程有哪些区别与联系？力扣（LeetCode）]]></content>
      <tags>
        <tag>Operation System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Everything About HashMap]]></title>
    <url>%2F2020%2F02%2F04%2FEverything-About-HashMap%2F</url>
    <content type="text"><![CDATA[1.为什么用HashMap？ HashMap是一个散列桶（数组和链表），它存储的内容是键值对(key-value)映射。 HashMap采用了数组和链表的数据结构，能在查询和修改方便继承了数组的线性查找和链表的寻址修改。数组是用来确定桶的位置，利用元素的key的hash值对数组长度取模得到. 链表是用来解决hash冲突问题，当出现hash值一样的情形，就在数组上的对应位置形成一条链表。 用LinkedList代替数组结构可以么? 当然是可以的，稍微说明一下，此题的意思是，源码中是这样的 12345Entry[] table = new Entry[capacity];Entry就是一个链表节点。 那下面这样表示，是否可行?List&lt;Entry&gt; table = new LinkedList&lt;Entry&gt;(); 答案很明显，是可以的。 既然是可以的,为什么HashMap不用LinkedList,而选用数组?因为用数组效率最高！在HashMap中，定位桶的位置是利用元素的key的哈希值对数组长度取模得到。此时，我们已得到桶的位置。显然数组的查找效率比LinkedList大。 那ArrayList，底层也是数组，查找也快啊，为啥不用ArrayList?因为采用基本数组结构，扩容机制可以自己定义，HashMap中数组扩容刚好是2的次幂，在做取模运算的效率高。 而ArrayList的扩容机制是1.5倍扩容，那ArrayList为什么是1.5倍扩容这就不在本文说明了。 HashMap是非synchronized，所以HashMap很快。 HashMap可以接受null键和值，而Hashtable则不能（原因就是equlas()方法需要对象，因为HashMap是后出的API经过处理才可以） 当链表转为红黑树后，什么时候退化为链表?为6的时候退转为链表。中间有个差值7可以防止链表和树之间频繁的转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。 2.HashMap的工作原理是什么？HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，计算并返回的hashCode是用于找到Map数组的bucket位置来储存Node 对象。这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Node。 以下是HashMap初始化 ，简单模拟数据结构12345678910111213Node[] table=new Node[16] 散列桶初始化，table class Node &#123; hash;//hash值 key;//键 value;//值 node next;//用于指向链表的下一层（产生冲突，用拉链法） &#125; put过程（JDK1.8版） 对Key用HashCode()求Hash值，然后再计算下标 如果没有碰撞，直接放入桶中（碰撞的意思是计算得到的Hash值相同，需要放到同一个bucket中） 如果碰撞了，以链表的方式链接到后面 如果链表长度超过阀值( TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于6，就把红黑树转回链表 如果节点已经存在就替换旧值 如果桶满了(容量16*加载因子0.75)，就需要 resize（扩容2倍后重排） 扩容后，元素要么是在原位置，要么是在原位置再移动2次幂的位置，且链表顺序不变。 Get过程(考虑特殊情况如果两个键的hashcode相同，你如何获取值对象？)当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。 3.有什么方法可以减少碰撞？ 扰动函数可以减少碰撞，原理是如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这就意味着存链表结构减小，这样取值的话就不会频繁调用equal方法，这样就能提高HashMap的性能。（扰动即Hash方法内部的算法实现，目的是让不同对象返回不同hashcode。） 使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。为什么String, Interger这样的wrapper类适合作为键？因为String是final的，而且已经重写了equals()和hashCode()方法了。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。 4.HashMap中hash函数怎么是是实现的? 我们可以看到在hashmap中要找到某个元素，需要根据key的hash值来求得对应数组中的位置。如何计算这个位置就是hash算法。前面说过hashmap的数据结构是数组和链表的结合，所以我们当然希望这个hashmap里面的元素位置尽量的分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，而不用再去遍历链表。 所以我们首先想到的就是把hashcode对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，“模”运算的消耗还是比较大的，能不能找一种更快速，消耗更小的方式，我们来看看JDK1.8的源码是怎么做的.1234567891011static final int hash(Object key) &#123; if (key == null)&#123; return 0; &#125; int h; h=key.hashCode()；返回散列值也就是hashcode // ^ ：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 //其中n是数组的长度，即Map的数组部分初始化长度 return (n-1)&amp;(h ^ (h &gt;&gt;&gt; 16));&#125; 高16位异或低16位以后，进行取模运算1.高16bit不变，低16bit和高16bit做了一个异或(得到的HashCode转化为32位的二进制，前16位和后16位低16bit和高16bit做了一个异或)2.(n·1)&amp;hash=-&gt;得到下标 为什么扩容是2的次幂? HashMap为了存取高效，要尽量较少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就在把数据存到哪个链表中的算法这个算法实际就是取模，hash%length。 但是，大家都知道这种运算不如位移运算快。因此，源码中做了优化hash&amp;(length-1)。 也就是说hash%length==hash&amp;(length-1) 5.拉链法导致的链表过深问题为什么不用二叉查找树代替，而选择红黑树？为什么不一直使用红黑树？之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持“平衡”是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于8的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。 6.对红黑树的见解？ 节点是红色或黑色。 根节点是黑色。 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 7.解决hash 碰撞还有那些办法？比较出名的有四种 (1)开放定址法 (2)链地址法 (3)再哈希法 (4)公共溢出区域法 开放定址法开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 链地址法将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 再哈希法当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。 建立公共溢出区将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。 下面给一个线性探查法的例子 问题：已知一组关键字为(26，36，41，38，44，15，68，12，06，51)，用除余法构造散列函数，用线性探查法解决冲突构造这组关键字的散列表 解答：为了减少冲突，通常令装填因子α由除余法因子是13的散列函数计算出的上述关键字序列的散列地址为(0，10，2，12，5，2，3，12，6，12)。 前5个关键字插入时，其相应的地址均为开放地址，故将它们直接插入T[0]，T[10)，T[2]，T[12]和T[5]中。 当插入第6个关键字15时，其散列地址2(即h(15)=15％13=2)已被关键字41(15和41互为同义词)占用。故探查h1=(2+1)％13=3，此地址开放，所以将15放入T[3]中。 当插入第7个关键字68时，其散列地址3已被非同义词15先占用，故将其插入到T[4]中。 当插入第8个关键字12时，散列地址12已被同义词38占用，故探查hl=(12+1)％13=0，而T[0]亦被26占用，再探查h2=(12+2)％13=1，此地址开放，可将12插入其中。 类似地，第9个关键字06直接插入T[6]中；而最后一个关键字51插人时，因探查的地址12，0，1，…，6均非空，故51插入T[7]中。 8.如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。这个值只可能在两个地方，一个是原下标的位置，另一种是在下标为 &lt;原下标+原容量&gt; 的位置 9.重新调整HashMap大小存在什么问题吗？ 当扩容重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。因为直接插入的效率更高。如果条件竞争发生了，那么就死循环了。(多线程的环境下不使用HashMap）。 为什么多线程会导致死循环，它是怎么发生的？HashMap的容量是有限的。当经过多次元素插入，使得HashMap达到一定饱和度时，Key映射位置发生冲突的几率会逐渐提高。这时候，HashMap需要扩展它的长度，也就是进行Resize。1.扩容：创建一个新的Entry空数组，长度是原数组的2倍。2.ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组。 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环。 在HashMap1.7之前是头插法，在扩容的过程中，可能会造成一个resize()的方法，然后调用transfer()方法，把里面的Entry进行了Rehash，在过程中，可能会造成链表的循环，在一下次Get()中出现死循环，或者出现没有加锁，所以数据不安全 10.HashTable数组 + 链表方式存储默认容量： 11(质数为宜) Put: 对key的hashCode()做hash运算，计算index; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树(JDK1.8中的改动)； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load factor*current capacity)，就要resize。 索引计算 : （key.hashCode() &amp; 0x7FFFFFFF）% table.length 若在链表中找到了，则替换旧值，若未找到则继续 当总元素个数超过容量*加载因子时，扩容为原来 2 倍并重新散列。 将新元素加到链表头部,对修改 Hashtable 内部共享数据的方法添加了 synchronized，保证线程安全。Get:对key的hashCode()做hash运算，计算index; 如果在bucket里的第一个节点里直接命中，则直接返回； 如果有冲突，则通过key.equals(k)去查找对应的Entry;• 若为树，则在树中通过key.equals(k)查找，O(logn)；• 若为链表，则在链表中通过key.equals(k)查找，O(n)。 11.HashMap ，HashTable 区别 默认容量不同。扩容不同 线程安全性，HashTable 安全 效率不同 HashTable 要慢因为加锁 12.可以使用CocurrentHashMap来代替Hashtable吗？我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。它们都可以用于多线程的环境，但是当Hashtable的大小增加到一定的时候，性能会急剧下降，因为迭代时需要被锁定很长的时间。因为ConcurrentHashMap引入了分割(segmentation)，不论它变得多么大，仅仅需要锁定map的某个部分，而其它的线程不需要等到迭代完成才能访问map。简而言之，在迭代的过程中，ConcurrentHashMap仅仅锁定map的某个部分，而Hashtable则会锁定整个map。 13.CocurrentHashMap（1.8） 其中抛弃了原有的 Segment 分段锁，而采用了CAS + synchronized来保证并发安全性。 其中的 val next 都用了 volatile修饰，保证了可见性 最大特点是引入了 CAS（借助 Unsafe 来实现【native code】）CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 CAS 会出现的问题：ABA解决：对变量增加一个版本号，每次修改，版本号加 1，比较的时候比较版本号。####Put过程 根据 key 计算出 hashcode 。判断是否需要进行初始化。 通过 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 Get过程 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 都不满足那就按照链表的方式遍历获取值。 14.TreeMapTreeMap 则是基于红黑树的一种提供顺序访问的 Map，和HashMap不同，它的get、put、remove之类操作都是O(logn)的复杂度，具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断 15.hash算法是干嘛的？还知道哪些hash算法？Hash函数是指把一个大范围映射到一个小范围。把大范围映射到一个小范围的目的往往是为了节省空间，使得数据容易保存。比较出名的算法有SHA,MD4、MD5等 说说String中hashcode的实现?123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; String类中的hashCode计算方法还是比较简单的，就是以31为权，每一位为字符的ASCII值进行运算，用自然溢出来等效取模。 哈希计算公式可以计为+ s[1]*31^(n-2) + ... + s[n-1]```1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859* 那为什么以31为质数呢?主要是因为31是一个奇质数，所以```31*i=32*i-i=(i&lt;&lt;5)-i```，这种位移与减法结合的计算相比一般的运算快很多。## 16.健可以为Null值么?可以，key为null的时候，hash算法最后的值以0来计算，也就是放在数组的第一个位置。## 17.一般用什么作为HashMap的key?一般用Integer、String这种不可变类当HashMap当key，而且String最为常用。• (1) 因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。• (2) 因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的,这些类已经很规范的覆写了hashCode()以及equals()方法。## Hashcode* 一、hashCode简介public int hashCode()：``hashCode``是根类Obeject中的方法。默认情况下，Object中的``hashCode() ``返回对象的32位jvm内存地址。也就是说如果对象不重写该方法，则返回相应对象的32为JVM内存地址。* 二、hashCode注意点关于hashCode方法，一致的约定是：1、重写了``euqls``方法的对象必须同时重写``hashCode()``方法。2、如果两个对象equals相等，那么这两个对象的HashCode一定也相同3、如果两个对象的HashCode相同，不代表两个对象就相同，只能说明这两个对象在散列存储结构中，存放于同一个位置* 三、hashCode作用从Object角度看，JVM每new一个Object，它都会将这个Object丢到一个Hash表中去，这样的话，下次做Object的比较或者取这个对象的时候（读取过程），它会根据对象的HashCode再从Hash表中取这个对象。这样做的目的是提高取对象的效率。若HashCode相同再去调用equal。HashCode是用于查找使用的，而equals是用于比较两个对象的是否相等的。* 四、为什么重写实际开发的过程中在hashmap或者hashset里如果不重写的hashcode和equals方法的话会导致我们存对象的时候，把对象存进去了，取的时候却取不到想要的对象。重写了hashcode和equals方法可以迅速的在hashmap中找到键的位置；#### **重写hashcode是为了保证相同的对象会有相同的hashcode；**#### **重写equals是为了保证在发生冲突的情况下取得到Entry对象（也可以理解是key或是元素）**；存在一个table数组，里面每个元素都是一个node链表，当添加一个元素（key-value）时，就首先计算元素key的hash值，通过table的长度和key的hash值进行与运算得到一个index，以此确定插入数组中的位置，但是可能存在同一hash值的元素已经被放在数组同一位置了，这时就把这个元素添加到同一hash值的node链表的链尾，他们在数组的同一位置，但是形成了链表，同一各链表上的Hash值是相同的，所以说数组存放的是链表。而当链表长度大于等于8时，链表就可能转换为红黑树，这样大大提高了查找的效率。&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20191102133424361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM1ODMzMTE=,size_16,color_FFFFFF,t_70&quot; alt=&quot;存储结构&quot; /&gt;&lt;/p&gt;```Javastatic class Node&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; &#123; final int hash; final K key; V value; Node&amp;lt;K,V&amp;gt; next; //可以看得出这是一个链表 Node(int hash, K key, V value, Node&amp;lt;K,V&amp;gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; * * * &#125;transient Node&lt;K,V&gt;[] table; HashMap内部包含一个Node类型的数组table，Node由Map.Entry继承而来。Node存储着键值对。它包含四个字段，从next字段我们可以看出node是一个链表。table数组中的每个位置都可以当做一个桶，一个桶存放一个链表。HashMap使用拉链法来解决冲突，同一个存放散列值相同的Node。数据域123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static final long serialVersionUID = 362498820763181265L; // 初始化容量，初始化有16个桶static final int DEFAULT_INITIAL_CAPACITY = 1 &amp;lt;&amp;lt; 4; // aka 16 // 最大容量 1 073 741 824, 10亿多static final int MAXIMUM_CAPACITY = 1 &amp;lt;&amp;lt; 30;// 默认的负载因子。因此初始情况下，当键值对的数量大于 16 * 0.75 = 12 时，就会触发扩容。static final float DEFAULT_LOAD_FACTOR = 0.75f;// 当put()一个元素到某个桶，其链表长度达到8时有可能将链表转换为红黑树 static final int TREEIFY_THRESHOLD = 8; // 在hashMap扩容时，如果发现链表长度小于等于6，则会由红黑树重新退化为链表。static final int UNTREEIFY_THRESHOLD = 6; // 在转变成红黑树树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换，否者直接扩容。这是为了避免在HashMap建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组 transient Node&amp;lt;k,v&amp;gt;[] table;// 存放元素的个数transient int size;// 被修改的次数fast-fail机制 transient int modCount;// 临界值 当实际大小(容量*填充比)超过临界值时，会进行扩容 int threshold;// 填充比final float loadFactor;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id="构造函数"&gt;构造函数&lt;/h4&gt;&lt;pre class="java"&gt;&lt;code&gt;public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &amp;lt; 0) throw new IllegalArgumentException(&amp;quot;Illegal initial capacity: &amp;quot; + initialCapacity); if (initialCapacity &amp;gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &amp;lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&amp;quot;Illegal load factor: &amp;quot; + loadFactor); this.loadFactor = loadFactor; // tableSizeFor(initialCapacity)方法计算出接近initialCapacity // 参数的2^n来作为初始化容量。 this.threshold = tableSizeFor(initialCapacity);&#125;public HashMap(Map&amp;lt;? extends K, ? extends V&amp;gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125;HashMap构造函数允许用户传入容量不是2的n次方，因为它可以自动地将传入的容量转换为2的n次方。### Put()源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; // “扰动函数”。参考 https://www.cnblogs.com/zhengwang/p/8136164.html return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16);&#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; HashMap.Node&amp;lt;K,V&amp;gt;[] tab; HashMap.Node&amp;lt;K,V&amp;gt; p; int n, i; // 未初始化则初始化table if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 通过table的长度和hash与运算得到一个index， // 然后判断table数组下标为index处是否已经存在node。 if ((p = tab[i = (n - 1) &amp;amp; hash]) == null) // 如果table数组下标为index处为空则新创建一个node放在该处 tab[i] = newNode(hash, key, value, null); else &#123; // 运行到这代表table数组下标为index处已经存在node，即发生了碰撞 HashMap.Node&amp;lt;K,V&amp;gt; e; K k; // 检查这个node的key是否跟插入的key是否相同。 if (p.hash == hash &amp;amp;&amp;amp; ((k = p.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k)))) e = p; // 检查这个node是否已经是一个红黑树 else if (p instanceof TreeNode) // 如果这个node已经是一个红黑树则继续往树种添加节点 e = ((HashMap.TreeNode&amp;lt;K,V&amp;gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; // 在这里循环遍历node链表 // 判断是否到达链表尾 if ((e = p.next) == null) &#123; // 到达链表尾，直接把新node插入链表，插入链表尾部，在jdk8之前是头插法 p.next = newNode(hash, key, value, null); if (binCount &amp;gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 如果node链表的长度大于等于8则可能把这个node转换为红黑树 treeifyBin(tab, hash); break; &#125; // 检查这个node的key是否跟插入的key是否相同。 if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k)))) break; p = e; &#125; &#125; // 当插入key存在，则更新value值并返回旧value if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; // 修改次数++ ++modCount; // 如果当前大小大于门限，门限原本是初始容量*0.75 if (++size &amp;gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125;下面简单说下put()流程：判断键值对数组table[]是否为空或为null，否则以默认大小resize()；根据键key计算hash值与table的长度进行与运算得到插入的数组索引 index，如果tab[index] == null，直接根据key-value新建node添加，否则转入3判断当前数组中处理hash冲突的方式为链表还是红黑树(check第一个节点类型即可),分别处理 为啥头插法为什么要换成尾插：jdk1.7时候用头插法可能是考虑到了一个所谓的热点数据的点(新插入的数据可能会更早用到)；找到链表尾部的时间复杂度是 O(n)，或者需要使用额外的内存地址来保存链表尾部的位置，头插法可以节省插入耗时。但是在扩容时会改变链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题。 从putVal()源码可以看出，HashMap并没有对null的键值对做限制（hash值设为0），即HashMap允许插入键尾null的键值对。但在JDK1.8之前HashMap使用第0个node存放键为null的键值对。 确定node下标：通过table的长度和key的hash进行与运算得到一个index。 在转变成红黑树树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换，否者直接扩容。这是为了避免在HashMap建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。 大多数人不知道的：HashMap链表成环的原因和解决方案get()操作源码解析1234567891011121314151617181920212223242526272829303132333435public V get(Object key) &#123; HashMap.Node&amp;lt;K,V&amp;gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final HashMap.Node&amp;lt;K,V&amp;gt; getNode(int hash, Object key) &#123; HashMap.Node&amp;lt;K,V&amp;gt;[] tab; HashMap.Node&amp;lt;K,V&amp;gt; first, e; int n; K k; // table不为空 if ((tab = table) != null &amp;amp;&amp;amp; (n = tab.length) &amp;gt; 0 &amp;amp;&amp;amp; // 通过table的长度和hash与运算得到一个index，table // 下标位index处的元素不为空，即元素为node链表 (first = tab[(n - 1) &amp;amp; hash]) != null) &#123; // 首先判断node链表中中第一个节点 if (first.hash == hash &amp;amp;&amp;amp; // always check first node // 分别判断key为null和key不为null的情况 ((k = first.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k)))) // key相等则返回第一个 return first; // 第一个节点key不同且node链表不止包含一个节点 if ((e = first.next) != null) &#123; // 判断node链表是否转为红黑树。 if (first instanceof HashMap.TreeNode) // 则在红黑树中进行查找。 return ((HashMap.TreeNode&amp;lt;K,V&amp;gt;)first).getTreeNode(hash, key); do &#123; // 循环遍历node链表中的节点，判断key是否相等 if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; // key在table中不存在则返回null。 return null; &#125; get(key)方法首先获取key的hash值， 计算hash &amp; (table.len - 1)得到在链表数组中的位置， 先判断node链表（桶）中的第一个节点的key是否与参数key相等， 不等则判断是否已经转为红黑树，若转为红黑树则在红黑树中查找， 如没有转为红黑树就遍历后面的链表找到相同的key值返回对应的Value值即可。 resize()操作源码解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112// 初始化或者扩容之后的元素调整 final HashMap.Node&amp;lt;K,V&amp;gt;[] resize() &#123; // 获取旧table HashMap.Node&amp;lt;K,V&amp;gt;[] oldTab = table; // 旧table容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 旧table扩容临界值 int oldThr = threshold; // 定义新table容量和临界值 int newCap, newThr = 0; // 如果原table不为空 if (oldCap &amp;gt; 0) &#123; // 如果table容量达到最大值，则修改临界值为Integer.MAX_VALUE // MAXIMUM_CAPACITY = 1 &amp;lt;&amp;lt; 30; // Integer.MAX_VALUE = 1 &amp;lt;&amp;lt; 31 - 1; if (oldCap &amp;gt;= MAXIMUM_CAPACITY) &#123; // Map达到最大容量，这时还要向map中放数据，则直接设置临界值为整数的最大值 // 在容量没有达到最大值之前不会再resize。 threshold = Integer.MAX_VALUE; // 结束操作 return oldTab; &#125; // 下面就是扩容操作（2倍） else if ((newCap = oldCap &amp;lt;&amp;lt; 1) &amp;lt; MAXIMUM_CAPACITY &amp;amp;&amp;amp; oldCap &amp;gt;= DEFAULT_INITIAL_CAPACITY) // 临界值也变为两倍 newThr = oldThr &amp;lt;&amp;lt; 1; // double threshold &#125; else if (oldThr &amp;gt; 0) // initial capacity was placed in threshold /* * 进入此if证明创建HashMap时用的带参构造：public HashMap(int initialCapacity) * 或 public HashMap(int initialCapacity, float loadFactor) * 注：带参的构造中initialCapacity（初始容量值）不管是输入几都会通过 * tableSizeFor(initialCapacity)方法计算出接近initialCapacity * 参数的2^n来作为初始化容量。 * 所以实际创建的容量并不等于设置的初始容量。 */ newCap = oldThr; else &#123; // zero initial threshold signifies using defaults // 进入此if证明创建map时用的无参构造： // 然后将参数newCap（新的容量）、newThr(新的扩容阀界值)进行初始化 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; // 进入这代表有两种可能。 // 1. 说明old table容量大于0但是小于16. // 2. 创建HashMap时用的带参构造，根据loadFactor计算临界值。 float ft = (float)newCap * loadFactor; newThr = (newCap &amp;lt; MAXIMUM_CAPACITY &amp;amp;&amp;amp; ft &amp;lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 修改临界值 threshold = newThr; @SuppressWarnings(&#123;&amp;quot;rawtypes&amp;quot;,&amp;quot;unchecked&amp;quot;&#125;) // 根据新的容量生成新的 table HashMap.Node&amp;lt;K,V&amp;gt;[] newTab = (HashMap.Node&amp;lt;K,V&amp;gt;[])new HashMap.Node[newCap]; // 替换成新的table table = newTab; // 如果oldTab不为null说明是扩容，否则直接返回newTab if (oldTab != null) &#123; /* 遍历原来的table */ for (int j = 0; j &amp;lt; oldCap; ++j) &#123; HashMap.Node&amp;lt;K,V&amp;gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 判断这个桶（链表）中就只有一个节点 if (e.next == null) // 根据新的容量重新计算在table中的位置index，并把当前元素赋值给他。 newTab[e.hash &amp;amp; (newCap - 1)] = e; // 判断这个链表是否已经转为红黑树 else if (e instanceof HashMap.TreeNode) // 在split函数中可能由于红黑树的长度小于等于UNTREEIFY_THRESHOLD（6） // 则把红黑树重新转为链表 ((HashMap.TreeNode&amp;lt;K,V&amp;gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 运行到这里证明桶中有多个节点。 HashMap.Node&amp;lt;K,V&amp;gt; loHead = null, loTail = null; HashMap.Node&amp;lt;K,V&amp;gt; hiHead = null, hiTail = null; HashMap.Node&amp;lt;K,V&amp;gt; next; do &#123; // 对桶进行遍历 next = e.next; if ((e.hash &amp;amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; HashMap 的工作原理是什么?HashMap基于hashing原理，我们通过put()和get()方法存储和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来存储值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会存储在链表的第一个节点，链接原先的对象节点，HashMap在每个链表节点中存储键值对对象。 快速失败 (fail-fast) 和安全失败 (fail-safe) 的区别是什么？ 1、快速失败（fail-fast）在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行修改（增加、删除、修改），则会抛出Concurrent Modification Exception.原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个modCount变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。注意：这里异常的抛出条件是检测到modCount!=expectedmodCount这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。 2、安全失败（fail-safe）采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception,但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。 HashMap？ConcurrentHashMap？相信看完这篇没人能难住你]]></content>
      <tags>
        <tag>Analyst of SourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithms, Part I | Princeton Online]]></title>
    <url>%2F2020%2F01%2F16%2FAlgorithms-Part-I-Princeton-Online%2F</url>
    <content type="text"><![CDATA[Princeton Online courseYou can find all the code and comments details in this RepositoryWhat algorithms and data structures will be covered in this course?The first part will focus on the basic data structure, sorting, and searching. Topics include: parallel search algorithm, binary search, stack, queue, backpack, insert sort, select sort, hill sort, fast sort, three-way fast sort, merge sort, heap sort, binary heap, binary search tree, red-black tree , Split link and linear probe hash tables, Graham scans, kd trees. The second part will focus on graph and string processing algorithms. Topics include: depth-first search, width-first search, topology sorting, Kosaraju-Sharir algorithm, Kruskal algorithm, Prim algorithm, Dijkistra algorithm, Bellman-Ford algorithm, Ford-Fulkerson algorithm, LSD cardinality ranking algorithm, MSD cardinality ranking algorithm, three-way Cardinality fast sorting algorithm, multi-path trie algorithm, ternary search trie algorithm, Knuth-Morris-Pratt algorithm, Boyer-Moore algorithm, Rabin-Karp algorithm, regular matching, run-length encoding, Huffman encoding, LZW compression, Burrows-Wheeler transform . The Imp of Algorithm in Princeton University.]]></content>
      <tags>
        <tag>Algorithms,</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EveryThing About MySQL]]></title>
    <url>%2F2020%2F01%2F14%2FEveryThing-About-MySQL%2F</url>
    <content type="text"><![CDATA[MYSQL彻底搞懂系列B-树、B+树、B-树、B*树 B树和B+树的插入、删除图文详解 关系型数据库和非关系型数据库为什么用B树或B+树 ==B+树的数据只出现在叶子节点上==，因此在查询单条数据的时候，查询速度非常稳定。因此，==在做单一数据的查询上，其平均性能并不如B树==。但是，B+树的叶子节点上有指针进行相连，因此在做数据遍历的时候，==只需要对叶子节点进行遍历即可，这个特性使得B+树非常适合做范围查询==。 没准是==Mysql中数据遍历操作比较多，所以用B+树作为索引结构==。凡做这种关联查询，你躲不开join操作的！既然涉及到了Join操作，无外乎从一个表中取一个数据，去另一个表中逐行匹配，如果索引结构是B+树，叶子节点上是有指针的，能够极大的提高这种一行一行的匹配速度 ==而Mongodb是做单一查询比较多，数据遍历操作比较少==，所以用B树作为索引结构。 那么为什么Mysql做数据遍历操作多？而Mongodb做数据遍历操作少呢？因为Mysql是关系型数据库，而Mongodb是非关系型数据。 平衡二叉树则是子树高读不能超过2，B树非叶子节点也可以存储数据，B+树则是叶子节点才可以存储数据。 我们说的==平衡二叉树结构，指的是逻辑结构上的平衡二叉树，其物理实现是数组==。然后由于在逻辑结构上相近的节点在物理结构上可能会差很远。因此，每次读取的磁盘页的数据中有许多是用不上的。因此，查找过程中要进行许多次的磁盘读取操作。而适合作为索引的结构应该是尽可能少的执行磁盘IO操作，因为执行磁盘IO操作非常的耗时。因此，平衡二叉树并不适合作为索引结构 红黑树这种结构==h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性==，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。也就是说，使用红黑树（平衡二叉树）结构的话，每次磁盘预读中的很多数据是用不上的数据。因此，它没能利用好磁盘预读的提供的数据。然后又由于深度大（较B树而言），所以进行的磁盘IO操作更多。 ==B树的每个节点可以存储多个关键字，它将节点大小设置为磁盘页的大小，充分利用了磁盘预读的功能==。每次读取磁盘页时就会读取一整个节点。==也正因每个节点存储着非常多个关键字，树的深度就会非常的小==。进而要执行的磁盘读取操作次数就会非常少，更多的是在内存中对读取进来的数据进行查找。 ==B树的查询，主要发生在内存中，而平衡二叉树的查询，则是发生在磁盘读取中==。因此，虽然B树查询查询的次数不比平衡二叉树的次数少，但是相比起磁盘IO速度，内存中比较的耗时就可以忽略不计了。因此，B树更适合作为索引。 一步步分析为什么B+树适合作为索引的结构 以及索引原理(阿里面试，写的很好B+Tree是mysql使用最频繁的一个索引数据结构，是Inodb和Myisam存储引擎模式的索引类型。相对Hash索引，B+Tree在查找单条记录的速度比不上Hash索引(Memory表只存在内存中)，但是因为更适合排序等操作，所以它更受欢迎。毕竟不可能只对数据库进行单条记录的操作。 带顺序访问指针的B+Tree B+Tree所有索引数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都有指向相邻叶子节点的指针。这样做是为了提高区间效率，例如查询key为从18到49的所有数据记录，当找到18后，只要顺着节点和指针顺序遍历就可以以此向访问到所有数据节点，极大提高了区间查询效率。 大大减少磁盘I/O读取 数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点需要一次I/O就可以完全载入 全文索引（FULLTEXT）=mysql的myISAM搜索引擎默认的索引类型==不过切记对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法==。 文本字段上的普通索引只能加快对出现在字段内容最前面的字符串(也就是字段内容开头的字符)进行检索操作。如果字段里存放的是由几个、甚至是多个单词构成的较大段文字，普通索引就没什么作用了。这种检索往往以LIKE%word%的形式出现，这对MySQL来说很复杂，如果需要处理的数据量很大，响应时间就会很长。 这类场合正是全文索引(full-textindex)可以大显身手的地方。在生成这种类型的索引时，MySQL将把在文本中出现的所有单词创建为一份清单，查询操作将根据这份清单去检索有关的数据记录。全文索引即可以随数据表一同创建，也可以等日后有必要时再使用下面这条命令添加：ALTER TABLE table_name ADD FULLTEXT(column1, column2) 有了全文索引，就可以用SELECT查询命令去检索那些包含着一个或多个给定单词的数据记录了。下面是这类查询命令的基本语法： SELECT * FROM table_name WHERE MATCH(column1, column2) AGAINST(&#39;word1&#39;, &#39;word2&#39;, &#39;word3&#39;) 上面这条命令将把column1和column2字段里有word1、word2和word3的数据记录全部查询出来。 InnoDB如何解决幻读 使用MVCC 一条SQL语句是如何执行的 由server层和存储引擎组成 server 层包括连接器、分析器、优化器、执行器，涵盖 MySQL的核心服务，以及所有的内置函数（如日期、时间、数学、加密函数等），还有所有跨存储引擎的功能，例如存储过程、触发器、视图等。 一条SQL更新语句是如何执行的？ 里面包含binlog和redolog,两阶段提交 什么叫视图？游标是什么？ 视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，视图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。 游标是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。 请简洁描述Mysql中InnoDB支持的四种事务隔离级别名称，以及逐级之间的区别？在Mysql中ENUM的用法是什么？ 同一个属性里面包含多个字段，每个字段都有自己的索引.enum 在数据库底层以整型方式储存，从 1 开始，0 用于指代空或错误的字符串。 CHAR和VARCHAR的区别？char 固定长度255，不足的部分补空格，取出时再去掉空格。varchar 不定长度 drop,delete与truncate的区别drop删除表，truncate清空表，delete删除表、drop和truncate不能回滚。 存储过程与触发器的区别 触发器是一种特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。 存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。可以用一个命令对象来调用存储过程。可以供外部程序调用，比如：java程序。 存储过程是预编译过的，执行效率高。存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。安全性高，执行存储过程需要有一定权限的用户。存储过程可以重复使用，可减少数据库开发人员的工作量。==缺点：移植性差==。 2）可以供外部程序调用，比如：java程序。 完整性约束包括哪些？数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。 实体完整性：规定表的每一行在表中是惟一的实体。 域完整性：是指表中的列必须满足某种特定的数据类型约束，其中约束又包括取值范围、精度等规定。 参照完整性：是指两个表的主关键字和外关键字的数据应一致，保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。 用户定义的完整性：不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件，它反映某一具体应用必须满足的语义要求。 与表有关的约束：包括列约束(NOT NULL（非空约束）)和表约束(PRIMARY KEY、foreign key、check、UNIQUE) MySql不支持check Mysql 的存储引擎,myisam和innodb的区别。NULL | myisam | innodb —|—|—事务支持|不支持| 支持| row 2 col 2存储结构 |三种文件 | 一种文件存储空间 |体积小 | 体积大可移植性 |方便 | 困难锁力度 |表级锁| 表级锁，行级锁全文索引 |支持 | 不支持表主键 |可以没有|必须有，没有就自动生成外键 |不支持 | 支持 1.锁 MyISAM 是非事务的存储引擎，适合用于频繁查询的应用。表锁，不会出现死锁，适合小数据，小并发。 Innodb是支持事务的存储引擎，合于插入和更新操作比较多的应用，设计合理的话是行锁（最大区别就在锁的级别上），适合大数据，大并发表锁和行锁的区别表锁 特点：开销小、加锁快、无死锁；锁粒度大，发生锁冲突的概率高，高并发下性能低 加锁的方式：自动加锁。查询操作（SELECT），会自动给涉及的所有表加读锁，更新操作（UPDATE、DELETE、INSERT），会自动给涉及的表加写锁。行锁 特点：锁的粒度小，发生锁冲突的概率低、处理并发的能力强；开销大、加锁慢、会出现死锁 加锁的方式：自动加锁。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁；对于普通SELECT语句，InnoDB不会加任何锁。 乐观锁：不加锁，只有在更新时验证数据是否被其他线程更新，吞吐量较高，适用于多读场景。它==假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，那么当前正在提交的事务会进行回滚==。 乐观锁实现方式是：版本号version和CAS(compare and swap) 悲观锁：读取时加锁，更新完释放锁，再此过程中会造成其他线程阻塞，导致吞吐量低，适用于多写场景。当事务A对某行数据应用了锁，==并且当这个事务把锁释放后，其他事务才能够执行与该锁冲突的操作==，这里事务A所施加的锁就叫悲观锁。 行锁(共享锁和排他锁),间隙锁(next-keylock）都属于悲观锁。InnoDB实现了以下两种类型的行锁： 共享锁（S）：==允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁==。 排他锁（X)：==允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。==另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。 意向排他锁（IX）：事务打算给数据行加行排他锁* ，事务在给一个数据行加排他锁前必须先取得该表的IX锁。间隙锁（Next-Key锁）: 当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁； 对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key)锁。 1:表级锁不会死锁,行级锁和页级锁可能死锁 2:在数据库实现资源锁定的过程中，随着锁定资源颗粒度的减小，锁定相同数据量的数据所需要消耗的内存数量是越来越多的，实现算法也会越来越复杂。不过，随着锁定资源颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。 3:==从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应==用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。 4:意向锁是InnoDB自动加的，不需用户干预。==对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)==；对于普通SELECT语句，InnoDB不会加任何锁； 5:InnoDB行锁实现方式: ==InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁== Mysql中MVCC的使用及原理详解MVCC是一种多版本并发控制机制。MVCC是通过保存数据在某个时间点的快照来实现的。在每个表后添加创建版本号和删除版本号，版本号为修改该项的事务版本号。 SELECT:InnoDB会根据以下两个条件检查每行记录 InnoDB只会查找版本早于当前事务版本的数据行(也就是,行的系统版本号小于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的. 行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除.只有a,b同时满足的记录，才能返回作为查询结果. DELETE:InnoDB会为删除的每一行保存当前系统的版本号(事务的ID)作为删除标识. UPDATE:InnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间。 锁策略2.日志redolog，binlog，undolog对事务的影响 binlog redolog,保证事务的持久性，缓存区中数据会慢慢更新到数据库的硬盘上。 undolog，记录了修改几率，可以随便回滚，保证原子性。 3.事务MVCC (MultiVersion Concurrency Control) 叫做==多版本并发==控制。==由undolog和记录版本的一个东西组成==。 InnoDB的 MVCC，是通过在每行记录的后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间，当然存储的并不是实际的时间值，而是系统版本号。 以上片段摘自《高性能Mysql》这本书对MVCC的定义。他的主要实现思想是通过==数据多版本==来做到==读写分离==。从而实现不加锁读进而做到读写并行。 MVCC在mysql中的实现依赖的是undo log与read view undolog :undolog中记录某行数据的多个版本的数据。 read view :用来判断当前版本数据的可见性ACID特性中的一致性是如何实现的 事务的原子性是通过 undo log 来实现的 事务的持久性性是通过 redo log 来实现的 事务的隔离性是通过 (读写锁+MVCC)来实现的 而事务的终极大boss一致性是通过原子性，持久性，隔离性来实现的！！！ 原子性，持久性，隔离性折腾半天的目的也是为了保障数据的一致性！ACID只是个概念，事务最终目的是要保障数据的可靠性，一致性 事务是如何通过日志实现的 mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Buffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。 redolog来记录已成功提交事务的修改信息，并且会把redolog持久化到磁盘，系统重启之后在读取redo log恢复最新数据。redolog是用来恢复数据的 用于保障，已提交事务的持久化特性 undolog 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，redolog记录数据被修改后的信息。undolog主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。undolog记录事务修改之前版本的数据信息，因此假如由于系统错误或者rollback操作而回滚的话可以根据undolog的信息来进行回滚到没被修改前的状态。 redo和undo基本流程如下：因为事务在修改页时，要先记 undo，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。 Redo（里面包括 undo 的修改） 一定要比数据页先持久化到磁盘。 当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的状态，崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo把该事务的修改回滚到事务开始之前。 如果有 commit 记录，就用 redo 前滚到该事务完成时并提交掉。 4.索引MySQL索引背后的数据结构及算法原理多种引擎的实现区别？聚族索引，非聚族索引，二级索引，唯一索引、最左匹配原则等等（非常重要） 唯一索引 唯一索引是不允许其中任何两行具有相同索引值的索引。当现有数据中存在重复的键值时，大多数数据库不允许将新创建的唯一索引与表一起保存。数据库还可能防止添加将在表中创建重复键值的新数据。例如，如果在employee表中职员的姓(lname)上创建了唯一索引，则任何两个员工都不能同姓。 主键索引 数据库表经常有一列或列组合，其值唯一标识表中的每一行。该列称为表的主键。在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 聚集索引 表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引。如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。 建索引有哪些原则 索引是建立在数据库表中的某些列的上面。在创建索引的时候，应该考虑在哪些列上可以创建索引，在哪些列上不能创建索引。一般来说应该在这些列上创建索引： 在经常需要搜索的列上，可以加快搜索的速度 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 什么情况下设置了索引但无法使用 条件中使用了 or，而相关列不全有索引 条件中使用了and，而相关列不满足最左原则 索引列的数据类型出现隐形转换，如varchar不加单引号的话可能会自动转换为int型） like查询是以%开头 where 子句里对索引列上有数学运算/函数 mysql估计使用全表扫描要比使用索引快什么情况下不宜建立索引？ 对于那些在查询中==很少使用或者参考的列不应该创建索引==。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那些==只有很少数据值的列==也不应该增加索引。举例比如性别只有男和女 对于==那些定义为text,image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少==。 经==常频繁更新的列==不要建立索引，因为肯定会影响插入或更新的效率 尽量避==免在 where 子句中使用 ！= 或者 &lt;&gt; 操作符，查询引用会放弃索引而进行全表扫==描。 当==修改性能远远大于检索性能时，不应该创建索引==。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 尽量避免NULL：在MySQL中，==含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂==。可以采用0、一个特殊的值或者一个空串代替空值 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 为什么用B-树上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了==磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入== 为了达到这个目的，在实际实现B-Tree还需要使用如下技巧： 每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。 为什么不用红黑树 红黑树这种结构，h(层数)明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。 MySQL索引失效的情形很多。例如： 在WHERE条件的LIKE关键字匹配的字符串以”%“开头，这种情况下，索引是不会起到作用的；WHERE条件中使用OR关键字来连接多个查询条件，如果有一个条件没有使用索引，那么其他的索引也不会起作用；多列索引的第一个字段没有使用，那么这个多列索引也不会起作用。 使用in查询时，in查询条件超过数据库表的一半的时候也会失效。 最左匹配原则 索引字段要尽量的小 索引的最左匹配特性（即从左往右匹配）：当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 MySQL索引优化深入分析执行计划如果有2级索引怎么存局部性原理与磁盘预读由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，==磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。==这样做的理论依据是计算机科学中著名的==局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中==。 由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。 预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行 5.SQL语句 SQL语句菜鸟教程 SQL教程 AND运算符，如果第一个条件和第二个条件都成立，则 AND 运算符显示一条记录。 OR运算符如果第一个条件和第二个条件中只要有一个成立，则 OR 运算符显示一条记录。 123SELECT * FROM WebsitesWHERE alexa &gt; 15AND (country=&apos;CN&apos; OR country=&apos;USA&apos;); ORDER BY 关键字默认按照升序对记录进行排序。如果需要按照降序对记录进行排序，您可以使用 DESC 关键字。 IN操作符IN操作符允许在WHERE子句中规定多个值。 BETWEEN操作符用于选取介于两个值之间的数据范围内的值。 123SELECT * FROM WebsitesWHERE (alexa BETWEEN 1 AND 20)AND country NOT IN (&apos;USA&apos;, &apos;IND&apos;); INNER JOIN：如果表中有至少一个匹配，则返回行 LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行 RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行 FULL JOIN：只要其中一个表中存在匹配，则返回行 SQL高级教程 模糊查询(like)1234SELECT * FROM Websites以&quot;G&quot;开始的所有客户WHERE name LIKE &apos;G%&apos;;以&quot;k&quot;结尾的所有客户WHERE name LIKE &apos;%k&apos;;还可以写NOT LIKE做反向查询 解释MySQL外连接、内连接(outer join和inner join)与自连接的区别外连接 左连接：连接两张表，左表数据完全显示，右表匹配，匹配不上的补null；在这里，t_employee就是左表，也就是基准表，==用基准表的数据去匹配右表的数据，所以左表的记录是全部会查询出来的，如果右表没有记录对应的话就显示null==。 LEFT JOIN 关键字从左表（table1）返回所有的行，即使右表（table2）中没有匹配。如果右表中没有匹配，则结果为 NULL。 右连接：同上，换个方向；全外连接：两表字段都匹配，匹配不上的补null； 内连接：所有查询出的结果都是能够在连接的表中有对应记录的。这就是内连接的特点，==只查询在连接的表中能够有对应的记录==， INNER JOIN关键字在表中存在至少一个匹配时返回行。 全外连接：==mysql是没有全外连接的==(mysql中没有full outer join关键字)，==想要达到全外连接的效果，可以使用union关键字连接左外连接和右外连接==。如果在Oracle中，直接就使用full outer join关键字连接两表就行了。 UNION SQL UNION 操作符合并两个或多个 SELECT 语句的结果。 1234SELECT country FROM WebsitesUNIONSELECT country FROM appsORDER BY country; SELECT INTO 通过 SQL，您可以从一个表复制信息到另一个表。SELECT INTO 语句从一个表复制数据，然后把数据插入到另一个新表中 123CREATE TABLE 新表ASSELECT * FROM 旧表 INSERT INTO SELECT 通过 SQL，您可以从一个表复制信息到另一个表。INSERT INTO SELECT 语句从一个表复制数据，然后把数据插入到一个已存在的表中。 12INSERT INTO table2SELECT * FROM table1; 自连接：找到两表的公共字段，然后和内连接一样。 交叉连接: 生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将一个数据源中的每个行与另一个数据源的每个行都一一匹配 SELECT type,pub_name FROM titles CROSS JOIN publishers ORDER BY type 子查询一个SELECT语句嵌套在另一个SELECT语句中，子查询也叫做内部查询，而包含子查询的语句又称为外部查询或主查询，子查询自身可以包含一个或多个子查询，一个查询语句中可以嵌套任意数量的子查询。 SQL查询重复记录 MySQL两道经典SQL面试题(行转列/列转行/求最值) SQL函数 GROUP BY GROUP BY 语句用于结合聚合函数，根据一个或多个列对结果集进行分组。 123统计 access_log 各个 site_id 的访问量：SELECT site_id, SUM(access_log.count) AS numsFROM access_log GROUP BY site_id; 1234SELECT Websites.name,COUNT(access_log.aid) AS nums FROM access_logLEFT JOIN WebsitesON access_log.site_id=Websites.idGROUP BY Websites.name; HAVING 在 SQL 中增加 HAVING 子句原因是，==WHERE 关键字无法与聚合函数一起使用==。HAVING 子句可以让我们筛选分组后的各组数据。 12345查找总访问量大于 200 的网站。SELECT Websites.name, Websites.url, SUM(access_log.count) AS nums FROM (access_log INNER JOIN WebsitesON access_log.site_id=Websites.id)GROUP BY Websites.nameHAVING SUM(access_log.count) &gt; 200; 6.SQL优化慢查询解决的基本步骤500万数量级查询优化我们是如何对实际项目进行查询优化的巧用这19条MySQL优化，效率至少提高3倍为什么要分区，分表和分库？一次SQL查询优化原理分析（900W+数据，从17s到300ms面试官：给我讲一下分库分表方案数据库如何保证数据不丢失MYSQL的主从同步延迟的原因及解决方案 mysql主从复制用途 从库生成两个线程，一个I/O线程，一个SQL线程；i/o线程去请求主库的binlog，并将得到的binlog日志写到relaylog（中继日志）文件中；主库会生成一个 log dump 线程，用来给从库i/o线程传binlog；SQL 线程，会读取relay log文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致； 实时灾备，用于故障切换,==读写分离(主写从读比例为10：1)==，提供查询服务备份，避免影响业务 主从部署必要条件：主库开启binlog日志（设置log-bin参数）,主从server-id不同,从库服务器能连通主库数据库如何保证高可用灰度发布在灰度发布开始后，先启动一个新版本应用，但是并不直接将流量切过来，而是测试人员对新版本进行线上测试，启动的这个新版本应用，就是我们的金丝雀。如果没有问题，那么可以将少量的用户流量导入到新版本上，然后再对新版本做运行状态观察，收集各种运行时数据，如果此时对新旧版本做各种数据对比，就是所谓的A/B测试。 当确认新版本运行良好后，再逐步将更多的流量导入到新版本上，在此期间，还可以不断地调整新旧两个版本的运行的服务器副本数量，以使得新版本能够承受越来越大的流量压力。直到将100%的流量都切换到新版本上，最后关闭剩下的老版本服务，完成灰度发布。 如果在灰度发布过程中（灰度期）发现了新版本有问题，就应该立即将流量切回老版本上，这样，就会将负面影响控制在最小范围内。 MySQL优化创建表时候的优化 整数TinyInt,SmallInt,MediumInt,Int,BigInt 使用的存储 8,16,24,32,64 位存储空间。使用 Unsigned 表示不允许负数，可以使正数的上线提高一倍。 实数Float,Double , 支持近似的浮点运算。Decimal，用于存储精确的小数。 字符串VarChar，存储变长的字符串。需要 1 或 2 个额外的字节记录字符串的长度。Char，定长，适合存储固定长度的字符串，如 MD5 值。 Blob，Text为了存储很大的数据而设计的。分别采用二进制和字符的方式。 时间类型DateTime，保存大范围的值，占 8 个字节。TimeStamp，推荐，与 UNIX 时间戳相同，占 4 个字节。SQL语句优化 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num=0 用EXISTS替代IN、用NOT EXISTS替代NOT IN 用Where子句替换HAVING 子句 因为HAVING 只会在检索出所有记录之后才对结果集进行过滤。 尽量避免在where子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描 Where子句中：where表之间的连接必须写在其他Where条件之前，那些可以过滤掉最大数量记录的条件必须写在Where子句的末尾.HAVING最后。 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引索引优化(选择索引的数据类型)MySQL支持很多数据类型，选择合适的数据类型存储数据对性能有很大的影响。 越小的数据类型通常更好：越小的数据类型通常在磁盘、内存和cpu缓存中都需要更少的空间，处理起来更快。 简单的数据类型更好：整形数据比起字符，处理开销更小，因为字符串的比较更复杂。在MySQL中，应用内置的日期和时间数据类型，而不是字符串来存储时间；以及用整形数据存储IP地址。 尽量避免NULL：应该制定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化，因为他们使得索引、索引的统计信息以及比较运算更加复杂。 为了更多的提高mysql效率可建立组合索引，遵循“最左前缀”原则。创建复合索引应该将最常用（频率）做限制条件的列放在最左边，一次递减。组合索引最左字段用in是可以用到索引的。相当于建立了col1,col1col2,col1col2col3三个索引。分库分表优化 垂直拆分：解决问题：表与表之间的io竞争 不解决问题：单表中数据量增长出现的压力 方案： 把产品表和用户表放到一个server上 订单表单独放到一个server上。 水平拆分： 解决问题：单表中数据量增长出现的压力 不解决问题：表与表之间的io争夺 用户表通过性别拆分为男用户表和女用户表 订单表通过已完成和完成中拆分为已完成订单和未完成订单 产品表 未完成订单放一个server上 已完成订单表盒男用户表放一个server上 女用户表放一个server上(女的爱购物 哈哈)，==可以把学校范围内的用户单独独立出来一张表==。 MySQL不需要执行后面的复杂操作，就可以直接返回结果，效率很高，==但是查询缓存失效非常频繁，只要有对一个表的更新，这个表的所有查询缓存都会被清空，因此可能你费力地把结果缓存起来，还没使用，就被一个更新全部清空了。除非你的业务是一张静态表，很长时间才会更新一次，这种情况下可以使用查询缓存==。(==把管理员信息放进去==) 7.三范式第一范式（1NF）==如果一个关系模式的所有属性的域都是原子的是指数据库表的每一列都是不可分割的基本数据项==，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。如果出现重复的属性，就可能需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。简而言之，第一范式就是无重复的列。 第二范式（2NF）第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被惟一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主关键字或主键、主码。（2NF）==要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性==，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。简而言之，第二范式就是非主属性非部分依赖于主关键字。 第三范式（3NF） 满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。简而言之，第三范式就是属性不依赖于其它非主属性。（我的理解是消除冗余） 优点:可以尽量得减少数据冗余，使得更新快，体积小 缺点:对于查询需要多个表进行关联，减少写得效率增加读得效率，更难进行索引优化]]></content>
      <tags>
        <tag>MySQL, DataBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SortAlgorithms]]></title>
    <url>%2F2020%2F01%2F13%2FSortAlgorithm%2F</url>
    <content type="text"><![CDATA[SortAlgorithms 原文链接： 八大排序算法总结与java实现 - iTimeTraveler 概述 直接插入排序 希尔排序 简单选择排序 堆排序 冒泡排序 快速排序 归并排序 基数排序 其中我们讨论的这八大排序算法的实现可以参考我的Github：SortAlgorithms，其中包括了排序测试模块[Test.java]和排序算法对比模块[Bench.java]，大家可以试运行。 它们都属于内部排序，也就是只考虑数据量较小仅需要使用内存的排序算法，他们之间关系如下： 一、直接插入排序（Insertion Sort） 插入排序的设计初衷是往有序的数组中快速插入一个新的元素。它的算法思想是：把要排序的数组分为了两个部分, 一部分是数组的全部元素(除去待插入的元素), 另一部分是待插入的元素; 先将第一部分排序完成, 然后再插入这个元素. 其中第一部分的排序也是通过再次拆分为两部分来进行的. 插入排序由于操作不尽相同, 可分为 直接插入排序 , 折半插入排序(又称二分插入排序), 链表插入排序 , 希尔排序 。我们先来看下直接插入排序。 1、基本思想直接插入排序的基本思想是：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过为止。 2、算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： ①. 从第一个元素开始，该元素可以认为已经被排序②. 取出下一个元素，在已经排序的元素序列中从后向前扫描③. 如果该元素（已排序）大于新元素，将该元素移到下一位置④. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置⑤. 将新元素插入到该位置后⑥. 重复步骤②~⑤ 算法实现中比较有意思的一点是，在每次比较操作发现取出来的新元素小于等于已排序的元素时，可以将已排序的元素移到下一位置，然后将取出来的新元素插入该位置（即相邻位置对调），接着再与前面的已排序的元素进行比较，如上图所示，这样做缺点是交换操作代价比较大。另一种做法是：将新元素取出（挖坑），从左到右依次与已排序的元素比较，如果已排序的元素大于取出的新元素，那么将该元素移动到下一个位置（填坑），接着再与前面的已排序的元素比较，直到找到已排序的元素小于等于新元素的位置，这时再将新元素插入进去。就像基本思想中的动图演示的那样。 如果比较操作的代价比交换操作大的话，可以采用二分查找法来减少比较操作的数目。可以认为是插入排序的一个变种，称为二分查找插入排序。 3、代码实现1234567891011121314151617181920212223242526272829303132333435363738394041/** * 插入排序 * * 1. 从第一个元素开始，该元素可以认为已经被排序 * 2. 取出下一个元素，在已经排序的元素序列中从后向前扫描 * 3. 如果该元素（已排序）大于新元素，将该元素移到下一位置 * 4. 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 * 5. 将新元素插入到该位置后 * 6. 重复步骤2~5 * @param arr 待排序数组 */public static void insertionSort(int[] arr)&#123; for( int i = 1; i &lt; arr.length; i++ ) &#123; int temp = arr[i]; // 取出下一个元素，在已经排序的元素序列中从后向前扫描 for( int j = i; j &gt;= 0; j-- ) &#123; if( j &gt; 0 &amp;&amp; arr[j-1] &gt; temp ) &#123; arr[j] = arr[j-1]; // 如果该元素（已排序）大于取出的元素temp，将该元素移到下一位置 System.out.println("Temping: " + Arrays.toString(arr)); &#125; else &#123; // 将新元素插入到该位置后 arr[j] = temp; System.out.println("Sorting: " + Arrays.toString(arr)); break; &#125; &#125; &#125;&#125;// 交换次数较多的实现public static void insertionSort(int[] arr)&#123; for( int i=0; i&lt;arr.length-1; i++ ) &#123; for( int j=i+1; j&gt;0; j-- ) &#123; if( arr[j-1] &lt;= arr[j] ) break; int temp = arr[j]; //交换操作 arr[j] = arr[j-1]; arr[j-1] = temp; System.out.println("Sorting: " + Arrays.toString(arr)); &#125; &#125;&#125; 直接插入排序复杂度如下： 最好情况下，排序前对象已经按照要求的有序。比较次数(KCN)：n−1；移动次数(RMN)为0。则对应的时间复杂度为O(n)。 最坏情况下，排序前对象为要求的顺序的反序。第i趟时第i个对象必须与前面i个对象都做排序码比较，并且每做1次比较就要做1次数据移动（从上面给出的代码中看出）。比较次数(KCN)：n²/2 ; 移动次数(RMN)为：n²/2。则对应的时间复杂度为O(n²)。 如果排序记录是随机的，那么根据概率相同的原则，在平均情况下的排序码比较次数和对象移动次数约为n²/2，因此，直接插入排序的平均时间复杂度为O(n²)。 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n) O(n²) O(1) Tips: 由于直接插入排序每次只移动一个元素的位， 并不会改变值相同的元素之间的排序， 因此它是一种稳定排序。 二、希尔排序（Shell Sort） 第一个突破O(n^2)的排序算法；是简单插入排序的改进版；它与插入排序的不同之处在于，它会优先比较距离较远的元素。 希尔排序，也称递减增量排序算法，1959年Shell发明。是插入排序的一种高速而稳定的改进版本。 希尔排序是先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。 1、基本思想 将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；每次再将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。 可以看到步长的选择是希尔排序的重要部分。只要最终步长为1任何步长序列都可以工作。一般来说最简单的步长取值是初次取数组长度的一半为增量，之后每次再减半，直到增量为1。更好的步长序列取值可以参考维基百科。 2、算法描述①. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（一般初次取数组半长，之后每次再减半，直到增量为1）②. 按增量序列个数k，对序列进行k 趟排序；③. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 3、代码实现以下是我自己的实现，可以看到实现很幼稚，但是好处是理解起来很简单。因为没有经过任何的优化，所以不建议大家直接使用。建议对比下方的维基百科官方实现代码，特别是步长取值策略部分。 123456789101112131415161718192021222324/** * 希尔排序 * * 1. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（一般初次取数组半长，之后每次再减半，直到增量为1） * 2. 按增量序列个数k，对序列进行k 趟排序； * 3. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void shellSort(int[] arr)&#123; int gap = arr.length / 2; for (; gap &gt; 0; gap /= 2) &#123; //不断缩小gap，直到1为止 for (int j = 0; (j+gap) &lt; arr.length; j++)&#123; //使用当前gap进行组内插入排序 for(int k = 0; (k+gap)&lt; arr.length; k += gap)&#123; if(arr[k] &gt; arr[k+gap]) &#123; int temp = arr[k+gap]; //交换操作 arr[k+gap] = arr[k]; arr[k] = temp; System.out.println(" Sorting: " + Arrays.toString(arr)); &#125; &#125; &#125; &#125;&#125; 下面是维基百科官方实现，大家注意gap步长取值部分： 1234567891011121314151617181920212223/** * 希尔排序（Wiki官方版） * * 1. 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1；（注意此算法的gap取值） * 2. 按增量序列个数k，对序列进行k 趟排序； * 3. 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void shell_sort(int[] arr) &#123; int gap = 1, i, j, len = arr.length; int temp; while (gap &lt; len / 3) gap = gap * 3 + 1; // &lt;O(n^(3/2)) by Knuth,1973&gt;: 1, 4, 13, 40, 121, ... for (; gap &gt; 0; gap /= 3) &#123; for (i = gap; i &lt; len; i++) &#123; temp = arr[i]; for (j = i - gap; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j -= gap) arr[j + gap] = arr[j]; arr[j + gap] = temp; &#125; &#125;&#125; 以下是希尔排序复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog2 n) O(nlog2 n) O(nlog2 n) O(1) 三、选择排序（Selection Sort） 从算法逻辑上看，选择排序是一种简单直观的排序算法，在简单选择排序过程中，所需移动记录的次数比较少。 1、基本思想选择排序的基本思想：比较 + 交换。 在未排序序列中找到最小（大）元素，存放到未排序序列的起始位置。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。 2、算法描述①. 从待排序序列中，找到关键字最小的元素；②. 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；③. 从余下的 N - 1 个元素中，找出关键字最小的元素，重复①、②步，直到排序结束。 3、代码实现选择排序比较简单，以下是我自己的实现，跟官方版差不多，所以完全可以参考。 12345678910111213141516171819202122232425/** * 选择排序 * * 1. 从待排序序列中，找到关键字最小的元素； * 2. 如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换； * 3. 从余下的 N - 1 个元素中，找出关键字最小的元素，重复①、②步，直到排序结束。 * 仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 * @param arr 待排序数组 */public static void selectionSort(int[] arr)&#123; for(int i = 0; i &lt; arr.length-1; i++)&#123; int min = i; for(int j = i+1; j &lt; arr.length; j++)&#123; //选出之后待排序中值最小的位置 if(arr[j] &lt; arr[min])&#123; min = j; &#125; &#125; if(min != i)&#123; int temp = arr[min]; //交换操作 arr[min] = arr[i]; arr[i] = temp; System.out.println("Sorting: " + Arrays.toString(arr)); &#125; &#125;&#125; 以下是选择排序复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n²) O(n²) O(1) 选择排序的简单和直观名副其实，这也造就了它”出了名的慢性子”，无论是哪种情况，哪怕原数组已排序完成，它也将花费将近n²/2次遍历来确认一遍。即便是这样，它的排序结果也还是不稳定的。 唯一值得高兴的是，它并不耗费额外的内存空间。 四、堆排序（Heap Sort） 1991年的计算机先驱奖获得者、斯坦福大学计算机科学系教授罗伯特·弗洛伊德(Robert W．Floyd) 和威廉姆斯(J．Williams) 在1964年共同发明了著名的堆排序算法(Heap Sort). 堆的定义如下：n个元素的序列{k1,k2,···,kn}，当且仅当满足下关系时，称之为堆。 ki &lt;= k(2i) 且 ki &lt;= k(2i+1) 或： ki &gt;= k(2i) 且 ki &gt;= k(2i+1) 把此序列对应的二维数组看成一个完全二叉树。那么堆的含义就是：完全二叉树中任何一个非叶子节点的值均不大于（或不小于）其左，右孩子节点的值。由上述性质可知大顶堆的堆顶的关键字肯定是所有关键字中最大的，小顶堆的堆顶的关键字是所有关键字中最小的。因此我们可使用大顶堆进行升序排序, 使用小顶堆进行降序排序。 1、基本思想此处以大顶堆为例，堆排序的过程就是将待排序的序列构造成一个堆，选出堆中最大的移走，再把剩余的元素调整成堆，找出最大的再移走，重复直至有序。 2、算法描述①. 先将初始序列K[1..n]建成一个大顶堆, 那么此时第一个元素K1最大, 此堆为初始的无序区.②. 再将关键字最大的记录K1 (即堆顶, 第一个元素)和无序区的最后一个记录 Kn 交换, 由此得到新的无序区K[1..n-1]和有序区K[n], 且满足K[1..n-1].keys &lt;= K[n].key ③. 交换K1 和 Kn 后, 堆顶可能违反堆性质, 因此需将K[1..n-1]调整为堆. 然后重复步骤②, 直到无序区只有一个元素时停止. 动图效果如下所示： 3、代码实现从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆函数，二是反复调用建堆函数以选择出剩余未排元素中最大的数来实现排序的函数。 总结起来就是定义了以下几种操作： 最大堆调整（Max_Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点 创建最大堆（Build_Max_Heap）：将堆所有数据重新排序 堆排序（HeapSort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 对于堆节点的访问： 父节点i的左子节点在位置：(2*i+1); 父节点i的右子节点在位置：(2*i+2); 子节点i的父节点在位置：floor((i-1)/2); 1234567891011121314151617181920212223242526272829303132333435363738/** * 堆排序 * * 1. 先将初始序列K[1..n]建成一个大顶堆, 那么此时第一个元素K1最大, 此堆为初始的无序区. * 2. 再将关键字最大的记录K1 (即堆顶, 第一个元素)和无序区的最后一个记录 Kn 交换, 由此得到新的无序区K[1..n−1]和有序区K[n], 且满足K[1..n−1].keys⩽K[n].key * 3. 交换K1 和 Kn 后, 堆顶可能违反堆性质, 因此需将K[1..n−1]调整为堆. 然后重复步骤②, 直到无序区只有一个元素时停止. * @param arr 待排序数组 */public static void heapSort(int[] arr)&#123; for(int i = arr.length; i &gt; 0; i--)&#123; max_heapify(arr, i); int temp = arr[0]; //堆顶元素(第一个元素)与Kn交换 arr[0] = arr[i-1]; arr[i-1] = temp; &#125;&#125;private static void max_heapify(int[] arr, int limit)&#123; if(arr.length &lt;= 0 || arr.length &lt; limit) return; int parentIdx = limit / 2; for(; parentIdx &gt;= 0; parentIdx--)&#123; if(parentIdx * 2 &gt;= limit)&#123; continue; &#125; int left = parentIdx * 2; //左子节点位置 int right = (left + 1) &gt;= limit ? left : (left + 1); //右子节点位置，如果没有右节点，默认为左节点位置 int maxChildId = arr[left] &gt;= arr[right] ? left : right; if(arr[maxChildId] &gt; arr[parentIdx])&#123; //交换父节点与左右子节点中的最大值 int temp = arr[parentIdx]; arr[parentIdx] = arr[maxChildId]; arr[maxChildId] = temp; &#125; &#125; System.out.println("Max_Heapify: " + Arrays.toString(arr));&#125; 注: x&gt;&gt;1 是位运算中的右移运算, 表示右移一位, 等同于x除以2再取整, 即 x&gt;&gt;1 == Math.floor(x/2) . 以上,①. 建立堆的过程, 从length/2 一直处理到0, 时间复杂度为O(n);②. 调整堆的过程是沿着堆的父子节点进行调整, 执行次数为堆的深度, 时间复杂度为O(lgn);③. 堆排序的过程由n次第②步完成, 时间复杂度为O(nlgn). 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog2n) O(nlog2n) O(nlog2n) O(1) Tips: 由于堆排序中初始化堆的过程比较次数较多, 因此它不太适用于小序列. 同时由于多次任意下标相互交换位置, 相同元素之间原本相对的顺序被破坏了, 因此, 它是不稳定的排序. 五、冒泡排序（Bubble Sort） 我想对于它每个学过C语言的都会了解，这可能是很多人接触的第一个排序算法。 1、基本思想冒泡排序（Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 2、算法描述冒泡排序算法的运作如下： ①. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。②. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。③. 针对所有的元素重复以上的步骤，除了最后一个。④. 持续每次对越来越少的元素重复上面的步骤①~③，直到没有任何一对数字需要比较。 3、代码实现冒泡排序需要两个嵌套的循环. 其中, 外层循环移动游标; 内层循环遍历游标及之后(或之前)的元素, 通过两两交换的方式, 每次只确保该内循环结束位置排序正确, 然后内层循环周期结束, 交由外层循环往后(或前)移动游标, 随即开始下一轮内层循环, 以此类推, 直至循环结束. 123456789101112131415161718192021/** * 冒泡排序 * * ①. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 * ②. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 * ③. 针对所有的元素重复以上的步骤，除了最后一个。 * ④. 持续每次对越来越少的元素重复上面的步骤①~③，直到没有任何一对数字需要比较。 * @param arr 待排序数组 */public static void bubbleSort(int[] arr)&#123; for (int i = arr.length - 1; i &gt; 0; i--) &#123; //外层循环移动游标 for(int j = 0; j &lt; i; j++)&#123; //内层循环遍历游标及之后(或之前)的元素 if(arr[j] &gt; arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; System.out.println("Sorting: " + Arrays.toString(arr)); &#125; &#125; &#125;&#125; 以下是冒泡排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(n²) O(n) O(n²) O(1) 冒泡排序是最容易实现的排序, 最坏的情况是每次都需要交换, 共需遍历并交换将近n²/2次, 时间复杂度为O(n²). 最佳的情况是内循环遍历一次后发现排序是对的, 因此退出循环, 时间复杂度为O(n). 平均来讲, 时间复杂度为O(n²). 由于冒泡排序中只有缓存的temp变量需要内存空间, 因此空间复杂度为常量O(1). Tips: 由于冒泡排序只在相邻元素大小不符合要求时才调换他们的位置, 它并不改变相同元素之间的相对顺序, 因此它是稳定的排序算法. 六、快速排序（Quick Sort） 快速排序（Quicksort）是对冒泡排序的一种改进，借用了分治的思想，由C. A. R. Hoare在1962年提出。 1、基本思想快速排序的基本思想：挖坑填数+分治法。 首先选一个轴值(pivot，也有叫基准的)，通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 2、算法描述快速排序使用分治策略来把一个序列（list）分为两个子序列（sub-lists）。步骤为： ①. 从数列中挑出一个元素，称为”基准”（pivot）。②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。 3、代码实现用伪代码描述如下： ①. i = L; j = R; 将基准数挖出形成第一个坑a[i]。②．j--，由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。③．i++，由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。④．再重复执行②，③二步，直到i==j，将基准数填入a[i]中 1234567891011121314151617181920212223242526272829303132/** * 快速排序（递归） * * ①. 从数列中挑出一个元素，称为"基准"（pivot）。 * ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 * ③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 * @param arr 待排序数组 * @param low 左边界 * @param high 右边界 */public static void quickSort(int[] arr, int low, int high)&#123; if(arr.length &lt;= 0) return; if(low &gt;= high) return; int left = low; int right = high; int temp = arr[left]; //挖坑1：保存基准的值 while (left &lt; right)&#123; while(left &lt; right &amp;&amp; arr[right] &gt;= temp)&#123; //坑2：从后向前找到比基准小的元素，插入到基准位置坑1中 right--; &#125; arr[left] = arr[right]; while(left &lt; right &amp;&amp; arr[left] &lt;= temp)&#123; //坑3：从前往后找到比基准大的元素，放到刚才挖的坑2中 left++; &#125; arr[right] = arr[left]; &#125; arr[left] = temp; //基准值填补到坑3中，准备分治递归快排 System.out.println("Sorting: " + Arrays.toString(arr)); quickSort(arr, low, left-1); quickSort(arr, left+1, high);&#125; 上面是递归版的快速排序：通过把基准temp插入到合适的位置来实现分治，并递归地对分治后的两个划分继续快排。那么非递归版的快排如何实现呢？ 因为递归的本质是栈，所以我们非递归实现的过程中，可以借助栈来保存中间变量就可以实现非递归了。在这里中间变量也就是通过Pritation函数划分区间之后分成左右两部分的首尾指针，只需要保存这两部分的首尾指针即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 快速排序（非递归） * * ①. 从数列中挑出一个元素，称为"基准"（pivot）。 * ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 * ③. 把分区之后两个区间的边界（low和high）压入栈保存，并循环①、②步骤 * @param arr 待排序数组 */public static void quickSortByStack(int[] arr)&#123; if(arr.length &lt;= 0) return; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); //初始状态的左右指针入栈 stack.push(0); stack.push(arr.length - 1); while(!stack.isEmpty())&#123; int high = stack.pop(); //出栈进行划分 int low = stack.pop(); int pivotIdx = partition(arr, low, high); //保存中间变量 if(pivotIdx &gt; low) &#123; stack.push(low); stack.push(pivotIdx - 1); &#125; if(pivotIdx &lt; high &amp;&amp; pivotIdx &gt;= 0)&#123; stack.push(pivotIdx + 1); stack.push(high); &#125; &#125;&#125;private static int partition(int[] arr, int low, int high)&#123; if(arr.length &lt;= 0) return -1; if(low &gt;= high) return -1; int l = low; int r = high; int pivot = arr[l]; //挖坑1：保存基准的值 while(l &lt; r)&#123; while(l &lt; r &amp;&amp; arr[r] &gt;= pivot)&#123; //坑2：从后向前找到比基准小的元素，插入到基准位置坑1中 r--; &#125; arr[l] = arr[r]; while(l &lt; r &amp;&amp; arr[l] &lt;= pivot)&#123; //坑3：从前往后找到比基准大的元素，放到刚才挖的坑2中 l++; &#125; arr[r] = arr[l]; &#125; arr[l] = pivot; //基准值填补到坑3中，准备分治递归快排 return l;&#125; 快速排序是通常被认为在同数量级（O(nlog2n)）的排序方法中平均性能最好的。但若初始序列按关键码有序或基本有序时，快排序反而蜕化为冒泡排序。为改进之，通常以“三者取中法”来选取基准记录，即将排序区间的两个端点与中点三个记录关键码居中的调整为支点记录。快速排序是一个不稳定的排序方法。 以下是快速排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog₂n) O(nlog₂n) O(n²) O(1)（原地分区递归版） 快速排序排序效率非常高。 虽然它运行最糟糕时将达到O(n²)的时间复杂度, 但通常平均来看, 它的时间复杂为O(nlogn), 比同样为O(nlogn)时间复杂度的归并排序还要快. 快速排序似乎更偏爱乱序的数列, 越是乱序的数列, 它相比其他排序而言, 相对效率更高. Tips: 同选择排序相似, 快速排序每次交换的元素都有可能不是相邻的, 因此它有可能打破原来值为相同的元素之间的顺序. 因此, 快速排序并不稳定. 七、归并排序（Merging Sort） 归并排序是建立在归并操作上的一种有效的排序算法，1945年由约翰·冯·诺伊曼首次提出。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用，且各层分治递归可以同时进行。 1、基本思想归并排序算法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 2、算法描述归并排序可通过两种方式实现： 自上而下的递归 自下而上的迭代 一、递归法（假设序列共有n个元素）： ①. 将序列每相邻两个数字进行归并操作，形成 floor(n/2)个序列，排序后每个序列包含两个元素；②. 将上述序列再次归并，形成 floor(n/4)个序列，每个序列包含四个元素；③. 重复步骤②，直到所有元素排序完毕。 二、迭代法 ①. 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 ②. 设定两个指针，最初位置分别为两个已经排序序列的起始位置 ③. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 ④. 重复步骤③直到某一指针到达序列尾 ⑤. 将另一序列剩下的所有元素直接复制到合并序列尾 3、代码实现归并排序其实要做两件事： 分解：将序列每次折半拆分 合并：将划分后的序列段两两排序合并 因此，归并排序实际上就是两个操作，拆分+合并 如何合并？ L[first…mid]为第一段，L[mid+1…last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first…last]并且也有序。 首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]此时将temp[]中的元素复制给L[]，则得到的L[first…last]有序 如何分解？ 在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列分组；直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。 这里我写了递归算法如下： 12345678910111213141516171819202122232425262728293031323334353637/** * 归并排序（递归） * * ①. 将序列每相邻两个数字进行归并操作，形成 floor(n/2)个序列，排序后每个序列包含两个元素； * ②. 将上述序列再次归并，形成 floor(n/4)个序列，每个序列包含四个元素； * ③. 重复步骤②，直到所有元素排序完毕。 * @param arr 待排序数组 */public static int[] mergingSort(int[] arr)&#123; if(arr.length &lt;= 1) return arr; int num = arr.length &gt;&gt; 1; int[] leftArr = Arrays.copyOfRange(arr, 0, num); int[] rightArr = Arrays.copyOfRange(arr, num, arr.length); System.out.println("split two array: " + Arrays.toString(leftArr) + " And " + Arrays.toString(rightArr)); return mergeTwoArray(mergingSort(leftArr), mergingSort(rightArr)); //不断拆分为最小单元，再排序合并&#125;private static int[] mergeTwoArray(int[] arr1, int[] arr2)&#123; int i = 0, j = 0, k = 0; int[] result = new int[arr1.length + arr2.length]; //申请额外的空间存储合并之后的数组 while(i &lt; arr1.length &amp;&amp; j &lt; arr2.length)&#123; //选取两个序列中的较小值放入新数组 if(arr1[i] &lt;= arr2[j])&#123; result[k++] = arr1[i++]; &#125;else&#123; result[k++] = arr2[j++]; &#125; &#125; while(i &lt; arr1.length)&#123; //序列1中多余的元素移入新数组 result[k++] = arr1[i++]; &#125; while(j &lt; arr2.length)&#123; //序列2中多余的元素移入新数组 result[k++] = arr2[j++]; &#125; System.out.println("Merging: " + Arrays.toString(result)); return result;&#125; 由上, 长度为n的数组, 最终会调用mergeSort函数2n-1次。通过自上而下的递归实现的归并排序, 将存在堆栈溢出的风险。 以下是归并排序算法复杂度: 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(n) 从效率上看，归并排序可算是排序算法中的”佼佼者”. 假设数组长度为n，那么拆分数组共需logn，, 又每步都是一个普通的合并子数组的过程， 时间复杂度为O(n)， 故其综合时间复杂度为O(nlogn)。另一方面， 归并排序多次递归过程中拆分的子数组需要保存在内存空间， 其空间复杂度为O(n)。 和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(n log n）的时间复杂度。代价是需要额外的内存空间。 八、基数排序（Radix Sort） 基数排序的发明可以追溯到1887年赫尔曼·何乐礼在打孔卡片制表机（Tabulation Machine）, 排序器每次只能看到一个列。它是基于元素值的每个位上的字符来排序的。 对于数字而言就是分别基于个位，十位， 百位或千位等等数字来排序。 基数排序（Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 1、基本思想它是这样实现的：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 基数排序按照优先从高位或低位来排序有两种实现方案： MSD（Most significant digital） 从最左侧高位开始进行排序。先按k1排序分组, 同一组中记录, 关键码k1相等, 再对各组按k2排序分成子组, 之后, 对后面的关键码继续这样的排序分组, 直到按最次位关键码kd对各子组排序后. 再将各组连接起来, 便得到一个有序序列。MSD方式适用于位数多的序列。 LSD （Least significant digital）从最右侧低位开始进行排序。先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。LSD方式适用于位数少的序列。 2、算法描述我们以LSD为例，从最低位开始，具体算法描述如下： ①. 取得数组中的最大数，并取得位数；②. arr为原始数组，从最低位开始取每个位组成radix数组；③. 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 3、代码实现基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。 分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中 收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[]。对新形成的序列L[]重复执行分配和收集元素中的十位、百位…直到分配完该序列中的最高位，则排序结束 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 基数排序（LSD 从低位开始） * * 基数排序适用于： * (1)数据范围较小，建议在小于1000 * (2)每个数值都要大于等于0 * * ①. 取得数组中的最大数，并取得位数； * ②. arr为原始数组，从最低位开始取每个位组成radix数组； * ③. 对radix进行计数排序（利用计数排序适用于小范围数的特点）； * @param arr 待排序数组 */public static void radixSort(int[] arr)&#123; if(arr.length &lt;= 1) return; //取得数组中的最大数，并取得位数 int max = 0; for(int i = 0; i &lt; arr.length; i++)&#123; if(max &lt; arr[i])&#123; max = arr[i]; &#125; &#125; int maxDigit = 1; while(max / 10 &gt; 0)&#123; maxDigit++; max = max / 10; &#125; System.out.println("maxDigit: " + maxDigit); //申请一个桶空间 int[][] buckets = new int[10][arr.length]; int base = 10; //从低位到高位，对每一位遍历，将所有元素分配到桶中 for(int i = 0; i &lt; maxDigit; i++)&#123; int[] bktLen = new int[10]; //存储各个桶中存储元素的数量 //分配：将所有元素分配到桶中 for(int j = 0; j &lt; arr.length; j++)&#123; int whichBucket = (arr[j] % base) / (base / 10); buckets[whichBucket][bktLen[whichBucket]] = arr[j]; bktLen[whichBucket]++; &#125; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 int k = 0; for(int b = 0; b &lt; buckets.length; b++)&#123; for(int p = 0; p &lt; bktLen[b]; p++)&#123; arr[k++] = buckets[b][p]; &#125; &#125; System.out.println("Sorting: " + Arrays.toString(arr)); base *= 10; &#125;&#125; 以下是基数排序算法复杂度，其中k为最大数的位数： 平均时间复杂度 最好情况 最坏情况 空间复杂度 O(d*(n+r)) O(d*(n+r)) O(d*(n+r)) O(n+r) 其中，d 为位数，r 为基数，n 为原数组个数。在基数排序中，因为没有比较操作，所以在复杂上，最好的情况与最坏的情况在时间上是一致的，均为 O(d*(n + r))。 基数排序更适合用于对时间, 字符串等这些整体权值未知的数据进行排序。 Tips: 基数排序不改变相同元素之间的相对顺序，因此它是稳定的排序算法。 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 总结 各种排序性能对比如下图，有些排序未详细介绍，暂且放到这里。实例测试结果可以看这里：八大排序算法耗时对比 。 排序类型 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n²) O(n) O(n²) O(1) 稳定 选择排序 O(n²) O(n²) O(n²) O(1) 不稳定 直接插入排序 O(n²) O(n) O(n²) O(1) 稳定 折半插入排序 O(n²) O(n) O(n²) O(1) 稳定 希尔排序 O(n^1.3) O(nlogn) O(n²) O(1) 不稳定 归并排序 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(n) 稳定 快速排序 O(nlog₂n) O(nlog₂n) O(n²) O(nlog₂n) 不稳定 堆排序 O(nlog₂n) O(nlog₂n) O(nlog₂n) O(1) 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) 稳定 桶排序 O(n+k) O(n+k) O(n²) O(n+k) (不)稳定 基数排序 O(d(n+k)) O(d(n+k)) O(d(n+kd)) O(n+kd) 稳定 从时间复杂度来说： (1). 平方阶O(n²)排序：各类简单排序：直接插入、直接选择和冒泡排序； (2). 线性对数阶O(nlog₂n)排序：快速排序、堆排序和归并排序； (3). O(n1+§))排序，§是介于0和1之间的常数：希尔排序 (4). 线性阶O(n)排序：基数排序，此外还有桶、箱排序。 到此，很多人会注意到基数排序的时间复杂度是最小的，那么为什么却没有快排、堆排序流行呢？我们看看下图算法导论的相关说明： 基数排序只适用于有基数的情况，而基于比较的排序适用范围就广得多。另一方面是内存上的考虑。作为一种通用的排序方法，最好不要带来意料之外的内存开销，所以各语言的默认实现都没有用基数排序，但是不能否认基数排序在各领域的应用。 时间复杂度极限当被排序的数有一些性质的时候（比如是整数，比如有一定的范围），排序算法的复杂度是可以小于O(nlgn)的。比如： 计数排序 复杂度O( k+n) 要求：被排序的数是0~k范围内的整数 基数排序 复杂度O( d(k+n) ) 要求：d位数，每个数位有k个取值 桶排序 复杂度 O( n ) （平均） 要求：被排序数在某个范围内，并且服从均匀分布 但是，当被排序的数不具有任何性质的时候，一般使用基于比较的排序算法，而基于比较的排序算法时间复杂度的下限必须是O(nlgn)。 参考很多高效排序算法的代价是 nlogn，难道这是排序算法的极限了吗？ 说明 当原表有序或基本有序时，直接插入排序和冒泡排序将大大减少比较次数和移动记录的次数，时间复杂度可降至O（n）； 而快速排序则相反，当原表基本有序时，将蜕化为冒泡排序，时间复杂度提高为O（n2）； 原表是否有序，对简单选择排序、堆排序、归并排序和基数排序的时间复杂度影响不大。 参考资料 数据结构可视化：visualgo，Sorting Algorithms Animations，CodePen &amp; sort it out 一个显示排序过程的PYTHON脚本 排序算法测试：Lab 1: Sorting - 哥德堡大学课件（University of Gothenburg） Sorting Algorithm Animations - 一个排序算法比较的网站 Sorting - 卡内基梅隆大学课件 数据结构常见的八大排序算法（详细整理） 必须知道的八大种排序算法【java实现】 十大经典排序算法 视觉直观感受 7 种常用的排序算法 JS中可能用得到的全部的排序算法 总结5种比较高效常用的排序算法 常见排序算法C++总结]]></content>
      <tags>
        <tag>Algorithms,</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EveryThing About Operation System]]></title>
    <url>%2F2019%2F12%2F27%2FEveryThing-About-Operation-System%2F</url>
    <content type="text"><![CDATA[堆和栈的区别堆 一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收，分配方式类似于链表。堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些堆可以被看成是一棵树，如：堆排序。 栈 由操作系统（编译器）自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈栈使用的是一级缓存， 它们通常都是被调用时处于存储空间中，调用完毕立即释放。一种先进后出的数据结构 用户态，内核态以及如何切换。 内核态：运行操作系统程序，控制计算机的硬件资源，并提供上层应用程序运行的环境，运行在高特权级上。内核态切换到用户态的途径——&gt;设置程序状态字。 用户态：运行用户程序上层应用程序的活动空间，运行在低特权级别上。为了使上层应用能够访问到这些资源，内核为上层应用提供访问的接口。用户态切换到内核态的唯一途径(申请外部资源)——&gt;中断/异常/系统调用(读写文件,申请堆内存,缺页(虚拟内存地址没有映射到物理内存地址,在Java中New一个对象))。系统调用 System， Callaccept:套接字的客户端连接套接字，bind套接字的服务端监听端口 信号和信号量的关系 信号：（signal）是一种处理异步事件的方式。信号时比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身。linux除了支持unix早期的信号语义函数，还支持语义符合posix.1标准的信号函数sigaction。 信号量：（Semaphore）进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。进程和线程，进程之间的通信方式等啥是进程，啥是线程，他们的本质区别？我们运行一个程序时，数据放在哪里？代码放在哪里？咋就还要分堆和栈？线程切换时是上下文是啥意思？ 虚拟地址是什么鬼东西？线程需要那么多种状态干啥子？什么是乐观锁、悲观锁？死锁是怎么造成的？解决死锁的策略有哪些？等等2、进程、线程究竟是由什么组成的？有哪些数据？ 3、内存管理，包括：虚拟内存（重点）、分页、分段、分页系统地址映射、内存置换算法（重点）。 安全系统不会死锁 进程是什么进程是具有一定独立功能的程序，它是系统进行资源分配和调度的一个独立单位，重点在系统调度和独立的单位，也就是说进程是可以独立运行的一段程序。 线程是什么线程是进程的一个实体，是CPU调度和分配的基本单位，它是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源，在运行时，只是暂用一些计数器，寄存器，和栈。 进程与线程的关系 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程（通常说的主线程）。 资源分配给进程，同一进程的所有线程共享该进程的所有资源。 线程在执行过程中，需要协作同步，不同进程的线程间要利用消息通信的方法实现同步。 处理机分配给线程，即真正在处理机上运行的是线程。 线程是指进程内的一个执行单元，也是进程内的可调度实体。 进程会释放资源，线程不会。从4个角度来分析进程与线程之间的区别 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位 并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可以并发执行 拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源 系统开销：创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O设备等，OS所付出的开销显著大于在创建或撤销线程时的开销，进程切换的开销也远大于线程切换的开销进程有几种状态 就绪状态：进程已经获得除处理机以外的所有资源，等待分配处理机资源 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数目 阻塞状态：进程等待某种条件，在条件满足之前无法运行线程有几种状态 执行状态：表示线程已经获得处理机而正在运行 就绪状态：指线程已经具备了各种执行条件，只需再获得CPU便可以立即执行难 阻塞状态：线程在执行过程中因某事受阻而处于暂停状态操作系统进程调度有哪几种 非抢占式方式：采用这种调度方式时，一旦把处理机分配给某个进程后，就一直让它运行下去，决不会因为时钟中断或任何其它原因去抢占当前正在运行进程的处理机，直至该进程完成，或发生某种事件而被阻塞时，才把处理机分配给其他进程 抢占式方式：这种调度方式允许调度程序根据某种原则，去暂停某个正在执行的进程，将已经分配给该进程的处理机重新分配给另一进程，在现代OS中广泛采用抢占方式。进程为什么需要同步进程同步机制的主要任务是对多个相关进程在执行次序上进行协调，使得并发执行的各个进程之间能按照一定的规则或时序共享系统资源，并能很好的相互合作，从而使得程序的执行具有可再现性 列举几种进程同步机制，并说明其优缺点 硬件同步机制： 信号量机制： 管程机制：进程之间通信的途径进程之间通信方向 管道：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用，进程的亲缘关系通常是指父子进程关系 有名管道：有名管道也是半双工的通信方式，但是它允许无亲缘关系的进程间的通信 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问，它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源，因此，主要作为进程间以及同一进程内不同线程之间的同步手段 消息队列：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识，消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点 信号：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生 共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程通信方式运行效率低而专门设计的，它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信 Socket(套接字)：套接字可以用于不同的进程间的通信线程之间通信的途径 锁机制：包括互斥锁，条件变量，读写锁 互斥锁提供了以排他方式防止数据结构被并发修改的方法 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止，对条件的测试是在互斥锁的保护下进行的，条件变量始终与互斥锁一起使用 读写锁允许多个线程同时读共享数据，而对写操作是互斥的 信号量机制：包括无名线程信号量和命名线程信号量 信号机制：类似进程间的信号处理 注意：线程间的通信的目的主要是用于线程的同步，所以线程没有像进程通信中的用于数据交换的通信机制 多线程如何同步 临界区（Critical Section）、互斥量（Mutex）、信号量（Semaphore）、事件（Event）的区别 临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。 互斥量：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享 .互斥量比临界区复杂。因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。 信号量：它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目 .信号量对象对线程的同步方式与前面几种方法不同，信号允许多个线程同时使用共享资源，这与操作系统中的PV操作相同。它指出了同时访问共享资源的线程最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。 PV操作及信号量的概念都是由荷兰科学家E.W.Dijkstra提出的。信号量S是一个整数，S大于等于零时代表可供并发进程使用的资源实体数，但S小于零时则表示正在等待使用共享资源的进程数。 P操作申请资源： S减1； 若S减1后仍大于等于零，则进程继续执行； 若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转入进程调度。 V操作释放资源： S加1； 若相加结果大于零，则进程继续执行； 若相加结果小于等于零，则从该信号的等待队列中唤醒一个等待进程，然后再返回原进程继续执行或转入进程调度。 事件：通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作 . 总结： 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说它可以跨越进程使用。所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。 互斥量（Mutex），信号灯（Semaphore），事件（Event）都可以被跨越进程使用来进行同步数据操作，而其他的对象与数据同步操作无关，但对于进程和线程来讲，如果进程和线程在运行状态则为无信号状态，在退出后为有信号状态。所以可以使用WaitForSingleObject来等待进程和线程退出。 通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号灯对象可以说是一种资源计数器。 死锁的定义如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程是死锁的 进程死锁的原因多个进程对资源的争夺，包括对不可抢占资源和对可消耗资源 进程死锁的4个必要条件 互斥条件：进程对所分配到的资源进行排它性使用，即在一段时间内，其资源只能被一个进程占用，如果此时还有其它进程请求该资源，则请求进程只能等待，直至占有该资源的进程用完释放 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已经被其它进程占有，此时请求进程被阻塞，但对自己已经获得的资源保持不放 不可抢占条件：进程已经获得的资源在未使用完之前不能被抢占，只能在进程使用完时由自己释放 循环等待条件：在发生死锁时，必然存在一个进程-资源循环链，即进程集合｛P0,P1,……,PN｝中的P0正在等待一个P1占用的资源，P1正在等待P2占用的资源，……，PN 正在等待P0占用的资源进程死锁的处理 预防死锁：通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一种 避免死锁：在资源的动态分配过程中，用某种方法防止系统进入不安全状态 检测死锁：通过检测机构及时检测出死锁的发生，然后采取适当的措施，把进程从死锁中解脱出来 解除死锁：当检测到系统中已经发生死锁时，采取相应的措施，将进程从死锁状态解脱出来，常用的方法是撤销一些进程，回收他们的资源，将它们分配给已经处于阻塞状态的进程，使其能够继续运行描述实时操作系统的基本特征实时操作系统是指操作系统工作时，其各种资源可以根据需要随时进行动态分配，由于各种资源可以进行动态分配，因此，其处理事务的能力较强 换言之，在特定时间内完成特定的任务，具有实时性与可靠性 操作系统中断与轮询的基本特点 轮询：对I/O设备的程序轮询的方式是早期的计算机系统对I/O设备的一种管理方式，它定时对各种设备轮流询问一遍有无处理要求。轮询占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已经很少应用 中断：中断是指CPU在正常运行程序的过程中，由于发生的内部或外部的特定的事件，使得CPU中断正在运行的程序，而转到响应的服务程序去处理 什么是临界区，如何解决冲突每个进程中访问临界资源的那段程序称为临界区，每次只准许一个进程进入临界区，进入后不允许其他进程进入 解决冲突的方法： 如果有若干个进程要求进入空闲的临界区，一次仅允许一个进程进入 任何时候，处于临界区内的进程不可以多于一个，如果已经有进程进入自己的临界区，则其他所有试图进入临界区的进程必须等待 进入临界区内的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区 如果进程不能进入自己的临界区，则应该让出CPU，避免进程出现“忙碌”现象。windows下内存是如何管理的windows操纵内存可以分为两个层面，物理内存和虚拟内存。 进程调度算法(长中短) 时间片轮转调度算法（RR）：给每个进程固定的执行时间，根据进程到达的先后顺序让进程在单位时间片内执行，执行完成后便调度下一个进程执行，时间片轮转调度不考虑进程等待时间和执行时间，属于抢占式调度。优点是兼顾长短作业；缺点是平均等待时间较长，上下文切换较费时。适用于分时系统。 先来先服务调度算法（FCFS）：根据进程到达的先后顺序执行进程，不考虑等待时间和执行时间，会产生饥饿现象。属于非抢占式调度，优点是公平，实现简单；缺点是不利于短作业。 优先级调度算法（HPF）：在进程等待队列中选择优先级最高的来执行。 多级反馈队列调度算法：将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境。 高响应比优先调度算法：根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。 进程调度算法(长中短) 长程调度，把作业后背队列调入内存，又称为作业调度或高级调度，这种调度将已进入系统并处于后备状态的作业按某种算法选择一个或一批，为其建立进程，并进入主机，当该作业执行完毕时，还负责回收系统资源，在批处理系统中，需要有作业调度的过程，以便将它们分批地装入内存，在分时系统和实时系统中，通常不需要长期调度。它的频率比较低，主要用来控制内存中进程的数量。 中程调度，内外存阻塞进程来回切换，又称为交换调度。它的核心思想是能将进程从内存或从CPU竞争中移出，从而降低多道程序设计的程度，之后进程能被重新调入内存，并从中断处继续执行，这种交换的***作可以调整进程在内存中的存在数量和时机。其主要任务是按照给定的原则和策略，将处于外存交换区中的就绪状态或等待状态的进程调入内存，或把处于内存就绪状态或内存等待状态的进程交换到外存交换区。 短程调度，把进程分配给CPU执行。又称为进程调度、低级调度或微观调度。这也是通常所说的调度，一般情况下使用最多的就是短期调度。它的主要任务是按照某种策略和算法将处理机分配给一个处于就绪状态的进程，分为抢占式和非抢占式。 可以从下图中清晰的看到这些调度之间的区别。 磁盘寻道算法 先来先服务算法（FCFS）First Come First Service 这是一种比较简单的磁盘调度算法。它根据进程请求访问磁盘的先后次序进行调度。此算法的优点是公平、简单，且每个进程的请求都能依次得到处理，不会出现某一进程的请求长期得不到满足的情况。此算法由于未对寻道进行优化，在对磁盘的访问请求比较多的情况下，此算法将降低设备服务的吞吐量，致使平均寻道时间可能较长，但各进程得到服务的响应时间的变化幅度较小。在单用户系统环境中，I/O队列的长度通常为1，因此，先来先服务FCFS算法是最经济实惠的磁盘调度算法. 先来先服务 （125）86.147.91.177.94.150.102.175.130 最短寻道时间优先算法（SSTF） Shortest Seek Time First 该算法选择这样的进程，其要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短，该算法可以得到比较好的吞吐量，但却不能保证平均寻道时间最短。其缺点是对用户的服务请求的响应机会不是均等的，因而导致响应时间的变化幅度很大。在服务请求很多的情况下，对内外边缘磁道的请求将会无限期的被延迟，有些请求的响应时间将不可预期。最短寻道时间优先（125）130.147.150.175.177.102.94.91.86 扫描算法（SCAN）电梯调度 扫描算法不仅考虑到欲访问的磁道与当前磁道的距离，更优先考虑的是磁头的当前移动方向。例如，当磁头正在自里向外移动时，扫描算法所选择的下一个访问对象应是其欲访问的磁道既在当前磁道之外，又是距离最近的。这样自里向外地访问，直到再无更外的磁道需要访问才将磁臂换向，自外向里移动。这时，同样也是每次选择这样的进程来调度，即其要访问的磁道，在当前磁道之内，从而避免了饥饿现象的出现。由于这种算法中磁头移动的规律颇似电梯的运行，故又称为电梯调度算法。此算法基本上克服了最短寻道时间优先算法的服务集中于中间磁道和响应时间变化比较大的缺点，而具有最短寻道时间优先算法的优点即吞吐量较大，平均响应时间较小，但由于是摆动式的扫描方法，两侧磁道被访问的频率仍低于中间磁道。电梯调度（125）102.94.91.86.130.147.150.175.177 循环扫描算法（CSCAN） 循环扫描算法是对扫描算法的改进。如果对磁道的访问请求是均匀分布的，当磁头到达磁盘的一端，并反向运动时落在磁头之后的访问请求相对较少。这是由于这些磁道刚被处理，而磁盘另一端的请求密度相当高，且这些访问请求等待的时间较长，为了解决这种情况，循环扫描算法规定磁头单向移动。例如，只自里向外移动，当磁头移到最外的被访问磁道时，磁头立即返回到最里的欲访磁道，即将最小磁道号紧接着最大磁道号构成循环，进行扫描。循环扫描 （125）130.147.150.175.177.86.91.94.102 學長筆記連結 https://kim85326.github.io/2018/01/09/CH6-%E8%A1%8C%E7%A8%8B%E6%8E%92%E7%8F%AD-(Process-Scheduling)/信號 https://kim85326.github.io/2018/01/10/CH10-%E6%AA%94%E6%A1%88%E7%B3%BB%E7%B5%B1-(File-System)/ 檔案系統https://kim85326.github.io/2018/01/09/CH8-%E8%A8%98%E6%86%B6%E9%AB%94%E7%AE%A1%E7%90%86-(Memory-Management-Strategies)/記憶體管理 https://kim85326.github.io/2018/01/09/CH9-%E8%99%9B%E6%93%AC%E8%A8%98%E6%86%B6%E9%AB%94%E7%AE%A1%E7%90%86-(Virtual-Memory-Management)/虛擬記憶裡 lru]]></content>
      <tags>
        <tag>Operation System</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SDN_OpenFlow]]></title>
    <url>%2F2019%2F11%2F06%2FSDN-OpenFlow%2F</url>
    <content type="text"><![CDATA[107 SDNa10715005 任偉Boot onosproject Configuration Json file and Create Topo using command line 已經解決ONOS GUI中的topology Ping 成功的畫面 Switch s3的forwarding table 還沒有解決h1 ping h2產生有兩條路徑的topology 讓ping packet走較長的路徑 原来是 现在想让他变成 Pre-requisites:VirtualBox Configuration:JDK Configuration in Ubuntu Install ONOS on Ubuntu Using Linux command:modification file in Linux gedit Reference: Basic ONOS Tutorial OpenFlow]]></content>
      <tags>
        <tag>ONOS OpenFlow SDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CV]]></title>
    <url>%2F2019%2F11%2F05%2FCV%2F</url>
    <content type="text"><![CDATA[pix2pixHD簡介 — High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs 【熟肉】线性代数的本质 - 01 - 向量究竟是什么？ Machine-Learning-Notes]]></content>
  </entry>
  <entry>
    <title><![CDATA[108FALL]]></title>
    <url>%2F2019%2F10%2F18%2F108FALL%2F</url>
    <content type="text"><![CDATA[CS5095701 Advanced Database Systems CourseInfo PrensentationSlides 11/15 Proposal presentation (all 14 groups) 11/22 Mid-term exam 11/29 paper presentation (4 groups)(sequence 1~4) Project proposal:You are required to propose a database related research project in this course. You are encouraged to have a publication as a goal for your project. A list of project ideas is listed below. You proposal should include the following aspects: importance of the proposed project your algorithm and ideas main contributions the design of the software you propose to build how you propose to evaluate your ideas the design of the experiments literature survey You will present to the class about your proposal (~ 5 minutes) and write a proposal report (2~4 pages in IEEE format).CS5014701 電腦與機器人視覺 Computer and Robot Vision Everybody Dance NOW Joint Discriminative and Generative Learning for Person Re-identification CS5146701 虛擬化網路及應用 Virtualized Networks and Applications Proposal Catch up from Flicknetwork virtualization CS5023701 Knowledge-Based SystemsRevisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU with Generalized Hamming Network CS5141701 深度學習導論及其應用 Introduction to Deep Learning and Its ApplicationsHung-yi Lee’S CourseInfo 李宏毅机器学习笔记(LeeML-Notes) 【財金學程】FBG006301 品牌價值創新講座 Seminar on Brand Value Innovation柯達企業失敗個案分析 TCG037301 親近經典智慧 Wisdom in Classics畜牧業的陰謀]]></content>
  </entry>
  <entry>
    <title><![CDATA[Recommend System]]></title>
    <url>%2F2019%2F10%2F03%2FRecommend-System%2F</url>
    <content type="text"><![CDATA[http://wepon.me/ pkuhttps://coladrill.github.io/about/ seuhttps://github.com/ColaDrill/2018spa 推荐系统 https://www.zhihu.com/people/coladrill/activities推荐系统 必看 手写xgboost Special ProjectsPreviousThe Uni require all the undergraduate student to reach out the Special Projects. Mission:Recommend systems based on the Collaborative Filtering Reference: Reinforcement Spinning Up Introduction to Deep Learning STAT 157, UC Berkeley, Spring, 2019Reference By 在伯克利教深度学习 Talk in Mandarin Intro CNN Elegant in code, simple in core IEEE International Conference on Signal, Information and Data Processing 2019Automatic Digital Recognition of Multiple Electricity Dashboards, (accepted) [EI]]]></content>
  </entry>
  <entry>
    <title><![CDATA[108_FALL]]></title>
    <url>%2F2019%2F09%2F28%2FPrepare4Interview%2F</url>
    <content type="text"><![CDATA[计算机网络和操作系统 一个浏览器发出请求：把所有流程连起来把想到的知识梳理一遍，http传输，json解析，tomcat收到请求， springmvc解析请求， 传给服务层， 请求数据库， 查询数据库， 数据库查找索引，数据库返回数据。 硬盘转速和文件系统读写速度的关系 加密为什么不用https 九章算法 《Java入门与基础算法班》 Java语言基础：数组，字符串，函数，类，对象，引用 Java算法基础： 枚举法，贪心法，递归，链表，栈，树，递归，哈希表，排序 问题类型 操作系统：（找手机相册里面的图片） 素质测试数字推理和图形推理字符串排重并排序 专业测试算法一级中药dijkstralru缓存机制 算法也可以考系统设计链表排序lru如何保证o1的查找和修改 天哥面试：（必会） 1:写一个二叉树的层次遍历或者链表的取中心点+把链表中心点后的部分反转 2:快速排序和二分归并排序有什么不同，最坏和平均时间复杂度分半是多少 进程和线程的区别是什么，除了时间片轮转法外，你还知道什么进程调度算法 线程持有锁的变量时，线程被切换了（若只有cpu时间片到了的话，不会释放锁，不然也就不存在死锁问题了），锁会被释放吗？不会，进程释放所有资源，线程不会， Java实现b+树，链表和栈，霍夫曼。（Java集合的底层实现）hashmap dp和写正则 逻辑回归和svm都可以用来作二分类，他们的lost function有什么不同 写一个dnn或者线性回归的反向传播算法的推导 svm中核函数起到的作用， 信息增益是怎么用于决策树中的特征选择 pca的原理是什么 cnn中的resnet中的res指什么 depthwise有什么好处 计算一下一个cnn卷积一次的计算量 为什么需要激活函数 二级中药红黑树，平衡树，b+树，跳跃表 Java基础 基础数据类型 protected修饰符 抽象类和接口区别 Java内存结构（重要） Java并发和线程同步。同步机制和锁解释一下 synchronized和lock区别 类，继承，多态的概念 设计爬虫，你需要设计什么 wait()和sleep(区别) 多线程的理解 hashtable和hashmap区别 synchronized如何保证原子性：monitor ，继续深入：如何保证读取对象头和修改对象头的原子性* 设计模式 设计模式：手画代理模式 数据库事务一定会锁表吗 项目找到一个痛点 难点：（特色模块）：单点登录，全局搜索（搜关键字，快速找到） 华为 6个数找出里面最大的两个数 一个四则运算字符串写程序运算出结果]]></content>
      <tags>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Computer Networks]]></title>
    <url>%2F2019%2F08%2F28%2FComputer-Networkds%2F</url>
    <content type="text"><![CDATA[##计算机网络常见面试题 经典面试题：从 URL 输入到页面展现到底发生什么之会话顺序？ 涉及到的协议(1) 应用层：HTTP(WWW访问协议)，DNS(域名解析服务) (2) 传输层：TCP(为HTTP提供可靠的数据传输)，UDP(DNS使用UDP传输) (3) 网络层：IP(IP数据数据包传输和路由选择)，ICMP(提供网络传输过程中的差错检测)，ARP(将本机的默认网关IP地址映射成物理MAC地址) 从 URL 输入到页面展现到底发生什么之分布式DNS原理及解析顺序，浏览器如何通过域名去查询 URL 对应的 IP 路由器是一种三层设备，主要使用ip地址进行网间路由查询与ip包的转发。而交换机是一种二层设备，使用MAC地址进行寻址，实现一个网络内的数据帧的转发。A类网络为1到126B类网络为129到191C类网络为192到223IPV4是一个32位的地址，用4个十进制数字表示。以C类地址192.168.24.1为例，其中前24位是网络地址，后8位是主机地址。如果两个IP地址在同一个子网内，则网络地址一定相同。 机器A的ip地址为 202.96.128.130，子网掩码为255.255.255.128，则IP地址的网络号为202.96.128，主机号为130 二层交换机工作于OSI模型的第二层数据链路层（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），它可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这写地址与对应的连接端口记录在自己内部的一个地址表中。 三层交换机（路由器）三层交换机工作于OSI模型中的第三层网络层，主要目的是加快大型局域网内部的数据交换。二层交换机是根据MAC地址进行处理数据， 三层交换机是根据IP地址进行处理数据 子网掩码：子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分.通过AND按位与运算即可确定。 DNS是应用层协议 网关是从一个网络到另一个网络的关口，或者说是从一个网络通向其他网络的IP地址。比如有网络A和网络B，A的IP范围192.168.1.1 ~ 192.168.1.254，子网掩码255.255.255.0，B的IP范围是192.168.2.1 ~ 192.168.2.254，子网掩码为255.255.255.0.在没有路由器的情况下，A网络和B网络是不能进行TCP？IP通信的。TCP/IP协议会判定两个网络中的主机属于不同的网络。如果网络A中的主机发现数据包的目的主机不在自己所属的网络中，它就会把数据包发送给自己的网关，再由网关转发给网络B的网关，最终网络B的网关再转发个网络B中的某个主机。 ARP原理 只要知道了目标地址的IP，就可以想这个目标IP发送数据包，但是，在网络层以下的链路层，实际进行通信的还是MAC，实际上也就是两个网卡之间的通信。ARP地址解析协议以IP地址为线索，用来定位下一个应该接收数据包的主机的MAC地址。ARP是根据IP地址获取MAC地址的一个网络层协议。 A类地址：第1到8位是网络地址，首位以二进制0开头，后24位二进制是主机地址。B类地址：第1到16位是网络地址，前两位是二进制10，后16位二进制是主机地址。C类地址：第1到24位是网络地址，前三位是二进制110，后8位二进制是主机地址。D类地址：第1到32位是网络地址，前四位是二进制1110，没有主机地址。 所以只有设置好网关的IP，TCP/IP协议才能实现不同网络之间的通信。网关的IP地址是具有路由功能的设备的IP地址，也就是路由器。 网络传输中的心跳控制 为什么连接的时候是三次握手，关闭的时候却是四次握手？因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同 步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你 发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 DNS的原理HTTP报文格式、头部字段等 请求方法“方法URL议/版本”：GET/sample.jsp HTTP/1.1 请求头(Request Header)请求头包含许多有关的客户端环境和请求正文的有用信息。请求头可以声明浏览器所用的语言，请求正文的长度等。 123456Accept:image/gif.image/jpeg.*/*Accept-Language:zh-cnConnection:Keep-AliveHost:localhostUser-Agent:Mozila/4.0(compatible:MSIE5.01:Windows NT5.0)Accept-Encoding:gzip,deflate. 请求正文 请求头和请求正文之间是一个空行，这个行非常重要，它表示请求头已经结束，接下来的是请求正文。请求正文中可以包含客户提交的查询字符串信息：username=jinqiao&amp;password=1234 session和cookiecookie是Web服务器发送给浏览器的一块信息。浏览器会在本地文件中给每一个Web服务器存储cookie。以后浏览器在给特定的Web服务器发请求的时候，同时会发送所有为该服务器存储的cookie。下面列出了session和cookie的区别： 无论客户端浏览器做怎么样的设置，session都应该能正常工作。客户端可以选择禁用cookie，但是，session仍然是能够工作的，因为客户端无法禁用服务端的session。 在存储的数据量方面session和cookies也是不一样的。session能够存储任意的Java对象，cookie只能存储String类型的对象。IPv4和IPv6 地址空间不同，IPv4中规定IP地址长度为32，而IPv6中IP地址的长度为128。 路由表大小不同，IPv6的路由表相比IPv4的更小。 安全性不同，IPv6的安全性更高，在使用IPv6的网络时，用户可对网络层的数据进行加密。 数字证书如何生成DHCP动态主机配置协议，是一种让系统得以连接到网络上，并获取所需的配置参数的手段 ICMP ping检测网络通信故障和实现链路追踪 ICMP（Internet Control Message Protocol）Internet控制报文协议。它是TCP/IP协议簇的一个子协议，用于在IP主机、路由器之间传递控制消息。 从网络加载一个10M的图片，说下注意事项图解TCP的3次握手和四次挥手TCP协议如何来保证传输的可靠性如何验证证书的合法性Get与POST的区别 get请求参数在url地址上，直接暴露，post请求的参数放body部分，按F12也直接暴露了 GET产生一个TCP数据包；POST产生两个TCP数据包。长的说：对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200ok（返回数据）。 get传输量小,因为受URL长度限制,但效率较低。post可以传输大量数据,所以上传文件时只能用post方式TCP的拥塞处理TCP是如何进行流量控制TCP和UDP分别对应的常见应用层协议IP地址的分类有了唯一的Mac地址为啥还需要IP地址？交换机、集线器与路由器有什么区别？网桥的作用网桥工作在数据链路层，将两个LAN连起来，根据MAC地址来转发帧，可以看作一个“低层的路由器”（路由器工作在网络层，根据网络地址如IP地址进行转发 过滤通信量。网桥可以使用局域网的一个网段上各工作站之间的信息量局限在本网段的范围内，而不会经过网桥溜到其他网段去。 扩大了物理范围，也增加了整个局域网上的工作站的最大数目。 可使用不同的物理层，可互连不同的局域网。 提高了可靠性。如果把较大的局域网分割成若干较小的局域网，并且每个小的局域网内部的信息量明显地高于网间的信息量，那么整个互连网络的性能就变得更好网桥缺点 由于网桥对接收的帧要先存储和查找站表，然后转发，这就增加了时延。 在MAC子层并没有流量控制功能。当网络上负荷很重时，可能因网桥缓冲区的存储空间不够而发生溢出，以致产生帧丢失的现象。 具有不同MAC子层的网段桥接再一起时，网桥在转发一个帧之前，必须修改帧的某些字段的内容，以适合另一个MAC子层的要求，增加时延。 网桥只适合于用户数不太多（不超过几百个）和信息量不太大的局域网，否则有时会产生较大的广播风暴。网络接口卡（网卡）的功能？网络接口卡即网卡也就是网络适配器，接收上一层的ip数据报，并将其封装成帧发送到局域网中。一般的适配器都包含物理层和数据链路层这两层的功能。网络接口卡实现的是TCP/IP四层参考模型中的网络接口层，对应OSI七 层参考模型中的 物理层协议和数据链路层协议。 URI和URL的区别URI标记了一个网络资源，仅此而已； URL标记了一个WWW互联网资源（用地址标记），并给出了他的访问地址 GET请求中URL编码的意义 首先 url 在网络中传输时使用ascll编码的，也就是说，在浏览器中一个请求发出去最终是使用ascll编码的，这样子要是我们发出去的请求中包含有非ascll字符的话，就会被浏览器编码，但是，但是，各个浏览器对于url的编码方式是不一样的！！！这就会导致很大的问题，同一个url在不同的浏览器中实际发出的url都不一样了，服务器还要怎么解析这些请求的？要解决这个问题效率最最高的方法就是在前端中对要发出的url使用js 进行编码，编码后的url就只剩下ascll编码中有的字符了。这就是URL编码。URL编码指的是对网址上的不安全的字符，例如中文，进行编码，编码后的中文方便在网络上传输。URL编码是负责把URL里面的空格和其他的特殊字符替换成对应的十六进制表示，反之就是解码。 APPlication,Session和Cookie的区别彻底弄懂session，cookie，tokenhttp缓存机制，浏览器缓存到底是什么如何避免浏览器缓存什么是分块传送。如果 HTTP 整块传输，需要提前设置 Content-Length。分块传输编码（Chunked transfer encoding）允许服务端在不预先给出报文长度的情况下，分块将输出发送给客户端。输出空段表示报文结束。 几种网络攻击方法 XSS （跨站脚本攻击) 【攻击者在 Web 页面中插入恶意脚本，当用户浏览页面时，促使脚本执行，从而达到攻击目的】 (1)客服端及服务端用户的输入数据进行双重验证(2)对所有的数据进行适当的编码(3)设置 HTTP Header： “X-XSS-Protection:1” DDos 分布式拒绝服务，【发送大量请求，使服务器瘫痪】 服务器加带宽（成本昂贵）2.使用DDos 防御产品 CSRF 跨站请求伪造 【用户本地存储cookie，攻击者利用用户的cookie进行认证，然后伪造用户发出请求】 检查标准请求头 ，确认是否同源(2)检查CSRF token SQL注入(通过用户输入,拼接成恶意Sql,并执行) 预编译SQL 2.验证用户输入3.用户输入编码 XXS攻击和SQL注入MySQL最全的重要知识点学习 SSL/TLS协议运行机制的概述 HTTP 常见面试题http协议有哪几种请求方式？ GET:用于请求访问已经被URI(统一资源标识符)识别的资源,可以通过URL传参给服务器 POST:用于传输信息给服务器,主要功能与GET方法类似,但一般推荐使用POST方式 PUT:传输文件,报文主体中包含文件内容,保存到对应URI位置 HEAD:获得报文首部,与GET方法类似,只是不返回报文主体,一般用于验证URI是否有效 DELETE:删除文件,与PUT方法相反,删除对应URI位置的文件 OPTIONS:查询响应URI支持的HTTP方法 http和https区别？HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。总的来说： HTTPS=SSL+HTTP https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。（这个只是默认端口不一样，实际上端口是可以改的） http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 HTTP请求报文与响应报文格式请求报文包含三部分： 请求行：包含请求方法、URI、HTTP版本信息 请求头部（headers）字段 请求内容实体(body) 响应报文包含三部分： 状态行：包含HTTP版本、状态码、状态码的原因短 响应头部（headers）字段 响应内容(body)实体 HTTP状态码 200 请求已成功，请求所希望的响应头或数据体将随此响应返回。 201 请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回 202 服务器已接受请求，但尚未处理 301 （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302 （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304 （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。 305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。 307 （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。 401 当前请求需要用户验证。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书 403 服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交 404 请求失败，请求所希望得到的资源未被在服务器上发现 500 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。 501 服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 502 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。]]></content>
      <tags>
        <tag>Computer Networks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Travel]]></title>
    <url>%2F2019%2F05%2F17%2FTravel%2F</url>
    <content type="text"><![CDATA[Europe Europe AsianTAIWAN taiwan]]></content>
      <categories>
        <category>Diary</category>
      </categories>
      <tags>
        <tag>Travel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Design Pattern-Behavioral-pattern]]></title>
    <url>%2F2019%2F05%2F16%2FDesign-Pattern-Behavioral-pattern%2F</url>
    <content type="text"><![CDATA[Design Patterns” Is a Bad Name From laike9m行为型模式 行为型模式关注的是各个类之间的相互作用，将职责划分清楚，使得我们的代码更加地清晰。策略模式策略模式太常用了，所以把它放到最前面进行介绍。它比较简单，我就不废话，直接用代码说事吧。下面设计的场景是，我们需要画一个图形，可选的策略就是用红色笔来画，还是绿色笔来画，或者蓝色笔来画。首先，先定义一个策略接口：public interface Strategy { public void draw(int radius, int x, int y);}然后我们定义具体的几个策略：123456789101112131415161718public class RedPen implements Strategy &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println(&amp;quot;用红色笔画图，radius:&amp;quot; + radius + &amp;quot;, x:&amp;quot; + x + &amp;quot;, y:&amp;quot; + y); &#125;&#125;public class GreenPen implements Strategy &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println(&amp;quot;用绿色笔画图，radius:&amp;quot; + radius + &amp;quot;, x:&amp;quot; + x + &amp;quot;, y:&amp;quot; + y); &#125;&#125;public class BluePen implements Strategy &#123; @Override public void draw(int radius, int x, int y) &#123; System.out.println(&amp;quot;用蓝色笔画图，radius:&amp;quot; + radius + &amp;quot;, x:&amp;quot; + x + &amp;quot;, y:&amp;quot; + y); &#125;&#125;使用策略的类：1234567891011public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeDraw(int radius, int x, int y)&#123; return strategy.draw(radius, x, y); &#125;&#125;客户端演示：1234public static void main(String[] args) &#123; Context context = new Context(new BluePen()); // 使用绿色笔来画 context.executeDraw(10, 0, 0);&#125;这个时候，大家有没有联想到结构型模式中的桥梁模式，它们其实非常相似，我把桥梁模式的图拿过来大家对比下：要我说的话，它们非常相似，桥梁模式在左侧加了一层抽象而已。桥梁模式的耦合更低，结构更复杂一些。 观察者模式观察者模式对于我们来说，真是再简单不过了。无外乎两个操作，观察者订阅自己关心的主题和主题有数据变化后通知观察者们。首先，需要定义主题，每个主题需要持有观察者列表的引用，用于在数据变更的时候通知各个观察者：12345678910111213141516171819202122public class Subject &#123; private List&amp;lt;Observer&amp;gt; observers = new ArrayList&amp;lt;Observer&amp;gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; // 数据已变更，通知观察者们 notifyAllObservers(); &#125; // 注册观察者 public void attach(Observer observer) &#123; observers.add(observer); &#125; // 通知观察者们 public void notifyAllObservers() &#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125;&#125;定义观察者接口：1234public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125;其实如果只有一个观察者类的话，接口都不用定义了，不过，通常场景下，既然用到了观察者模式，我们就是希望一个事件出来了，会有多个不同的类需要处理相应的信息。比如，订单修改成功事件，我们希望发短信的类得到通知、发邮件的类得到通知、处理物流信息的类得到通知等。我们来定义具体的几个观察者类：1234567891011121314151617181920212223242526public class BinaryObserver extends Observer &#123; // 在构造方法中进行订阅主题 public BinaryObserver(Subject subject) &#123; this.subject = subject; // 通常在构造方法中将 this 发布出去的操作一定要小心 this.subject.attach(this); &#125; // 该方法由主题类在数据变更的时候进行调用 @Override public void update() &#123; String result = Integer.toBinaryString(subject.getState()); System.out.println(&amp;quot;订阅的数据发生变化，新的数据处理为二进制值为：&amp;quot; + result); &#125;&#125;public class HexaObserver extends Observer &#123; public HexaObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; String result = Integer.toHexString(subject.getState()).toUpperCase(); System.out.println(&amp;quot;订阅的数据发生变化，新的数据处理为十六进制值为：&amp;quot; + result); &#125;&#125;客户端使用也非常简单：12345678910public static void main(String[] args) &#123; // 先定义一个主题 Subject subject1 = new Subject(); // 定义观察者 new BinaryObserver(subject1); new HexaObserver(subject1); // 模拟数据变更，这个时候，观察者们的 update 方法将会被调用 subject.setState(11);&#125;output:12订阅的数据发生变化，新的数据处理为二进制值为：1011订阅的数据发生变化，新的数据处理为十六进制值为：B当然，jdk 也提供了相似的支持，具体的大家可以参考 java.util.Observable和 java.util.Observer这两个类。实际生产过程中，观察者模式往往用消息中间件来实现，如果要实现单机观察者模式，笔者建议读者使用 Guava 中的 EventBus，它有同步实现也有异步实现，本文主要介绍设计模式，就不展开说了。还有，即使是上面的这个代码，也会有很多变种，大家只要记住核心的部分，那就是一定有一个地方存放了所有的观察者，然后在事件发生的时候，遍历观察者，调用它们的回调函数。责任链模式 责任链通常需要先建立一个单向链表，然后调用方只需要调用头部节点就可以了，后面会自动流转下去。比如流程审批就是一个很好的例子，只要终端用户提交申请，根据申请的内容信息，自动建立一条责任链，然后就可以开始流转了。 有这么一个场景，用户参加一个活动可以领取奖品，但是活动需要进行很多的规则校验然后才能放行，比如首先需要校验用户是否是新用户、今日参与人数是否有限额、全场参与人数是否有限额等等。设定的规则都通过后，才能让用户领走奖品。 如果产品给你这个需求的话，我想大部分人一开始肯定想的就是，用一个 List 来存放所有的规则，然后 foreach 执行一下每个规则就好了。不过，读者也先别急，看看责任链模式和我们说的这个有什么不一样？ 首先，我们要定义流程上节点的基类：1234567891011121314public abstract class RuleHandler &#123; // 后继节点 protected RuleHandler successor; public abstract void apply(Context context); public void setSuccessor(RuleHandler successor) &#123; this.successor = successor; &#125; public RuleHandler getSuccessor() &#123; return successor; &#125;&#125; 接下来，我们需要定义具体的每个节点了。 校验用户是否是新用户：123456789101112public class NewUserRuleHandler extends RuleHandler &#123; public void apply(Context context) &#123; if (context.isNewUser()) &#123; // 如果有后继节点的话，传递下去 if (this.getSuccessor() != null) &#123; this.getSuccessor().apply(context); &#125; &#125; else &#123; throw new RuntimeException(&amp;quot;该活动仅限新用户参与&amp;quot;); &#125; &#125;&#125; 校验用户所在地区是否可以参与：123456789101112public class LocationRuleHandler extends RuleHandler &#123; public void apply(Context context) &#123; boolean allowed = activityService.isSupportedLocation(context.getLocation); if (allowed) &#123; if (this.getSuccessor() != null) &#123; this.getSuccessor().apply(context); &#125; &#125; else &#123; throw new RuntimeException(&amp;quot;非常抱歉，您所在的地区无法参与本次活动&amp;quot;); &#125; &#125;&#125; 校验奖品是否已领完：123456789101112public class LimitRuleHandler extends RuleHandler &#123; public void apply(Context context) &#123; int remainedTimes = activityService.queryRemainedTimes(context); // 查询剩余奖品 if (remainedTimes &amp;gt; 0) &#123; if (this.getSuccessor() != null) &#123; this.getSuccessor().apply(userInfo); &#125; &#125; else &#123; throw new RuntimeException(&amp;quot;您来得太晚了，奖品被领完了&amp;quot;); &#125; &#125;&#125; 客户端：12345678910public static void main(String[] args) &#123; RuleHandler newUserHandler = new NewUserRuleHandler(); RuleHandler locationHandler = new LocationRuleHandler(); RuleHandler limitHandler = new LimitRuleHandler(); // 假设本次活动仅校验地区和奖品数量，不校验新老用户 locationHandler.setSuccessor(limitHandler); locationHandler.apply(context);&#125; 代码其实很简单，就是先定义好一个链表，然后在通过任意一节点后，如果此节点有后继节点，那么传递下去。 至于它和我们前面说的用一个 List 存放需要执行的规则的做法有什么异同，留给读者自己琢磨吧。 模板方法模式 在含有继承结构的代码中，模板方法模式是非常常用的。 通常会有一个抽象类：123456789101112131415161718public abstract class AbstractTemplate &#123; // 这就是模板方法 public void templateMethod() &#123; init(); apply(); // 这个是重点 end(); // 可以作为钩子方法 &#125; protected void init() &#123; System.out.println(&amp;quot;init 抽象层已经实现，子类也可以选择覆写&amp;quot;); &#125; // 留给子类实现 protected abstract void apply(); protected void end() &#123; &#125;&#125; 模板方法中调用了 3 个方法，其中 apply() 是抽象方法，子类必须实现它，其实模板方法中有几个抽象方法完全是自由的，我们也可以将三个方法都设置为抽象方法，让子类来实现。也就是说，模板方法只负责定义第一步应该要做什么，第二步应该做什么，第三步应该做什么，至于怎么做，由子类来实现。 我们写一个实现类：123456789public class ConcreteTemplate extends AbstractTemplate &#123; public void apply() &#123; System.out.println(&amp;quot;子类实现抽象方法 apply&amp;quot;); &#125; public void end() &#123; System.out.println(&amp;quot;我们可以把 method3 当做钩子方法来使用，需要的时候覆写就可以了&amp;quot;); &#125;&#125; 客户端调用演示：12345public static void main(String[] args) &#123; AbstractTemplate t = new ConcreteTemplate(); // 调用模板方法 t.templateMethod();&#125; 代码其实很简单，基本上看到就懂了，关键是要学会用到自己的代码中。 状态模式 update: 2017-10-19 废话我就不说了，我们说一个简单的例子。商品库存中心有个最基本的需求是减库存和补库存，我们看看怎么用状态模式来写。 核心在于，我们的关注点不再是 Context 是该进行哪种操作，而是关注在这个 Context 会有哪些操作。 定义状态接口：123public interface State &#123; public void doAction(Context context);&#125; 定义减库存的状态：12345678910111213public class DeductState implements State &#123; public void doAction(Context context) &#123; System.out.println(&amp;quot;商品卖出，准备减库存&amp;quot;); context.setState(this); //... 执行减库存的具体操作 &#125; public String toString() &#123; return &amp;quot;Deduct State&amp;quot;; &#125;&#125; 定义补库存状态：12345678910111213public class RevertState implements State &#123; public void doAction(Context context) &#123; System.out.println(&amp;quot;给此商品补库存&amp;quot;); context.setState(this); //... 执行加库存的具体操作 &#125; public String toString() &#123; return &amp;quot;Revert State&amp;quot;; &#125;&#125; 前面用到了 context.setState(this)，我们来看看怎么定义 Context 类：1234567891011121314public class Context &#123; private State state; private String name; public Context(String name) &#123; this.name = name; &#125; public void setState(State state) &#123; this.state = state; &#125; public void getState() &#123; return this.state; &#125;&#125; 我们来看下客户端调用，大家就一清二楚了：123456789101112131415public static void main(String[] args) &#123; // 我们需要操作的是 iPhone X Context context = new Context(&amp;quot;iPhone X&amp;quot;); // 看看怎么进行补库存操作 State revertState = new RevertState(); revertState.doAction(context); // 同样的，减库存操作也非常简单 State deductState = new DeductState(); deductState.doAction(context); // 如果需要我们可以获取当前的状态 // context.getState().toString();&#125; 读者可能会发现，在上面这个例子中，如果我们不关心当前 context 处于什么状态，那么 Context 就可以不用维护 state 属性了，那样代码会简单很多。 不过，商品库存这个例子毕竟只是个例，我们还有很多实例是需要知道当前 context 处于什么状态的。 行为型模式总结 行为型模式部分介绍了策略模式、观察者模式、责任链模式、模板方法模式和状态模式，其实，经典的行为型模式还包括备忘录模式、命令模式等，但是它们的使用场景比较有限，而且本文篇幅也挺大了，我就不进行介绍了。 总结 学习设计模式的目的是为了让我们的代码更加的优雅、易维护、易扩展。这次整理这篇文章，让我重新审视了一下各个设计模式，对我自己而言收获还是挺大的。我想，文章的最大收益者一般都是作者本人，为了写一篇文章，需要巩固自己的知识，需要寻找各种资料，而且，自己写过的才最容易记住，也算是我给读者的建议吧。 （全文完） https://javadoop.com/post/design-pattern]]></content>
      <categories>
        <category>Foundation</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DesignPattern-Structural-pattern part2]]></title>
    <url>%2F2019%2F05%2F16%2FDesignPattern-Structural-pattern-part2%2F</url>
    <content type="text"><![CDATA[在上一篇文章 详解设计模式之结构型模式（上）中我们学习了三种结构型模式：适配器模式、桥接模式、组合模式。本文我们将介绍剩余四种结构型模式，它们分别是： 装饰模式 外观模式 享元模式 代理模式 四、装饰模式提到装饰，我们先来想一下生活中有哪些装饰： 女生的首饰：戒指、耳环、项链等装饰品 家居装饰品：粘钩、镜子、壁画、盆栽等 我们为什么需要这些装饰品呢？很容易想到是为了美，戒指、耳环、项链、壁画、盆栽等都是为了提高颜值或增加美观度。但粘钩、镜子不一样，它们是为了方便我们挂东西、洗漱。所以我们可以总结出装饰品共有两种功能： 增强原有的特性：我们本身就是有一定颜值的，添加装饰品提高了我们的颜值。同样，房屋本身就有一定的美观度，家居装饰提高了房屋的美观度。 添加新的特性：在墙上挂上粘钩，让墙壁有了挂东西的功能。在洗漱台装上镜子，让洗漱台有了照镜子的功能。 并且，我们发现装饰品并不会改变物品本身，只是起到一个锦上添花的作用。装饰模式也一样，它的主要作用就是： 增强一个类原有的功能 为一个类添加新的功能并且 装饰模式也不会改变原有的类。 装饰模式：动态地给一个对象增加一些额外的职责，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”。 1. 用于增强功能的装饰模式我们用程序来模拟一下戴上装饰品提高我们颜值的过程： 新建颜值接口：123public interface IBeauty &#123; int getBeautyValue();&#125; 新建 Me 类，实现颜值接口：12345678public class Me implements IBeauty &#123;​ @Override public int getBeautyValue() &#123; return 100; &#125;&#125; 戒指装饰类，将 Me 包装起来：12345678910111213public class RingDecorator implements IBeauty &#123; private final IBeauty me;​ public RingDecorator(IBeauty me) &#123; this.me = me; &#125;​ @Override public int getBeautyValue() &#123; return me.getBeautyValue() + 20; &#125;&#125; 客户端测试：12345678910public class Client &#123; @Test public void show() &#123; IBeauty me = new Me(); System.out.println("我原本的颜值：" + me.getBeautyValue());​ IBeauty meWithRing = new RingDecorator(me); System.out.println("戴上了戒指后，我的颜值：" + meWithRing.getBeautyValue()); &#125;&#125; 运行程序，输出如下：12我原本的颜值：100戴上了戒指后，我的颜值：120 这就是最简单的增强功能的装饰模式。以后我们可以添加更多的装饰类，比如： 耳环装饰类：123456789101112public class EarringDecorator implements IBeauty &#123; private final IBeauty me;​ public EarringDecorator(IBeauty me) &#123; this.me = me; &#125;​ @Override public int getBeautyValue() &#123; return me.getBeautyValue() + 50; &#125;&#125; 项链装饰类：123456789101112public class NecklaceDecorator implements IBeauty &#123; private final IBeauty me;​ public NecklaceDecorator(IBeauty me) &#123; this.me = me; &#125;​ @Override public int getBeautyValue() &#123; return me.getBeautyValue() + 80; &#125;&#125; 客户端测试：12345678910111213141516171819public class Client &#123; @Test public void show() &#123; IBeauty me = new Me(); System.out.println("我原本的颜值：" + me.getBeautyValue());​ // 随意挑选装饰 IBeauty meWithNecklace = new NecklaceDecorator(me); System.out.println("戴上了项链后，我的颜值：" + meWithNecklace.getBeautyValue());​ // 多次装饰 IBeauty meWithManyDecorators = new NecklaceDecorator(new RingDecorator(new EarringDecorator(me))); System.out.println("戴上耳环、戒指、项链后，我的颜值：" + meWithManyDecorators.getBeautyValue());​ // 任意搭配装饰 IBeauty meWithNecklaceAndRing = new NecklaceDecorator(new RingDecorator(me)); System.out.println("戴上戒指、项链后，我的颜值：" + meWithNecklaceAndRing.getBeautyValue()); &#125;&#125; 运行程序，输出如下：12345我原本的颜值：100戴上了项链后，我的颜值：180戴上耳环、戒指、项链后，我的颜值：250戴上戒指、项链后，我的颜值：200 可以看到，装饰器也实现了 IBeauty 接口，并且没有添加新的方法，也就是说这里的装饰器仅用于增强功能，并不会改变 Me 原有的功能，这种装饰模式称之为 透明装饰模式，由于没有改变接口，也没有新增方法，所以透明装饰模式可以无限装饰。 装饰模式是 继承 的一种替代方案。本例如果不使用装饰模式，而是改用继承实现的话，戴着戒指的 Me 需要派生一个子类、戴着项链的 Me 需要派生一个子类、戴着耳环的 Me 需要派生一个子类、戴着戒指 + 项链的需要派生一个子类……各种各样的排列组合会造成类爆炸。而采用了装饰模式就只需要为每个装饰品生成一个装饰类即可，所以说就 增加对象功能 来说，装饰模式比生成子类实现更为灵活。 2. 用于添加功能的装饰模式我们用程序来模拟一下房屋装饰粘钩后，新增了挂东西功能的过程： 新建房屋接口：123public interface IHouse &#123; void live();&#125; 房屋类：1234567public class House implements IHouse&#123;​ @Override public void live() &#123; System.out.println("房屋原有的功能：居住功能"); &#125;&#125; 新建粘钩装饰器接口，继承自房屋接口：123public interface IStickyHookHouse extends IHouse&#123; void hangThings();&#125; 粘钩装饰类：1234567891011121314151617public class StickyHookDecorator implements IStickyHookHouse &#123; private final IHouse house;​ public StickyHookDecorator(IHouse house) &#123; this.house = house; &#125;​ @Override public void live() &#123; house.live(); &#125;​ @Override public void hangThings() &#123; System.out.println("有了粘钩后，新增了挂东西功能"); &#125;&#125; 客户端测试：1234567891011public class Client &#123; @Test public void show() &#123; IHouse house = new House(); house.live();​ IStickyHookHouse stickyHookHouse = new StickyHookDecorator(house); stickyHookHouse.live(); stickyHookHouse.hangThings(); &#125;&#125; 运行程序，显示如下：123房屋原有的功能：居住功能房屋原有的功能：居住功能有了粘钩后，新增了挂东西功能 这就是用于 新增功能 的装饰模式。我们在接口中新增了方法：hangThings，然后在装饰器中将 House 类包装起来，之前 House 中的方法仍然调用 house 去执行，也就是说我们并没有修改原有的功能，只是扩展了新的功能，这种模式在装饰模式中称之为 半透明装饰模式。 为什么叫半透明呢？由于新的接口 IStickyHookHouse 拥有之前 IHouse 不具有的方法，所以我们如果要使用装饰器中添加的功能，就不得不区别对待 装饰前的对象和装饰后的对象。也就是说客户端要使用新方法，必须知道具体的装饰类 StickyHookDecorator，所以这个装饰类对客户端来说是可见的、不透明的。而被装饰者不一定要是 House，它可以是实现了 IHouse 接口的任意对象，所以被装饰者对客户端是不可见的、透明的。由于一半透明，一半不透明，所以称之为半透明装饰模式。 我们可以添加更多的装饰器： 新建镜子装饰器的接口，继承自房屋接口：123public interface IMirrorHouse extends IHouse &#123; void lookMirror();&#125; 镜子装饰类：1234567891011121314151617public class MirrorDecorator implements IMirrorHouse&#123; private final IHouse house;​ public MirrorDecorator(IHouse house) &#123; this.house = house; &#125;​ @Override public void live() &#123; house.live(); &#125;​ @Override public void lookMirror() &#123; System.out.println("有了镜子后，新增了照镜子功能"); &#125;&#125; 客户端测试：1234567891011public class Client &#123; @Test public void show() &#123; IHouse house = new House(); house.live();​ IMirrorHouse mirrorHouse = new MirrorDecorator(house); mirrorHouse.live(); mirrorHouse.lookMirror(); &#125;&#125; 运行程序，输出如下：123房屋原有的功能：居住功能房屋原有的功能：居住功能​有了镜子后，新增了照镜子功能 现在我们仿照 透明装饰模式 的写法，同时添加粘钩和镜子装饰试一试：12345678910111213public class Client &#123; @Test public void show() &#123; IHouse house = new House(); house.live();​ IStickyHookHouse stickyHookHouse = new StickyHookDecorator(house); IMirrorHouse houseWithStickyHookMirror = new MirrorDecorator(stickyHookHouse); houseWithStickyHookMirror.live(); houseWithStickyHookMirror.hangThings(); // 这里会报错，找不到 hangThings 方法 houseWithStickyHookMirror.lookMirror(); &#125;&#125; ​我们会发现，第二次装饰时，无法获得上一次装饰添加的方法。原因很明显，当我们用 IMirrorHouse 装饰器后，接口变为了 IMirrorHouse，这个接口中并没有 hangThings 方法。 那么我们能否让 IMirrorHouse 继承自 IStickyHookHouse，以实现新增两个功能呢？ 可以，但那样做的话两个装饰类之间有了依赖关系，那就不是装饰模式了。装饰类不应该存在依赖关系，而应该在原本的类上进行装饰。这就意味着，半透明装饰模式中，我们无法多次装饰。 有的同学会问了，既增强了功能，又添加了新功能的装饰模式叫什么呢？ —— 举一反三，肯定是叫全不透明装饰模式！ —— 并不是！只要添加了新功能的装饰模式都称之为 半透明装饰模式，他们都具有不可以多次装饰的特点。仔细理解上文半透明名称的由来就知道了，“透明”指的是我们无需知道被装饰者具体的类，既增强了功能，又添加了新功能的装饰模式仍然具有半透明特性。 看了这两个简单的例子，是不是发现装饰模式很简单呢？恭喜你学会了 1 + 1 = 2，现在你已经掌握了算数的基本思想，接下来我们来做一道微积分题练习一下。 I/O 中的装饰模式I/O 指的是 Input/Output，即输入、输出。我们以 Input 为例。先在 src 文件夹下新建一个文件 readme.text，随便写点文字：123禁止套娃禁止禁止套娃​禁止禁止禁止套娃 然后用 Java 的 InputStream 读取，代码一般长这样：12345678public void io() throws IOException &#123; InputStream in = new BufferedInputStream(new FileInputStream("src/readme.txt")); byte[] buffer = new byte[1024]; while (in.read(buffer) != -1) &#123; System.out.println(new String(buffer)); &#125; in.close();&#125; 这样写有一个问题，如果读取过程中出现了 IO 异常，InputStream 就不能正确关闭，所以我们要用try…finally来保证 InputStream 正确关闭：1234567891011121314public void io() throws IOException &#123; InputStream in = null; try &#123; in = new BufferedInputStream(new FileInputStream("src/readme.txt")); byte[] buffer = new byte[1024]; while (in.read(buffer) != -1) &#123; System.out.println(new String(buffer)); &#125; &#125; finally &#123; if (in != null) &#123; in.close(); &#125; &#125;&#125; 这种写法实在是太丑了，而 IO 操作又必须这么写，显然 Java 也意识到了这个问题，所以 Java 7 中引入了try(resource)语法糖，IO 的代码就可以简化如下：12345678public void io() throws IOException &#123; try (InputStream in = new BufferedInputStream(new FileInputStream("src/readme.txt"))) &#123; byte[] buffer = new byte[1024]; while (in.read(buffer) != -1) &#123; System.out.println(new String(buffer)); &#125; &#125;&#125; 这种写法和上一种逻辑是一样的，运行程序，显示如下：123禁止套娃禁止禁止套娃禁止禁止禁止套娃 观察获取 InputStream 这句代码：1InputStream in = new BufferedInputStream(new FileInputStream("src/readme.txt")); 是不是和我们之前多次装饰的代码非常相似：123// 多次装饰IBeauty meWithManyDecorators = new NecklaceDecorator(new RingDecorator(new EarringDecorator(me))); 事实上，查看 I/O 的源码可知，Java I/O 的设计框架便是使用的 装饰者模式，InputStream 的继承关系如下： 其中，InputStream 是一个抽象类，对应上文例子中的 IHouse，其中最重要的方法是 read 方法，这是一个抽象方法：1234567public abstract class InputStream implements Closeable &#123; public abstract int read() throws IOException; // ...&#125; 这个方法会读取输入流的下一个字节，并返回字节表示的 int 值（0~255），返回 -1 表示已读到末尾。由于它是抽象方法，所以具体的逻辑交由子类实现。 上图中，左边的三个类 FileInputStream、ByteArrayInputStream、ServletInputStream 是 InputStream 的三个子类，对应上文例子中实现了 IHouse 接口的 House。 右下角的三个类 BufferedInputStream、DataInputStream、CheckedInputStream 是三个具体的装饰者类，他们都为 InputStream 增强了原有功能或添加了新功能。 FilterInputStream 是所有装饰类的父类，它没有实现具体的功能，仅用来包装了一下 InputStream：12345678910111213public class FilterInputStream extends InputStream &#123; protected volatile InputStream in; protected FilterInputStream(InputStream in) &#123; this.in = in; &#125;​ public int read() throws IOException &#123; return in.read(); &#125; //...&#125; 我们以 BufferedInputStream 为例。原有的 InputStream 读取文件时，是一个字节一个字节读取的，这种方式的执行效率并不高，所以我们可以设立一个缓冲区，先将内容读取到缓冲区中，缓冲区读满后，将内容从缓冲区中取出来，这样就变成了一段一段读取，用内存换取效率。BufferedInputStream 就是用来做这个的。它继承自 FilterInputStream：123456789101112131415161718public class BufferedInputStream extends FilterInputStream &#123; private static final int DEFAULT_BUFFER_SIZE = 8192; protected volatile byte buf[];​ public BufferedInputStream(InputStream in) &#123; this(in, DEFAULT_BUFFER_SIZE); &#125;​ public BufferedInputStream(InputStream in, int size) &#123; super(in); if (size &lt;= 0) &#123; throw new IllegalArgumentException("Buffer size &lt;= 0"); &#125; buf = new byte[size]; &#125; //...&#125; 我们先来看它的构造方法，在构造方法中，新建了一个 byte[] 作为缓冲区，从源码中我们看到，Java 默认设置的缓冲区大小为 8192 byte，也就是 8 KB。 然后我们来查看 read 方法：1234567891011121314151617​public class BufferedInputStream extends FilterInputStream &#123; //...​ public synchronized int read() throws IOException &#123; if (pos &gt;= count) &#123; fill(); if (pos &gt;= count) return -1; &#125; return getBufIfOpen()[pos++] &amp; 0xff; &#125;​ private void fill() throws IOException &#123; // 往缓冲区内填充读取内容的过程 //... &#125;&#125; 在 read 方法中，调用了 fill 方法，fill 方法的作用就是往缓冲区中填充读取的内容。这样就实现了增强原有的功能。 在源码中我们发现，BufferedInputStream 没有添加 InputStream 中没有的方法，所以 BufferedInputStream 使用的是 透明的装饰模式。 DataInputStream 用于更加方便地读取 int、double 等内容，观察 DataInputStream 的源码可以发现，DataInputStream 中新增了 readInt、readLong 等方法，所以 DataInputStream 使用的是 半透明装饰模式。 理解了 InputStream 后，再看一下 OutputStream 的继承关系，相信大家一眼就能看出各个类的作用了： 这就是装饰模式，注意不要和适配器模式混淆了。两者在使用时都是包装一个类，但两者的区别其实也很明显： 纯粹的适配器模式 仅用于改变接口，不改变其功能，部分情况下我们需要改变一点功能以适配新接口。但使用适配器模式时，接口一定会有一个 回炉重造 的过程。 装饰模式 不改变原有的接口，仅用于增强原有功能或添加新功能，强调的是锦上添花。 掌握了装饰者模式之后，理解 Java I/O 的框架设计就非常容易了。但对于不理解装饰模式的人来说，各种各样相似的 InputStream 非常容易让开发者感到困惑。这一点正是装饰模式的缺点：容易造成程序中有大量相似的类。虽然这更像是开发者的缺点，我们应该做的是提高自己的技术，掌握了这个设计模式之后它就是我们的一把利器。现在我们再看到 I/O 不同的 InputStream 装饰类，只需要关注它增强了什么功能或添加了什么功能即可。 五、外观模式外观模式非常简单，体现的就是 Java 中封装的思想。将多个子系统封装起来，提供一个更简洁的接口供外部调用。 外观模式：外部与一个子系统的通信必须通过一个统一的外观对象进行，为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式。 举个例子，比如我们每天打开电脑时，都需要做三件事： 打开浏览器 打开 IDE 打开微信 每天下班时，关机前需要做三件事： 关闭浏览器 关闭 IDE 关闭微信 用程序模拟如下： 新建浏览器类：123456789public class Browser &#123; public static void open() &#123; System.out.println("打开浏览器"); &#125;​ public static void close() &#123; System.out.println("关闭浏览器"); &#125;​&#125; 新建 IDE 类：123456789public class IDE &#123; public static void open() &#123; System.out.println("打开 IDE"); &#125;​ public static void close() &#123; System.out.println("关闭 IDE"); &#125;&#125; 新建微信类：123456789public class Wechat &#123; public static void open() &#123; System.out.println("打开微信"); &#125;​ public static void close() &#123; System.out.println("关闭微信"); &#125;&#125; 客户端调用：1234567891011121314public class Client &#123; @Test public void test() &#123; System.out.println("上班:"); Browser.open(); IDE.open(); Wechat.open();​ System.out.println("下班:"); Browser.close(); IDE.close(); Wechat.close(); &#125;&#125; 运行程序，输出如下：12345678上班:打开浏览器打开 IDE打开微信下班:关闭浏览器关闭 IDE关闭微信 由于我们每天都要做这几件事，所以我们可以使用 外观模式，将这几个子系统封装起来，提供更简洁的接口：12345678910111213public class Facade &#123; public void open() &#123; Browser.open(); IDE.open(); Wechat.open(); &#125;​ public void close() &#123; Browser.close(); IDE.close(); Wechat.close(); &#125;&#125; 客户端就可以简化代码，只和这个外观类打交道：1234567891011public class Client &#123; @Test public void test() &#123; Facade facade = new Facade(); System.out.println("上班:"); facade.open();​ System.out.println("下班:"); facade.close(); &#125;&#125; ​运行程序，输出与之前一样。 外观模式就是这么简单，它使得两种不同的类不用直接交互，而是通过一个中间件——也就是外观类——间接交互。外观类中只需要暴露简洁的接口，隐藏内部的细节，所以说白了就是封装的思想。 外观模式非常常用，（当然了！写代码哪有不封装的！）尤其是在第三方库的设计中，我们应该提供尽量简洁的接口供别人调用。另外，在 MVC 架构中，C 层（Controller）就可以看作是外观类，Model 和 View 层通过 Controller 交互，减少了耦合。 六、享元模式享元模式体现的是 程序可复用 的特点，为了节约宝贵的内存，程序应该尽可能地复用，就像《极限编程》作者 Kent 在书里说到的那样：Don’t repeat yourself. 简单来说 享元模式就是共享对象，提高复用性，官方的定义倒是显得文绉绉的： 享元模式：运用共享技术有效地支持大量细粒度对象的复用。系统只使用少量的对象，而这些对象都很相似，状态变化很小，可以实现对象的多次复用。由于享元模式要求能够共享的对象必须是细粒度对象，因此它又称为轻量级模式。 ​有个细节值得注意：有些对象本身不一样，但通过一点点变化后就可以复用，我们编程时可能稍不注意就会忘记复用这些对象。比如说伟大的《超级玛丽》，谁能想到草和云更改一下颜色就可以实现复用呢？ 还有里面的三种乌龟，换一个颜色、加一个装饰就变成了不同的怪： 在《超级玛丽》中，这样的细节还有很多，正是这些精湛的复用使得这一款红遍全球的游戏仅有 40KB 大小。正是印证了那句名言：神在细节之中。 七、代理模式现在我们有一个 人 类，他整天就只负责吃饭、睡觉： 人类的接口1234public interface IPerson &#123; void eat(); void sleep();&#125; 人 类：123456789101112public class Person implements IPerson&#123;​ @Override public void eat() &#123; System.out.println("我在吃饭"); &#125;​ @Override public void sleep() &#123; System.out.println("我在睡觉"); &#125;&#125; 客户端测试：12345678public class Client &#123; @Test public void test() &#123; Person person = new Person(); person.eat(); person.sleep(); &#125;&#125; 运行程序，输出如下：12​我在吃饭我在睡觉 我们可以把这个类包装到另一个类中，实现完全一样的行为：123456789101112131415161718public class PersonProxy implements IPerson &#123;​ private final Person person;​ public PersonProxy(Person person) &#123; this.person = person; &#125;​ @Override public void eat() &#123; person.eat(); &#125;​ @Override public void sleep() &#123; person.sleep(); &#125;&#125; 将客户端修改为调用这个新的类：123456789public class Client &#123; @Test public void test() &#123; Person person = new Person(); PersonProxy proxy = new PersonProxy(person); proxy.eat(); proxy.sleep(); &#125;​&#125; 运行程序，输出如下：12我在吃饭我在睡觉 这就是代理模式。 笔者尽量用最简洁的代码讲解此模式，只要理解了上述这个简单的例子，你就知道代理模式是怎么一回事了。我们在客户端和 Person 类之间新增了一个中间件 PersonProxy，这个类就叫做代理类，他实现了和 Person 类一模一样的行为。 代理模式：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。 现在这个代理类还看不出任何意义，我们来模拟一下工作中的需求。在实际工作中，我们可能会遇到这样的需求：在网络请求前后，分别打印将要发送的数据和接收到数据作为日志信息。此时我们就可以新建一个网络请求的代理类，让它代为处理网络请求，并在代理类中打印这些日志信息。 新建网络请求接口：12345public interface IHttp &#123; void request(String sendData);​ void onSuccess(String receivedData);&#125; 新建 Http 请求工具类：1234567891011public class HttpUtil implements IHttp &#123; @Override public void request(String sendData) &#123; System.out.println("网络请求中..."); &#125;​ @Override public void onSuccess(String receivedData) &#123; System.out.println("网络请求完成。"); &#125;&#125; 新建 Http 代理类：1234567891011121314151617public class HttpProxy implements IHttp &#123; private final HttpUtil httpUtil;​ public HttpProxy(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; &#125;​ @Override public void request(String sendData) &#123; httpUtil.request(sendData); &#125;​ @Override public void onSuccess(String receivedData) &#123; httpUtil.onSuccess(receivedData); &#125;&#125; 到这里，和我们上述吃饭睡觉的代码是一模一样的，现在我们在 HttpProxy 中新增打印日志信息：12345678910111213141516171819public class HttpProxy implements IHttp &#123; private final HttpUtil httpUtil;​ public HttpProxy(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; &#125;​ @Override public void request(String sendData) &#123; System.out.println("发送数据:" + sendData); httpUtil.request(sendData); &#125;​ @Override public void onSuccess(String receivedData) &#123; System.out.println("收到数据:" + receivedData); httpUtil.onSuccess(receivedData); &#125;&#125; 客户端验证：123456789public class Client &#123; @Test public void test() &#123; HttpUtil httpUtil = new HttpUtil(); HttpProxy proxy = new HttpProxy(httpUtil); proxy.request("request data"); proxy.onSuccess("received result"); &#125;&#125; 运行程序，输出如下：1234发送数据:request data网络请求中...收到数据:received result网络请求完成。 这就是代理模式的一个应用，除了 打印日志，它还可以用来做权限管理。读者看到这里可能已经发现了，这个代理类看起来和装饰模式的 FilterInputStream 一模一样，但两者的目的不同，装饰模式是为了 增强功能或添加功能，代理模式主要是为了加以控制。 动态代理上例中的代理被称之为静态代理，动态代理与静态代理的原理一模一样，只是换了一种写法。使用动态代理，需要把一个类传入，然后根据它正在调用的方法名判断是否需要加以控制。用伪代码表示如下：1234567891011121314151617181920public class HttpProxy &#123; private final HttpUtil httpUtil;​ public HttpProxy(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; &#125;​ // 假设调用 httpUtil 的任意方法时，都要通过这个方法间接调用, methodName 表示方法名，args 表示方法中传入的参数 public visit(String methodName, Object[] args) &#123; if (methodName.equals("request")) &#123; // 如果方法名是 request，打印日志，并调用 request 方法，args 的第一个值就是传入的参数 System.out.println("发送数据:" + args[0]); httpUtil.request(args[0].toString()); &#125; else if (methodName.equals("onSuccess")) &#123; // 如果方法名是 onSuccess，打印日志，并调用 onSuccess 方法，args 的第一个值就是传入的参数 System.out.println("收到数据:" + args[0]); httpUtil.onSuccess(args[0].toString()); &#125; &#125;&#125; 伪代码看起来还是很简单的，实现起来唯一的难点就是 怎么让 httpUtil 调用任意方法时，都通过一个方法间接调用。这里需要用到反射技术，不了解反射技术也没有关系，不妨把它记做固定的写法。实际的动态代理类代码如下：123456789101112131415161718192021222324public class HttpProxy implements InvocationHandler &#123; private HttpUtil httpUtil;​ public IHttp getInstance(HttpUtil httpUtil) &#123; this.httpUtil = httpUtil; return (IHttp) Proxy.newProxyInstance(httpUtil.getClass().getClassLoader(), httpUtil.getClass().getInterfaces(), this); &#125;​ // 调用 httpUtil 的任意方法时，都要通过这个方法调用 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; if (method.getName().equals("request")) &#123; // 如果方法名是 request，打印日志，并调用 request 方法 System.out.println("发送数据:" + args[0]); result = method.invoke(httpUtil, args); &#125; else if (method.getName().equals("onSuccess")) &#123; // 如果方法名是 onSuccess，打印日志，并调用 onSuccess 方法 System.out.println("收到数据:" + args[0]); result = method.invoke(httpUtil, args); &#125; return result; &#125;&#125; 先看 getInstance 方法，Proxy.newProxyInstance 方法是 Java 系统提供的方法，专门用于动态代理。其中传入的第一个参数是被代理的类的 ClassLoader，第二个参数是被代理类的 Interfaces，这两个参数都是 Object 中的，每个类都有，这里就是固定写法。我们只要知道系统需要这两个参数才能让我们实现我们的目的：调用被代理类的任意方法时，都通过一个方法间接调用。现在我们给系统提供了这两个参数，系统就会在第三个参数中帮我们实现这个目的。 第三个参数是 InvocationHandler 接口，这个接口中只有一个方法：1public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; ​那么不用猜就知道，现在我们调用被代理类 httpUtil 的任意方法时，都会通过这个 invoke 方法调用了。invoke 方法中，第一个参数我们暂时用不上，第二个参数 method 就是调用的方法，使用 method.getName() 可以获取到方法名，第三个参数是调用 method 方法需要传入的参数。本例中无论 request 还是 onSuccess 都只有一个 String 类型的参数，对应到这里就是 args[0]。返回的 Object 是 method 方法的返回值，本例中都是无返回值的。 我们在 invoke 方法中判断了当前调用方法的方法名，如果现在调用的方法是 request，那么打印请求参数，并使用这一行代码继续执行当前方法：1result = method.invoke(httpUtil, args); 这就是 反射调用函数 的写法，如果不了解可以记做固定写法，想要了解的同学可以看之前的这篇文章：详解面试中常考的 Java 反射机制。虽然这个函数没有返回值，但我们还是将 result 返回，这是标准做法。 如果现在调用的方法是 onSuccess，那么打印接收到的数据，并反射继续执行当前方法。 修改客户端验证一下：123456789public class Client &#123; @Test public void test() &#123; HttpUtil httpUtil = new HttpUtil(); IHttp proxy = new HttpProxy().getInstance(httpUtil); proxy.request("request data"); proxy.onSuccess("received result"); &#125;&#125; 运行程序，输出与之前一样：1234发送数据:request data网络请求中...收到数据:received result网络请求完成。 动态代理本质上与静态代理没有区别，它的好处是 节省代码量。比如被代理类有 20 个方法，而我们只需要控制其中的两个方法，就可以用动态代理通过方法名对被代理类进行动态的控制，而如果用静态方法，我们就需要将另外的 18 个方法也写出来，非常繁琐。这就是动态代理的优势所在。 八. 享元模式 Flyweight Pattern英文是 Flyweight Pattern，不知道是谁最先翻译的这个词，感觉这翻译真的不好理解，我们试着强行关联起来吧。Flyweight 是轻量级的意思，享元分开来说就是 共享 元器件，也就是复用已经生成的对象，这种做法当然也就是轻量级的了。 复用对象最简单的方式是，用一个 HashMap 来存放每次新生成的对象。每次需要一个对象的时候，先到 HashMap 中看看有没有，如果没有，再生成新的对象，然后将这个对象放入 HashMap 中 结构型模式总结前面，我们说了代理模式、适配器模式、桥梁模式、装饰模式、门面模式、组合模式和享元模式。读者是否可以分别把这几个模式说清楚了呢？在说到这些模式的时候，心中是否有一个清晰的图或处理流程在脑海里呢？ 代理模式是做方法增强的，适配器模式是把鸡包装成鸭这种用来适配接口的，桥梁模式做到了很好的解耦，装饰模式从名字上就看得出来，适合于装饰类或者说是增强类的场景，门面模式的优点是客户端不需要关心实例化过程，只要调用需要的方法即可，组合模式用于描述具有层次结构的数据，享元模式是为了在特定的场景中缓存已经创建的对象，用于提高性能。 本文作者：Alpinist Wang 声明：本文归 “力扣” 版权所有，如需转载请联系。文章封面图和文中部分图片来源于网络，为非商业用途使用，如有侵权联系删除。 编辑于 2019-11-28]]></content>
      <categories>
        <category>Foundation</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CV And SoP]]></title>
    <url>%2F2019%2F05%2F14%2FCV-AND-SOP%2F</url>
    <content type="text"><![CDATA[THE GUIDELINE OF CV AND SOP(PS) 美国研究生申请时经常会在Application Requirements部分看到几种不同名称的申请文书，比如：personal statement，PS，Personal history statement，statement，Statement of goals，Personal purpose，personal essay或Statement of Purpose。不管名字如何变化，其实就是我们大家都知道的研究生申请主文书——个人陈述，只不过不同的美国大学在申请时关注申请人的侧重点不同，要求学生主要陈述和介绍自己的内容占比不同，但核心内容并无太多差异。 通过上面这些美国大学的官方研究生申请文书的要求，我们可以看出个人陈述文书主要是让申请人要描述个人背景／经历、学习／学术情况、与申请专业相关的研究／实习／工作情况，以及职业目标这四部分。 我要申请什么专业／项目？要申请具体哪个分支？ 我为什么要申请这个专业？为什么选择这个分支？ 我什么特殊经历或个人原因让你开始关注这个专业领域，开始对这个分支方向感兴趣？ 我是否之前在学习、研究、实习或工作中有与申请专业和申请分支相关的个人经历、学术能力、专业技能或研究成果？ 我觉得我目前在这个专业和这个分支领域还存在哪些不足，还希望进行怎样的专业能力提升和自我完善？ 我未来的学习／研究计划是什么？ 我未来的短期和长期的职业规划是什么？ 我为什么会选择申请这所大学？吸引我的主要因素都有哪些？ 除了学术、研究、工作方面经历和能力本身，你还有哪些个人独特的、有别其他人的地方？ UCSD 看上面官网截图图片内容我们能看出，要求PS篇幅1页，并且需要包括：你感兴趣的具体领域，你关注的分支方向，以及你感兴趣的教授是谁。这个PS的命题要求需要我们注意明确篇幅字数，同时文书内容重点是在学术能力和项目研究方面去介绍自己和展示自己能力，以及要对这个学校的申请部门和教授们有一些了解和关注，因为是要明确具体的回答你感兴趣这个学校的分支方向和某个教授的，如果你不提前进行了解，回答的没有针对性，或者你提到的教授擅长研究领域根本不是你文书中表达的感兴趣方向，那么你这样的内容表述也会给你的申请减分。我不过这个学校的题目要求并不篇，完全可以在通用版PS的基础上最后补充1-2句感兴趣教授和对于这名教授的感兴趣原因就可以了，因为大部分通用版的PS内容中我是会给学生们直接陈述出申请人擅长和感兴趣的领域和分支方向的，所以这部分内容不需要额外新增和补充，只是有针对性的补充感兴趣教授就行了。 University of Michigan–Ann Arbor的申请文书要求中需要同时递交两种文书，分别是Statement of Purpose和Personal Statement， 这两个不同名称的文书在内容要求上是有区别的，第一个Statement of Purpose主要是让我们介绍自己关于学术、研究方面的背景和未来职业规划，这些部分正好是我上面提到要在通用版PS中涵盖的第1、2、4、5、6、7问题部分内容。第二个Personal Statement主要是让我们讲述自己的个人经历、想法观点、兴趣倾向，以及选择申请这所大学核心部分原因等内容，这些部分正好是我上面提到要在通用版PS中涵盖的第3、8、9问题部分内容。我们只要根据题目将通用版PS内容进行有效拆分就可以了，也并不需要跟别单独再新写两篇文书的。 特别、特别、特别重点强调的关键点： PS内容不要写的跟resume或CV一样，就是不用再完整的陈述一遍你简历中已经出现过的内容了，因为申请文书之间是相互呼应和结合的，所以PS要有针对性和侧重点的去表述重点，而不是流水账一样的再讲一遍！ PS申请文书表述的形式要以学术风格为主，严谨、有条理、有逻辑最重要，要客观陈述，避免使用过多形容词，但不要花很大比重去讲述和体现你的学术或项目研究完成过程和项目调研大篇幅内容，因为这部分是通过Writing sample或Research paper去展示的，而不是PS。 如果我们递交申请时会同时递交几篇文书（简历除外），那么请注意每篇文书之间的素材选择和文书内容要有不同，不要有太多相同内容重复出现，因为人是多元的，所以请尽量更多素材选择的去全面展示自己。 CV SOP寫作心得 留學申請(10) - 讓別人一眼就了解你的CV 女博士的申請記錄（她的部落格） UCSD教授給出的指導建議(重要) UCSD教授和他的學生在申請斯坦佛博士學位時使用的SOP Advice for Foreign Students Wishing to Pursue Graduate Study in Computer Science at UCSC by Professor Jim Whitehead Native Speaker Editor+理工商法專業背景 + 中文客服(高學歷+豐富美國工作經驗) modify 申請文件：Personal Statement Shau-ru Lin(shau.ru.lin@gmail.com)，費用計算是(2012/2013)： Translation: $0.10/word (72 hours); $0.12/word (24 hours) English Editing: $0.05/word (72 hours); $0.06/word (24 hours) ##字数要求： personal_statement ： 三版 500 700 1000 SOP ：三版 500 700 1000 不同學校的SOP可能會有不同的字體, 字數限制, 有些學校的字數限制是死的, 也就是說他不會讓你上傳WORD或PDF檔,而是在申請系統內直接打字, 當你打超過規定的字數時他也不會讓你寫下去了, 而有些學校則是上傳WORD或PDF檔, 可以繳交超過學校字數規定的SOP, 但是超過字數會有甚麼後果有甚麼影響當然還是要先寄信跟學校問清楚, 如果校方說沒問題, 當然可以小超過一些, 我寫SOP的方式是先把第一志願的SOP寫出來, 我的第一志願SOP所限制的字數是1000字, 另外幾間學校都限制500字或800字, 先把最長的寫完, 之後再用1000字的修即可, SOP的格式依照侃威的建議採取5至6段, 第一段的目的是要吸引讀者所以會以類似小說的寫法作為開頭. 二三段分別在描述自己在學校做過的兩個projects, 第四段則是講畢業專題, 五與六段則是在講學校的課程或是學校有哪方面很吸引你, 以及你的未來規劃. CV方面如果你有發publication那當然是非常加分的, publication之下就是在學校做的各個project或自己做的side-project, 你覺得越重要越能吸引審查員眼睛的經歷就要放在越前面, 例如我沒有發過任何的publication, 我就把我在學校做的兩個專題以及畢業專題放在最前面, 因為自己有許多志工經歷也有創立過社團, 這些相比之下比較沒那麼重要的就放在後面的頁數, CV我個人認為不要超過2頁, 而有些人也說審查者通常只會看第一頁, 所以說能盡量抓住他們眼睛的東西就盡量往前移, 排版方面侃威也幫我修了大概5–6次, 網路上也有許多的template可供大家做選擇. Reference NWU同学的CV 這裡是女博士的申請文件 NTU_UCLA 有伯克利的台大电机系同学的在电脑里面可以拿来参考 基本知识：1. personal statement→为什么来读（兴趣），为什么选项目，为目标做了什么（经历），可以给项目带来什么（对同学贡献，对教授贡献） 2. SOP→要求一篇sop=ps（个人经历，课外活动，志愿者，人生规划等）--学术生活写一篇，要求两篇--sop侧重学术（学术兴趣，职业规划，学术经历）--分开写，适当增减。 3. statement of diversity→学生背景多样性（学术领域，兴趣，家庭，社会族群），我的规划能带来什么多样性（什么多样性，怎么带来）eg.中医世家申请生物医药，政府官员家庭（了解中国）申请社会学历史学等，少数民族（语言融合）申请语言类，家庭背景（和本国比）差怎么对自己性格塑造产生影响 4. 有些学校有明确要求，按照要求来。eg.有些学校会要求‘不要写什么’，可以打电话/发邮件给小蜜（问ps的明确要求） 5. 格式要求：可以有页眉（CV不要有），正文就别再写题目了，一定要有页码，用默认页边距，用TIMES或者Cabrial，字号12，不要有水印/Logo，根据要求（single space，double space），不要分版块，段首缩进五格（敲五下） 写什么/怎么写：1. 我有什么兴趣，为什么，做了什么，意味着什么（做了哪些思考，得到了什么），为什么选这个项目 2. 学校看完ps要能回答的三个问题： * 为什么能再graduate level的学习中成功（学习能力，学习态度→GPA，基础知识→成绩单，若没有，需要写出‘我有足够的基础’，我有兴趣） * 为什么能在职业发展中成功（有热情/兴趣，对领域有理解，有经验→细节，有能力） * 为什么我和你的项目很匹配（为什么项目能帮我实现我的目标，我是你项目要找的人→读选校要求+推荐信） 3. 研究兴趣/学术兴趣： * eg. 申请ME，对燃烧感兴趣（笼统）→改为对公共政策专业里的具体方面感兴趣，如health policy里的与健康相关的XX问题（细化到一个大的研究问题而不是具体的题目） * eg. 申请media/communication，如何评判social media中一个话题的讨论/影响（不强调什么话题什么影响，而是‘如何’评判） * 总结：可以被实践探索的问题（PHD必须有研究兴趣，MS不一定，但要有相关的感兴趣的问题or想弄清楚等→体现它促使你努力学），相关兴趣点不要超过三个问题，两个最好，不相关兴趣点不要超过两个（不够focus）。 * 具体到‘哪个教授哪个方向’， 最好写相对general，不要写教授名字（除非套过辞，或者目标及其明确），免得该方向教授不招人（可以多写一个研究兴趣）。 要了解领域动态，你感兴趣的（不能太过时）是否跟美国院校主流兴趣match的，这个学校的擅长领域是否跟自己match（如专排），自己的背景是否justify–真实，合理。 对于职业型MS，要突出自己的行业领域兴趣（具体哪个行业，government，nonprofit.‍‍‌‍‌‌‌‌‍‌‍‌‌‌‌‍‌‍‍..）公司服务方向（creative，research，analysis，branding，pr）和具体部门 若不确定行业/职能→重点写自己要做什么东西（岗位职能），eg. 我想进industry做研发→进什么方向的企业做什么方向的研发，地域也可以作为一个talking point。可以问问小蜜通常出来的学生都做啥。 4. 写法/原因（怎么表现兴趣）： 我解决了什么问题，产生了什么好处。 我对学科有很深的了解，知道它的魅力，困难，知道怎么去克服。 我有探索，有思考，eg我就想知道social media怎么评判，我做了XX调查/思考/分析（充实）。 展现整个过程：为什么产生问题，对这个问题又什么了解探索，过程中怎么思考，通过这个过程越来越明确坚定。 5.经历： 我做的什么事，为什么这个项目/问题重要，我用了什么方法（为什么用这些方法），遇到了什么困难，怎么克服（是否克服），有什么思考，得到了什么变化（兴趣更坚定之类）。能不能让对你专业不太了解的能知道你做了什么为什么做，让同专业的认可你的成果。每段经历都差不多字数，有选择地讲（最能体现我能力的地方），不要把一个研究分几段写，不同的研究内容可以适当合并在一起。把重要的经历都写上，没有数量限制。不要流水账。不一定要和专业相关。 6. be specific： eg. 我发现X在Y学科很重要→怎么重要，提高了我的研究能力→什么能力 7. such as：到底是什么，做了什么事情（how），what it is， what does it mean（自己问自己） 8. be strong： 主动语态＞被动语态。eg. was used, was obtained→we obtained, I realized…PS不要客观，而是强调‘我’的参与性，CV也是。 solution＞problem。强调解决过程。 wh‍‍‌‍‌‌‌‌‍‌‍‌‌‌‌‍‌‍‍at do you do next＞what do you think。理由同上。 用积极替换消息。不要有‘我知道XXX地方不足“，改成’我会有兴趣地学习XXX”，我做了XXX，虽然影响了GPA，但是收获了XXX，同时其他方面表现了我的能力。不要强调自己多么苦多么惨多么多挑战，而是写成很享受过程。 选校理由：不要写很普遍的东西（比如as we all know…）不需要特别华丽的语言（NO PAIN, NO GAIN这种）。紧密结合所写的东西。选校理由不要千篇一律（位置好，学术好，排名好），不要太personal（男女朋友）。学校的课程设置怎么fit我，学校的课程设置很独特等。为什么喜欢教授，喜欢哪几个（XX的理论对自己印象深刻），我和学长/教授聊了，他们告诉我XXXimpress me，所以想来。 布局：1. 故事型。说明自己的大成就。问题--不impressive，太naive。开头故事要concise。最初怎么感兴趣，做了什么探索，具体的规划，为什么选校。 2. 单刀直入型。开头直接写我的兴趣，我的优势，我为什么选这个学校。 3. 选择最有利的证据。抛掉水证据。 怎么评价：1. 是不是每句话都清楚具体，语法上，专业上。 2. 是不是回答了’三大问题‘ 3. 能不能展现我的特点 4. 能不能给别人留下印象 5. 思考有没有深度（文笔像小学生） 6. 是否足够简洁（不要考虑语言是否华丽）推荐看Emily的PS修改建议和前后对比，看黄黄（版主）的ps 细节：1. 看要求，一般不超过1K字 2. 不要写成流水账 3. 英语表达&amp;专业术语 4. 不要assume读者什么都不知道解释一大堆，尽量简洁 5. 不要太emotional（去掉你的惊叹号），不要写别人的感受做法等，只写自己的 6. 段落分配要合理 Q&amp;A科研经历不一定很match，关键体现你的思考方式等不用自爆家门，什么学校什么专业不用写你的论文名不用写项目的全称描述详细到’你想研究什么问题‘就可以了如果是大方向的，要突出研究能力，可以扯一些体现相关性的东西做了大比赛获得很多提高但是没获奖，还是要写，突出收获实习经历不一定要写，看申请学校是否看重]]></content>
      <tags>
        <tag>Application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[System Design]]></title>
    <url>%2F2019%2F05%2F14%2FSystem-Design%2F</url>
    <content type="text"><![CDATA[系統設計救星! 一天內手把手教你面試System design]]></content>
      <categories>
        <category>Foundation</category>
      </categories>
      <tags>
        <tag>Foundation</tag>
        <tag>System Design</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DesignPattern_Structural pattern part1]]></title>
    <url>%2F2019%2F05%2F13%2FDesignPattern-Structural-pattern%20part1%2F</url>
    <content type="text"><![CDATA[我们学习了 5 种构建型模式。它们主要用于构建对象。让我们简单回顾一下： ​工厂方法模式：为每一类对象建立工厂，将对象交由工厂创建，客户端只和工厂打交道。 ​抽象工厂模式：为每一类工厂提取出抽象接口，使得新增工厂、替换工厂变得非常容易。 ​建造者模式：用于创建构造过程稳定的对象，不同的 Builder 可以定义不同的配置。 ​单例模式：全局使用同一个对象，分为饿汉式和懒汉式。懒汉式有双检锁和内部类两种实现方式。 ​原型模式：为一个类定义 clone 方法，使得创建相同的对象更方便。 本篇文章我们将一起学习结构型模式，顾名思义，结构型模式是用来设计程序的结构的。结构型模式就像搭积木，将不同的类结合在一起形成契合的结构。包括以下几种： ​适配器模式 ​桥接模式 ​组合模式 ​装饰模式 ​外观模式 ​享元模式 ​代理模式 由于内容较多，本篇我们先讲解前三种模式。 一、适配器模式 Adapter Convert the existing interfaces to a new interface to achieve compatibility and reusability of the unrelated classes in one application. Also known as Wrapper pattern. 说到适配器，我们最熟悉的莫过于电源适配器了，也就是手机的充电头。它就是适配器模式的一个应用。 试想一下，你有一条连接电脑和手机的 USB 数据线，连接电脑的一端从电脑接口处接收 5V 的电压，连接手机的一端向手机输出 5V 的电压，并且他们工作良好。 中国的家用电压都是 220V，所以 USB 数据线不能直接拿来给手机充电，这时候我们有两种方案： 单独制作手机充电器，接收 220V 家用电压，输出 5V 电压。添加一个适配器，将 220V 家庭电压转化为类似电脑接口的 5V 电压，再连接数据线给手机充电。如果你使用过早期的手机，就会知道以前的手机厂商采用的就是第一种方案：早期的手机充电器都是单独制作的，充电头和充电线是连在一起的。现在的手机都采用了电源适配器加数据线的方案。这是生活中应用适配器模式的一个进步。 适配器模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。适配的意思是适应、匹配。通俗地讲，适配器模式适用于 有相关性但不兼容的结构，源接口通过一个中间件转换后才可以适用于目标接口，这个转换过程就是适配，这个中间件就称之为适配器。 家用电源和 USB 数据线有相关性：家用电源输出电压，USB 数据线输入电压。但两个接口无法兼容，因为一个输出 220V，一个输入 5V，通过适配器将输出 220V 转换成输出 5V 之后才可以一起工作。 让我们用程序来模拟一下这个过程。 首先，家庭电源提供 220V 的电压： 1234567class HomeBattery &#123; int supply() &#123; // 家用电源提供一个 220V 的输出电压 return 220; &#125;&#125; USB 数据线只接收 5V 的充电电压：12345678class USBLine &#123; void charge(int volt) &#123; // 如果电压不是 5V，抛出异常 if (volt != 5) throw new IllegalArgumentException("只能接收 5V 电压"); // 如果电压是 5V，正常充电 System.out.println("正常充电"); &#125;&#125; 先来看看适配之前，用户如果直接用家庭电源给手机充电：123456789101112131415161718public class User &#123; @Test public void chargeForPhone() &#123; HomeBattery homeBattery = new HomeBattery(); int homeVolt = homeBattery.supply(); System.out.println("家庭电源提供的电压是 " + homeVolt + "V"); USBLine usbLine = new USBLine(); usbLine.charge(homeVolt); &#125;&#125;运行程序，输出如下：家庭电源提供的电压是 220Vjava.lang.IllegalArgumentException: 只能接收 5V 电压这时，我们加入电源适配器： 1234567class Adapter &#123; int convert(int homeVolt) &#123; // 适配过程：使用电阻、电容等器件将其降低为输出 5V int chargeVolt = homeVolt - 215; return chargeVolt; &#125;&#125; 然后，用户再使用适配器将家庭电源提供的电压转换为充电电压：123456789101112131415161718192021public class User &#123; @Test public void chargeForPhone() &#123; HomeBattery homeBattery = new HomeBattery(); int homeVolt = homeBattery.supply(); System.out.println("家庭电源提供的电压是 " + homeVolt + "V"); Adapter adapter = new Adapter(); int chargeVolt = adapter.convert(homeVolt); System.out.println("使用适配器将家庭电压转换成了 " + chargeVolt + "V"); USBLine usbLine = new USBLine(); usbLine.charge(chargeVolt); &#125;&#125;运行程序，输出如下：家庭电源提供的电压是 220V使用适配器将家庭电压转换成了 5V正常充电 这就是适配器模式。在我们日常的开发中经常会使用到各种各样的 Adapter，都属于适配器模式的应用。 但适配器模式并不推荐多用。因为未雨绸缪好过亡羊补牢，如果事先能预防接口不同的问题，不匹配问题就不会发生，只有遇到源接口无法改变时，才应该考虑使用适配器。比如现代的电源插口中很多已经增加了专门的充电接口，让我们不需要再使用适配器转换接口，这又是社会的一个进步。 二、桥接模式 Bridge Decouple an abstraction or interface from its implementation so that the two can vary independently. 考虑这样一个需求：绘制矩形、圆形、三角形这三种图案。按照面向对象的理念，我们至少需要三个具体类，对应三种不同的图形。 抽象接口 IShape：123public interface IShape &#123; void draw();&#125; 三个具体形状类：12345678910111213141516171819202122class Rectangle implements IShape &#123; @Override public void draw() &#123; System.out.println("绘制矩形"); &#125;&#125;class Round implements IShape &#123; @Override public void draw() &#123; System.out.println("绘制圆形"); &#125;&#125;class Triangle implements IShape &#123; @Override public void draw() &#123; System.out.println("绘制三角形"); &#125;&#125; 接下来我们有了新的需求，每种形状都需要有四种不同的颜色：红、蓝、黄、绿。 这时我们很容易想到两种设计方案： 为了复用形状类，将每种形状定义为父类，每种不同颜色的图形继承自其形状父类。此时一共有 12 个类。 为了复用颜色类，将每种颜色定义为父类，每种不同颜色的图形继承自其颜色父类。此时一共有 12 个类。乍一看没什么问题，我们使用了面向对象的继承特性，复用了父类的代码并扩展了新的功能。 但仔细想一想，如果以后要增加一种颜色，比如黑色，那么我们就需要增加三个类；如果再要增加一种形状，我们又需要增加五个类，对应 5 种颜色。 更不用说遇到增加 20 个形状，20 种颜色的需求，不同的排列组合将会使工作量变得无比的庞大。看来我们不得不重新思考设计方案。 形状和颜色，都是图形的两个属性。他们两者的关系是平等的，所以不属于继承关系。更好的的实现方式是：将形状和颜色分离，根据需要对形状和颜色进行组合，这就是桥接模式的思想。 桥接模式：将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体模式或接口模式。官方定义非常精准、简练，但却有点不易理解。通俗地说，如果一个对象有两种或者多种分类方式，并且两种分类方式都容易变化，比如本例中的形状和颜色。这时使用继承很容易造成子类越来越多，所以更好的做法是把这种分类方式分离出来，让他们独立变化，使用时将不同的分类进行组合即可。 说到这里，不得不提一个设计原则：合成 / 聚合复用原则。虽然它没有被划分到六大设计原则中，但它在面向对象的设计中也非常的重要。 合成 / 聚合复用原则：优先使用合成 / 聚合，而不是类继承。 继承虽然是面向对象的三大特性之一，但继承会导致子类与父类有非常紧密的依赖关系，它会限制子类的灵活性和子类的复用性。而使用合成 / 聚合，也就是使用接口实现的方式，就不存在依赖问题，一个类可以实现多个接口，可以很方便地拓展功能。 让我们一起来看一下本例使用桥接模式的程序实现： 新建接口类 IColor，仅包含一个获取颜色的方法：123public interface IColor &#123; String getColor();&#125; 每种颜色都实现此接口：123456789101112131415161718192021222324252627282930public class Red implements IColor &#123; @Override public String getColor() &#123; return "红"; &#125;&#125;public class Blue implements IColor &#123; @Override public String getColor() &#123; return "蓝"; &#125;&#125;public class Yellow implements IColor &#123; @Override public String getColor() &#123; return "黄"; &#125;&#125;public class Green implements IColor &#123; @Override public String getColor() &#123; return "绿"; &#125;&#125; 在每个形状类中，桥接 IColor 接口：12345678910111213141516171819202122232425262728293031323334353637383940414243class Rectangle implements IShape &#123; private IColor color; void setColor(IColor color) &#123; this.color = color; &#125; @Override public void draw() &#123; System.out.println("绘制" + color.getColor() + "矩形"); &#125;&#125;class Round implements IShape &#123; private IColor color; void setColor(IColor color) &#123; this.color = color; &#125; @Override public void draw() &#123; System.out.println("绘制" + color.getColor() + "圆形"); &#125;&#125;class Triangle implements IShape &#123; private IColor color; void setColor(IColor color) &#123; this.color = color; &#125; @Override public void draw() &#123; System.out.println("绘制" + color.getColor() + "三角形"); &#125;&#125; 测试函数：12345678910111213141516171819@Testpublic void drawTest() &#123; Rectangle rectangle = new Rectangle(); rectangle.setColor(new Red()); rectangle.draw(); Round round = new Round(); round.setColor(new Blue()); round.draw(); Triangle triangle = new Triangle(); triangle.setColor(new Yellow()); triangle.draw();&#125;运行程序，输出如下：绘制红矩形绘制蓝圆形绘制黄三角形 这时我们再来回顾一下官方定义：将抽象部分与它的实现部分分离，使它们都可以独立地变化。抽象部分指的是父类，对应本例中的形状类，实现部分指的是不同子类的区别之处。将子类的区别方式 —— 也就是本例中的颜色 —— 分离成接口，通过组合的方式桥接颜色和形状，这就是桥接模式，它主要用于 两个或多个同等级的接口。 三、组合模式 Composite Build a complex object out of elemental objects and itself like a tree structure. 上文说到，桥接模式用于将同等级的接口互相组合，那么组合模式和桥接模式有什么共同点吗？ 事实上组合模式和桥接模式的组合完全不一样。组合模式用于 整体与部分的结构，当整体与部分有相似的结构，在操作时可以被一致对待时，就可以使用组合模式。例如： 文件夹和子文件夹的关系：文件夹中可以存放文件，也可以新建文件夹，子文件夹也一样。总公司子公司的关系：总公司可以设立部门，也可以设立分公司，子公司也一样。树枝和分树枝的关系：树枝可以长出叶子，也可以长出树枝，分树枝也一样。在这些关系中，虽然整体包含了部分，但无论整体或部分，都具有一致的行为。 组合模式：又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。考虑这样一个实际应用：设计一个公司的人员分布结构，结构如下图所示。 我们注意到人员结构中有两种结构，一是管理者，如老板，PM，CFO，CTO，二是职员。其中有的管理者不仅仅要管理职员，还会管理其他的管理者。这就是一个典型的整体与部分的结构。 3.1.不使用组合模式的设计方案要描述这样的结构，我们很容易想到以下设计方案： 新建管理者类：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Manager &#123; // 职位 private String position; // 工作内容 private String job; // 管理的管理者 private List&lt;Manager&gt; managers = new ArrayList&lt;&gt;(); // 管理的职员 private List&lt;Employee&gt; employees = new ArrayList&lt;&gt;(); public Manager(String position, String job) &#123; this.position = position; this.job = job; &#125; public void addManager(Manager manager) &#123; managers.add(manager); &#125; public void removeManager(Manager manager) &#123; managers.remove(manager); &#125; public void addEmployee(Employee employee) &#123; employees.add(employee); &#125; public void removeEmployee(Employee employee) &#123; employees.remove(employee); &#125; // 做自己的本职工作 public void work() &#123; System.out.println("我是" + position + "，我正在" + job); &#125; // 检查下属 public void check() &#123; work(); for (Employee employee : employees) &#123; employee.work(); &#125; for (Manager manager : managers) &#123; manager.check(); &#125; &#125;&#125; 新建职员类：12345678910111213141516public class Employee &#123; // 职位 private String position; // 工作内容 private String job; public Employee(String position, String job) &#123; this.position = position; this.job = job; &#125; // 做自己的本职工作 public void work() &#123; System.out.println("我是" + position + "，我正在" + job); &#125;&#125; 客户端建立人员结构关系：1234567891011121314151617181920212223242526272829public class Client &#123; @Test public void test() &#123; Manager boss = new Manager("老板", "唱怒放的生命"); Employee HR = new Employee("人力资源", "聊微信"); Manager PM = new Manager("产品经理", "不知道干啥"); Manager CFO = new Manager("财务主管", "看剧"); Manager CTO = new Manager("技术主管", "划水"); Employee UI = new Employee("设计师", "画画"); Employee operator = new Employee("运营人员", "兼职客服"); Employee webProgrammer = new Employee("程序员", "学习设计模式"); Employee backgroundProgrammer = new Employee("后台程序员", "CRUD"); Employee accountant = new Employee("会计", "背九九乘法表"); Employee clerk = new Employee("文员", "给老板递麦克风"); boss.addEmployee(HR); boss.addManager(PM); boss.addManager(CFO); PM.addEmployee(UI); PM.addManager(CTO); PM.addEmployee(operator); CTO.addEmployee(webProgrammer); CTO.addEmployee(backgroundProgrammer); CFO.addEmployee(accountant); CFO.addEmployee(clerk); boss.check(); &#125;&#125; 运行测试方法，输出如下（为方便查看，笔者添加了缩进）：1234567891011我是老板，我正在唱怒放的生命 我是人力资源，我正在聊微信 我是产品经理，我正在不知道干啥 我是设计师，我正在画画 我是运营人员，我正在兼职客服 我是技术主管，我正在划水 我是程序员，我正在学习设计模式 我是后台程序员，我正在CRUD 我是财务主管，我正在看剧 我是会计，我正在背九九乘法表 我是文员，我正在给老板递麦克风 这样我们就设计出了公司的结构，但是这样的设计有两个弊端： name 字段，job 字段，work 方法重复了。 管理者对其管理的管理者和职员需要区别对待。 关于第一个弊端，虽然这里为了讲解，只有两个字段和一个方法重复，实际工作中这样的整体部分结构会有相当多的重复。比如此例中还可能有工号、年龄等字段，领取工资、上下班打卡、开各种无聊的会等方法。 大量的重复显然是很丑陋的代码，分析一下可以发现， Manager 类只比 Employee 类多一个管理人员的列表字段，多几个增加 / 移除人员的方法，其他的字段和方法全都是一样的。 有读者应该会想到：我们可以将重复的字段和方法提取到一个工具类中，让 Employee 和 Manager 都去调用此工具类，就可以消除重复了。 这样固然可行，但属于 Employee 和 Manager 类自己的东西却要通过其他类调用，并不利于程序的高内聚。 关于第二个弊端，此方案无法解决，此方案中 Employee 和 Manager 类完全是两个不同的对象，两者的相似性被忽略了。 所以我们有更好的设计方案，那就是组合模式！ 3.2.使用组合模式的设计方案组合模式最主要的功能就是让用户可以一致对待整体和部分结构，将两者都作为一个相同的组件，所以我们先新建一个抽象的组件类：12345678910111213141516171819202122public abstract class Component &#123; // 职位 private String position; // 工作内容 private String job; public Component(String position, String job) &#123; this.position = position; this.job = job; &#125; // 做自己的本职工作 public void work() &#123; System.out.println("我是" + position + "，我正在" + job); &#125; abstract void addComponent(Component component); abstract void removeComponent(Component component); abstract void check();&#125; 管理者继承自此抽象类：123456789101112131415161718192021222324252627public class Manager extends Component &#123; // 管理的组件 private List&lt;Component&gt; components = new ArrayList&lt;&gt;(); public Manager(String position, String job) &#123; super(position, job); &#125; @Override public void addComponent(Component component) &#123; components.add(component); &#125; @Override void removeComponent(Component component) &#123; components.remove(component); &#125; // 检查下属 @Override public void check() &#123; work(); for (Component component : components) &#123; component.check(); &#125; &#125;&#125; 职员同样继承自此抽象类：123456789101112131415161718192021public class Employee extends Component &#123; public Employee(String position, String job) &#123; super(position, job); &#125; @Override void addComponent(Component component) &#123; System.out.println("职员没有管理权限"); &#125; @Override void removeComponent(Component component) &#123; System.out.println("职员没有管理权限"); &#125; @Override void check() &#123; work(); &#125;&#125; 修改客户端如下：1234567891011121314151617181920212223242526272829public class Client &#123; @Test public void test()&#123; Component boss = new Manager("老板", "唱怒放的生命"); Component HR = new Employee("人力资源", "聊微信"); Component PM = new Manager("产品经理", "不知道干啥"); Component CFO = new Manager("财务主管", "看剧"); Component CTO = new Manager("技术主管", "划水"); Component UI = new Employee("设计师", "画画"); Component operator = new Employee("运营人员", "兼职客服"); Component webProgrammer = new Employee("程序员", "学习设计模式"); Component backgroundProgrammer = new Employee("后台程序员", "CRUD"); Component accountant = new Employee("会计", "背九九乘法表"); Component clerk = new Employee("文员", "给老板递麦克风"); boss.addComponent(HR); boss.addComponent(PM); boss.addComponent(CFO); PM.addComponent(UI); PM.addComponent(CTO); PM.addComponent(operator); CTO.addComponent(webProgrammer); CTO.addComponent(backgroundProgrammer); CFO.addComponent(accountant); CFO.addComponent(clerk); boss.check(); &#125;&#125; 运行测试方法，输出结果与之前的结果一模一样。 可以看到，使用组合模式后，我们解决了之前的两个弊端。一是将共有的字段与方法移到了父类中，消除了重复，并且在客户端中，可以一致对待 Manager 和 Employee 类： Manager 类和 Employee 类统一声明为 Component 对象 统一调用 Component 对象的 addComponent 方法添加子对象即可。 3.3.组合模式中的安全方式与透明方式读者可能已经注意到了，Employee 类虽然继承了父类的 addComponent 和 removeComponent 方法，但是仅仅提供了一个空实现，因为 Employee 类是不支持添加和移除组件的。这样是否违背了接口隔离原则呢？ 接口隔离原则：客户端不应依赖它不需要的接口。如果一个接口在实现时，部分方法由于冗余被客户端空实现，则应该将接口拆分，让实现类只需依赖自己需要的接口方法。 答案是肯定的，这样确实违背了接口隔离原则。这种方式在组合模式中被称作透明方式. 透明方式：在 Component 中声明所有管理子对象的方法，包括 add 、remove 等，这样继承自 Component 的子类都具备了 add、remove 方法。对于外界来说叶节点和枝节点是透明的，它们具备完全一致的接口。 这种方式有它的优点：让 Manager 类和 Employee 类具备完全一致的行为接口，调用者可以一致对待它们。 但它的缺点也显而易见：Employee 类并不支持管理子对象，不仅违背了接口隔离原则，而且客户端可以用 Employee 类调用 addComponent 和 removeComponent 方法，导致程序出错，所以这种方式是不安全的。 那么我们可不可以将 addComponent 和 removeComponent 方法移到 Manager 子类中去单独实现，让 Employee 不再实现这两个方法呢？我们来尝试一下。 将抽象类修改为：123456789101112131415161718public abstract class Component &#123; // 职位 private String position; // 工作内容 private String job; public Component(String position, String job) &#123; this.position = position; this.job = job; &#125; // 做自己的本职工作 public void work() &#123; System.out.println("我是" + position + "，我正在" + job); &#125; abstract void check();&#125; 可以看到，我们在父类中去掉了 addComponent 和 removeComponent 这两个抽象方法。 Manager 类修改为：12345678910111213141516171819202122232425public class Manager extends Component &#123; // 管理的组件 private List&lt;Component&gt; components = new ArrayList&lt;&gt;(); public Manager(String position, String job) &#123; super(position, job); &#125; public void addComponent(Component component) &#123; components.add(component); &#125; void removeComponent(Component component) &#123; components.remove(component); &#125; // 检查下属 @Override public void check() &#123; work(); for (Component component : components) &#123; component.check(); &#125; &#125;&#125; Manager 类单独实现了 addComponent 和 removeComponent 这两个方法，去掉了 @Override 注解。 Employee 类修改为：1234567891011public class Employee extends Component &#123; public Employee(String position, String job) &#123; super(position, job); &#125; @Override void check() &#123; work(); &#125;&#125; 客户端建立人员结构关系：1234567891011121314151617181920212223242526272829public class Client &#123; @Test public void test()&#123; Manager boss = new Manager("老板", "唱怒放的生命"); Employee HR = new Employee("人力资源", "聊微信"); Manager PM = new Manager("产品经理", "不知道干啥"); Manager CFO = new Manager("财务主管", "看剧"); Manager CTO = new Manager("技术主管", "划水"); Employee UI = new Employee("设计师", "画画"); Employee operator = new Employee("运营人员", "兼职客服"); Employee webProgrammer = new Employee("程序员", "学习设计模式"); Employee backgroundProgrammer = new Employee("后台程序员", "CRUD"); Employee accountant = new Employee("会计", "背九九乘法表"); Employee clerk = new Employee("文员", "给老板递麦克风"); boss.addComponent(HR); boss.addComponent(PM); boss.addComponent(CFO); PM.addComponent(UI); PM.addComponent(CTO); PM.addComponent(operator); CTO.addComponent(webProgrammer); CTO.addComponent(backgroundProgrammer); CFO.addComponent(accountant); CFO.addComponent(clerk); boss.check(); &#125;&#125; 运行程序，输出结果与之前一模一样。 这种方式在组合模式中称之为安全方式。 安全方式：在 Component 中不声明 add 和 remove 等管理子对象的方法，这样叶节点就无需实现它，只需在枝节点中实现管理子对象的方法即可。 安全方式遵循了接口隔离原则，但由于不够透明，Manager 和 Employee 类不具有相同的接口，在客户端中，我们无法将 Manager 和 Employee 统一声明为 Component 类了，必须要区别对待，带来了使用上的不方便。 安全方式和透明方式各有好处，在使用组合模式时，需要根据实际情况决定。但大多数使用组合模式的场景都是采用的透明方式，虽然它有点不安全，但是客户端无需做任何判断来区分是叶子结点还是枝节点，用起来是真香。 总结到这里我们就把结构型模式的前三种介绍完了，让我们总结一下： 适配器模式：用于有相关性但不兼容的接口 桥接模式：用于同等级的接口互相组合 组合模式：用于整体与部分的结构 剩余四种结构型模式我们将在下篇文章中学习。 本文作者：Alpinist Wang 声明：本文归 “力扣” 版权所有，如需转载请联系。文章封面图和文中部分图片来源于网络，为非商业用途使用，如有侵权联系删除。]]></content>
      <categories>
        <category>Foundation</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DesignPattern_Creational Pattern]]></title>
    <url>%2F2019%2F05%2F12%2FDesignPattern_Creational%20Pattern%2F</url>
    <content type="text"><![CDATA[如何用「设计模式」制作珍珠奶茶？面向对象的特点是可维护、可复用、可扩展、灵活性好，它真正强大的地方在于：随着业务变得越来越复杂，面向对象依然能够使得程序结构良好，而面向过程却会导致程序越来越臃肿。 让面向对象保持结构良好的秘诀就是 设计模式，今天力扣就带领大家一起来探索设计模式的世界！ 设计模式的六大原则设计模式的世界丰富多彩，比如生产一个个「产品」的工厂模式，衔接两个不相关接口的适配器模式，用不同的方式做同一件事的策略模式，构建步骤稳定、根据构建过程的不同配置构建出不同对象的建造者模式等。 面向对象结合设计模式，才能真正体会到程序变得可维护、可复用、可扩展、灵活性好。设计模式对于程序员而言并不陌生，每个程序员在编程时都会或多或少地接触到设计模式。无论是在大型程序的架构中，亦或是在源码的学习中，设计模式都扮演着非常重要的角色。 设计模式基于六大原则： 开闭原则 Open Close Principle：一个软件实体如类、模块和函数应该对修改封闭，对扩展开放。 单一职责原则 Single Responsibility Principle：一个类只做一件事，一个类应该只有一个引起它修改的原因。 里氏替换原则 Liskov Substitution Principle：子类应该可以完全替换父类。也就是说在使用继承时，只扩展新功能，而不要破坏父类原有的功能。 依赖倒置原则 Dependence Inversion Principle：细节应该依赖于抽象，抽象不应依赖于细节。把抽象层放在程序设计的高层，并保持稳定，程序的细节变化由低层的实现层来完成。 迪米特法则 Law of Demeter （最少知识原则 Least Knowledge Principle）：又名「最少知道原则」，一个类不应知道自己操作的类的细节，换言之，只和朋友谈话，不和朋友的朋友谈话。 接口隔离原则 Interface segregation Principle：客户端不应依赖它不需要的接口。如果一个接口在实现时，部分方法由于冗余被客户端空实现，则应该将接口拆分，让实现类只需依赖自己需要的接口方法。 所有的设计模式都是为了程序能更好的满足这六大原则。设计模式一共有 23 种，今天我们先来学习构建型模式，一共五种，分别是： 工厂方法模式 抽象工厂模式 单例模式 建造型模式 原型模式 一、工厂模式 Factory Method Provides an abstraction or an interface and lets subclass or implementing classes decide which class or method should be instantiated or called, based on the conditions or parameters given. 在平时编程中，构建对象最常用的方式是 new 一个对象。乍一看这种做法没什么不好，而实际上这也属于一种硬编码。每 new 一个对象，相当于调用者多知道了一个类，增加了类与类之间的联系，不利于程序的松耦合。其实构建过程可以被封装起来，工厂模式便是用于封装对象的设计模式。 1.1.简单工厂模式 举个例子，直接 new 对象的方式相当于当我们需要一个苹果时，我们需要知道苹果的构造方法，需要一个梨子时，需要知道梨子的构造方法。更好的实现方式是有一个水果工厂，我们告诉工厂需要什么种类的水果，水果工厂将我们需要的水果制造出来给我们就可以了。这样我们就无需知道苹果、梨子是怎么种出来的，只用和水果工厂打交道即可。 水果工厂： 123456789public class FruitFactory &#123; public Fruit create(String type)&#123; switch (type)&#123; case "苹果": return new Apple(); case "梨子": return new Pear(); default: throw new IllegalArgumentException("暂时没有这种水果"); &#125; &#125;&#125; 调用者：123456789public class User &#123; private void eat()&#123; FruitFactory fruitFactory = new FruitFactory(); Fruit apple = fruitFactory.create("苹果"); Fruit pear = fruitFactory.create("梨子"); apple.eat(); pear.eat(); &#125;&#125; 事实上，将构建过程封装的好处不仅可以降低耦合，如果某个产品构造方法相当复杂，使用工厂模式可以大大减少代码重复。比如，如果生产一个苹果需要苹果种子、阳光、水分，将工厂修改如下：123456789101112131415public class FruitFactory &#123; public Fruit create(String type) &#123; switch (type) &#123; case "苹果": AppleSeed appleSeed = new AppleSeed(); Sunlight sunlight = new Sunlight(); Water water = new Water(); return new Apple(appleSeed, sunlight, water); case "梨子": return new Pear(); default: throw new IllegalArgumentException("暂时没有这种水果"); &#125; &#125;&#125; 调用者的代码则完全不需要变化，而且调用者不需要在每次需要苹果时，自己去构建苹果种子、阳光、水分以获得苹果。苹果的生产过程再复杂，也只是工厂的事。这就是封装的好处，假如某天科学家发明了让苹果更香甜的肥料，要加入苹果的生产过程中的话，也只需要在工厂中修改，调用者完全不用关心。 不知不觉中，我们就写出了简单工厂模式的代码。工厂模式一共有三种： 简单工厂模式 工厂方法模式 抽象工厂模式 注：在 GoF 所著的《设计模式》一书中，简单工厂模式被划分为工厂方法模式的一种特例，没有单独被列出来。 总而言之，简单工厂模式就是让一个工厂类承担构建所有对象的职责。调用者需要什么产品，让工厂生产出来即可。它的弊端也显而易见： 一是如果需要生产的产品过多，此模式会导致工厂类过于庞大，承担过多的职责，变成超级类。当苹果生产过程需要修改时，要来修改此工厂。梨子生产过程需要修改时，也要来修改此工厂。也就是说这个类不止一个引起修改的原因。违背了单一职责原则。二是当要生产新的产品时，必须在工厂类中添加新的分支。而开闭原则告诉我们：类应该对修改封闭。我们希望在添加新功能时，只需增加新的类，而不是修改既有的类，所以这就违背了开闭原则。 1.2.工厂方法模式 为了解决简单工厂模式的这两个弊端，工厂方法模式应运而生，它规定每个产品都有一个专属工厂。比如苹果有专属的苹果工厂，梨子有专属的梨子工厂，Java 代码如下： 苹果工厂：12345public class AppleFactory &#123; public Fruit create()&#123; return new Apple(); &#125;&#125; 梨子工厂：12345public class PearFactory &#123; public Fruit create()&#123; return new Pear(); &#125;&#125; 调用者：12345678910public class User &#123; private void eat()&#123; AppleFactory appleFactory = new AppleFactory(); Fruit apple = appleFactory.create(); PearFactory pearFactory = new PearFactory(); Fruit pear = pearFactory.create(); apple.eat(); pear.eat(); &#125;&#125; 有读者可能会开喷了，这样和直接 new 出苹果和梨子有什么区别？上文说工厂是为了减少类与类之间的耦合，让调用者尽可能少的和其他类打交道。用简单工厂模式，我们只需要知道 FruitFactory，无需知道 Apple 、Pear 类，很容易看出耦合度降低了。但用工厂方法模式，调用者虽然不需要和 Apple 、Pear 类打交道了，但却需要和 AppleFactory、PearFactory 类打交道。有几种水果就需要知道几个工厂类，耦合度完全没有下降啊，甚至还增加了代码量！ 这位读者请先放下手中的大刀，仔细想一想，工厂模式的第二个优点在工厂方法模式中还是存在的。当构建过程相当复杂时，工厂将构建过程封装起来，调用者可以很方便的直接使用，同样以苹果生产为例：12345678public class AppleFactory &#123; public Fruit create()&#123; AppleSeed appleSeed = new AppleSeed(); Sunlight sunlight = new Sunlight(); Water water = new Water(); return new Apple(appleSeed, sunlight, water); &#125;&#125; 调用者无需知道苹果的生产细节，当生产过程需要修改时也无需更改调用端。同时，工厂方法模式解决了简单工厂模式的两个弊端。 当生产的产品种类越来越多时，工厂类不会变成超级类。工厂类会越来越多，保持灵活。不会越来越大、变得臃肿。如果苹果的生产过程需要修改时，只需修改苹果工厂。梨子的生产过程需要修改时，只需修改梨子工厂。符合单一职责原则。 当需要生产新的产品时，无需更改既有的工厂，只需要添加新的工厂即可。保持了面向对象的可扩展性，符合开闭原则。 1.3.抽象工厂模式 Abstract Factory Provides one level of interface higher than the factory pattern. It is used to return one of several factories. 工厂方法模式可以进一步优化，提取出工厂接口： 123public interface IFactory &#123; Fruit create();&#125; 然后苹果工厂和梨子工厂都实现此接口：1234567891011121314public class AppleFactory implements IFactory &#123; @Override public Fruit create()&#123; return new Apple(); &#125;&#125;public class PearFactory implements IFactory &#123; @Override public Fruit create()&#123; return new Pear(); &#125;&#125; 此时，调用者可以将 AppleFactory 和 PearFactory 统一作为 IFactory 对象使用，调用者 Java 代码如下：12345678910public class User &#123; private void eat()&#123; IFactory appleFactory = new AppleFactory(); Fruit apple = appleFactory.create(); IFactory pearFactory = new PearFactory(); Fruit pear = pearFactory.create(); apple.eat(); pear.eat(); &#125;&#125; 可以看到，我们在创建时指定了具体的工厂类后，在使用时就无需再关心是哪个工厂类，只需要将此工厂当作抽象的 IFactory 接口使用即可。这种经过抽象的工厂方法模式被称作抽象工厂模式。 由于客户端只和 IFactory 打交道了，调用的是接口中的方法，使用时根本不需要知道是在哪个具体工厂中实现的这些方法，这就使得替换工厂变得非常容易。 例如：12345678910111213141516public class User &#123; private void eat()&#123; IFactory factory = new AppleFactory(); Fruit fruit = factory.create(); fruit.eat(); &#125;&#125;//如果需要替换为吃梨子，只需要更改一行代码即可：public class User &#123; private void eat()&#123; IFactory factory = new PearFactory(); Fruit fruit = factory.create(); fruit.eat(); &#125;&#125; IFactory 中只有一个抽象方法时，或许还看不出抽象工厂模式的威力。实际上抽象工厂模式主要用于替换一系列方法。例如将程序中的 SQL Server 数据库整个替换为 Access 数据库，使用抽象方法模式的话，只需在 IFactory 接口中定义好增删改查四个方法，让 SQLFactory 和 AccessFactory 实现此接口，调用时直接使用 IFactory 中的抽象方法即可，调用者无需知道使用的什么数据库，我们就可以非常方便的整个替换程序的数据库，并且让客户端毫不知情。 抽象工厂模式很好的发挥了开闭原则、依赖倒置原则，但缺点是抽象工厂模式太重了，如果 IFactory 接口需要新增功能，则会影响到所有的具体工厂类。使用抽象工厂模式，替换具体工厂时只需更改一行代码，但要新增抽象方法则需要修改所有的具体工厂类。所以抽象工厂模式适用于增加同类工厂这样的横向扩展需求，不适合新增功能这样的纵向扩展。 二、单例模式 Singleton One instance of a class or one value accessible globally in an application. 单例模式非常常见，某个对象全局只需要一个实例时，就可以使用单例模式。它的优点也显而易见： 它能够避免对象重复创建，节约空间并提升效率 避免由于操作不同实例导致的逻辑错误 单例模式有两种实现方式：饿汉式和懒汉式。 2.1.饿汉式 饿汉式：变量在声明时便初始化。1234567891011public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 可以看到，我们将构造方法定义为 private，这就保证了其他类无法实例化此类，必须通过 getInstance 方法才能获取到唯一的 instance 实例，非常直观。但饿汉式有一个弊端，那就是即使这个单例不需要使用，它也会在类加载之后立即创建出来，占用一块内存，并增加类初始化时间。就好比一个电工在修理灯泡时，先把所有工具拿出来，不管是不是所有的工具都用得上。就像一个饥不择食的饿汉，所以称之为饿汉式。 2.2.懒汉式 懒汉式：先声明一个空变量，需要用时才初始化。例如：1234567891011121314public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance()&#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 我们先声明了一个初始值为 null 的 instance 变量，当需要使用时判断此变量是否已被初始化，没有初始化的话才 new 一个实例出来。就好比电工在修理灯泡时，开始比较偷懒，什么工具都不拿，当发现需要使用螺丝刀时，才把螺丝刀拿出来。当需要用钳子时，再把钳子拿出来。就像一个不到万不得已不会行动的懒汉，所以称之为懒汉式。 懒汉式解决了饿汉式的弊端，好处是按需加载，避免了内存浪费，减少了类初始化时间。 上述代码的懒汉式单例乍一看没什么问题，但其实它不是线程安全的。如果有多个线程同一时间调用 getInstance 方法，instance 变量可能会被实例化多次。为了保证线程安全，我们需要给判空过程加上锁：12345678910111213141516public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 这样就能保证多个线程调用 getInstance 时，一次最多只有一个线程能够执行判空并 new 出实例的操作，所以 instance 只会实例化一次。但这样的写法仍然有问题，当多个线程调用 getInstance 时，每次都需要执行 synchronized 同步化方法，这样会严重影响程序的执行效率。所以更好的做法是在同步化之前，再加上一层检查：123456789101112131415161718public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 这样增加一种检查方式后，如果 instance 已经被实例化，则不会执行同步化操作，大大提升了程序效率。上面这种写法也就是我们平时较常用的双检锁方式实现的线程安全的单例模式。 除了双检锁方式外，还有一种比较常见的静态内部类方式保证懒汉式单例的线程安全：12345678910111213public class Singleton &#123; private static class SingletonHolder &#123; public static Singleton instance = new Singleton(); &#125; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125; 虽然我们经常使用这种静态内部类的懒加载方式，但其中的原理不一定每个人都清楚。接下来我们便来分析其原理，搞清楚两个问题： 静态内部类方式是怎么实现懒加载的 静态内部类方式是怎么保证线程安全的 Java 类的加载过程包括：加载、验证、准备、解析、初始化。初始化阶段即执行类的 clinit 方法（clinit = class + initialize），包括为类的静态变量赋初始值和执行静态代码块中的内容。但不会立即加载内部类，内部类会在使用时才加载。所以当此 Singleton 类加载时，SingletonHolder 并不会被立即加载，所以不会像饿汉式那样占用内存。 另外，Java 虚拟机规定，当访问一个类的静态字段时，如果该类尚未初始化，则立即初始化此类。当调用Singleton 的 getInstance 方法时，由于其使用了 SingletonHolder 的静态变量 instance，所以这时才会去初始化 SingletonHolder，在 SingletonHolder 中 new 出 Singleton 对象。这就实现了懒加载。 第二个问题的答案是 Java 虚拟机的设计是非常稳定的，早已经考虑到了多线程并发执行的情况。虚拟机在加载类的 clinit 方法时，会保证 clinit 在多线程中被正确的加锁、同步。即使有多个线程同时去初始化一个类，一次也只有一个线程可以执行 clinit 方法，其他线程都需要阻塞等待，从而保证了线程安全。 懒加载方式在平时非常常见，比如打开我们常用的美团、饿了么、支付宝 app，应用首页会立刻刷新出来，但其他标签页在我们点击到时才会刷新。这样就减少了流量消耗，并缩短了程序启动时间。再比如游戏中的某些模块，当我们点击到时才会去下载资源，而不是事先将所有资源都先下载下来，这也属于懒加载方式，避免了内存浪费。 但懒汉式的缺点就是将程序加载时间从启动时延后到了运行时，虽然启动时间缩短了，但我们浏览页面时就会看到数据的 loading 过程。如果用饿汉式将页面提前加载好，我们浏览时就会特别的顺畅，也不失为一个好的用户体验。比如我们常用的 QQ、微信 app，作为即时通讯的工具软件，它们会在启动时立即刷新所有的数据，保证用户看到最新最全的内容。著名的软件大师 Martin 在《代码整洁之道》一书中也说到：不提倡使用懒加载方式，因为程序应该将构建与使用分离，达到解耦。饿汉式在声明时直接初始化变量的方式也更直观易懂。所以在使用饿汉式还是懒汉式时，需要权衡利弊。 一般的建议是：对于构建不复杂，加载完成后会立即使用的单例对象，推荐使用饿汉式。对于构建过程耗时较长，并不是所有使用此类都会用到的单例对象，推荐使用懒汉式。 三、建造型模式 Builder Construct a complex object from simple objects step by step. 建造型模式用于创建过程稳定，但配置多变的对象。在《设计模式》一书中的定义是：将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。 经典的「建造者-指挥者」模式现在已经不太常用了，现在建造者模式主要用来通过链式调用生成不同的配置。比如我们要制作一杯珍珠奶茶。它的制作过程是稳定的，除了必须要知道奶茶的种类和规格外，是否加珍珠和是否加冰是可选的。使用建造者模式表示如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class MilkTea &#123; private final String type; private final String size; private final boolean pearl; private final boolean ice; private MilkTea(Builder builder) &#123; this.type = builder.type; this.size = builder.size; this.pearl = builder.pearl; this.ice = builder.ice; &#125; public String getType() &#123; return type; &#125; public String getSize() &#123; return size; &#125; public boolean isPearl() &#123; return pearl; &#125; public boolean isIce() &#123; return ice; &#125; public static class Builder &#123; private final String type; private String size = "中杯"; private boolean pearl = true; private boolean ice = false; public Builder(String type) &#123; this.type = type; &#125; public Builder size(String size) &#123; this.size = size; return this; &#125; public Builder pearl(boolean pearl) &#123; this.pearl = pearl; return this; &#125; public Builder ice(boolean cold) &#123; this.ice = cold; return this; &#125; public MilkTea build() &#123; return new MilkTea(this); &#125; &#125;&#125; 可以看到，我们将 MilkTea 的构造方法设置为私有的，所以外部不能通过 new 构建出 MilkTea 实例，只能通过 Builder 构建。对于必须配置的属性，通过 Builder 的构造方法传入，可选的属性通过 Builder 的链式调用方法传入，如果不配置，将使用默认配置，也就是中杯、加珍珠、不加冰。根据不同的配置可以制作出不同的奶茶：123456789101112131415161718192021222324252627282930313233343536public class User &#123; private void buyMilkTea() &#123; MilkTea milkTea = new MilkTea.Builder("原味").build(); show(milkTea); MilkTea chocolate =new MilkTea.Builder("巧克力味") .ice(false) .build(); show(chocolate); MilkTea strawberry = new MilkTea.Builder("草莓味") .size("大杯") .pearl(false) .ice(true) .build(); show(strawberry); &#125; private void show(MilkTea milkTea) &#123; String pearl; if (milkTea.isPearl()) pearl = "加珍珠"; else pearl = "不加珍珠"; String ice; if (milkTea.isIce()) &#123; ice = "加冰"; &#125; else &#123; ice = "不加冰"; &#125; System.out.println("一份" + milkTea.getSize() + "、" + pearl + "、" + ice + "的" + milkTea.getType() + "奶茶"); &#125;&#125; 运行程序，输出如下：123一份中杯、加珍珠、不加冰的原味奶茶一份中杯、加珍珠、不加冰的巧克力味奶茶一份大杯、不加珍珠、加冰的草莓味奶茶 使用建造者模式的好处是不用担心忘了指定某个配置，保证了构建过程是稳定的。在 OkHttp、Retrofit 等著名框架的源码中都使用到了建造者模式。 四、原型模式 Prototype Cloning an object by reducing the cost of creation. 原型模式：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 Java 中，Object 的 clone() 方法就属于原型模式。 举个例子，比如有一天，周杰伦到奶茶店点了一份不加冰的原味奶茶，你说我是周杰伦的忠实粉，我也要一份跟周杰伦一样的。用程序表示如下： 奶茶类：1234public class MilkTea &#123; public String type; public boolean ice;&#125; 下单：1234567private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = "原味"; milkTeaOfJay.ice = false; MilkTea yourMilkTea = milkTeaOfJay;&#125; 好像没什么问题，将周杰伦的奶茶直接赋值到你的奶茶上就行了，看起来我们并不需要 clone 方法。但是这样真的是复制了一份奶茶吗？ 当然不是，Java 的赋值只是传递地址。这样赋值之后，yourMilkTea 仍然指向的周杰伦的奶茶，并不会多一份一样的奶茶。 那么我们要怎么做才能点一份一样的奶茶呢？将程序修改如下就可以了：123456789private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = "原味"; milkTeaOfJay.ice = false; MilkTea yourMilkTea = new MilkTea(); yourMilkTea.type = "原味"; yourMilkTea.ice = false;&#125; 只有这样，yourMilkTea 才是 new 出来的一份全新的奶茶。我们设想一下，如果有一千个粉丝都需要点和周杰伦一样的奶茶的话，按照现在的写法就需要 new 一千次，并为每一个新的对象赋值一千次，造成大量的重复。 更糟糕的是，如果周杰伦临时决定加个冰，那么粉丝们的奶茶配置也要跟着修改：123456789101112private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = "原味"; milkTeaOfJay.ice = true; MilkTea yourMilkTea = new MilkTea(); yourMilkTea.type = "原味"; yourMilkTea.ice = true; // 将一千个粉丝的 ice 都修改为 true ...&#125; 大批量的修改无疑是非常丑陋的做法，这就是我们需要 clone 方法的理由！ 运用原型模式，在 MilkTea 中新增 clone 方法：1234567891011public class MilkTea&#123; public String type; public boolean ice; public MilkTea clone()&#123; MilkTea milkTea = new MilkTea(); milkTea.type = this.type; milkTea.ice = this.ice; return milkTea; &#125;&#125; 下单：12345678910private void order()&#123; MilkTea milkTeaOfJay = new MilkTea(); milkTeaOfJay.type = "原味"; milkTeaOfJay.ice = false; MilkTea yourMilkTea = milkTeaOfJay.clone(); // 一千位粉丝都调用 milkTeaOfJay 的 clone 方法即可 ...&#125; 这就是原型模式，Java 中有一个语法糖，让我们并不需要手写 clone 方法。这个语法糖就是 Cloneable 接口，我们只要让需要拷贝的类实现此接口即可。12345678910public class MilkTea implements Cloneable&#123; public String type; public boolean ice; @NonNull @Override protected MilkTea clone() throws CloneNotSupportedException &#123; return (MilkTea) super.clone(); &#125;&#125; 值得注意的是，Java 自带的 clone 方法是浅拷贝的。也就是说调用此对象的 clone 方法，只有基本类型的参数会被拷贝一份，非基本类型的对象不会被拷贝一份，而是继续使用传递引用的方式。如果需要实现深拷贝，必须要自己手动修改 clone 方法才行。 Conclusion of Creational pattern创建型模式总体上比较简单，它们的作用就是为了产生实例对象，算是各种工作的第一步了，因为我们写的是面向对象的代码，所以我们第一步当然是需要创建一个对象了。 简单工厂模式最简单；工厂模式在简单工厂模式的基础上增加了选择工厂的维度，需要第一步选择合适的工厂；抽象工厂模式有产品族的概念，如果各个产品是存在兼容性问题的，就要用抽象工厂模式。单例模式就不说了，为了保证全局使用的是同一对象，一方面是安全性考虑，一方面是为了节省资源；建造者模式专门对付属性很多的那种类，为了让代码更优美；原型模式用得最少，了解和 Object 类中的 clone() 方法相关的知识即可。 今天我们学习了设计模式的 5 种构建型模式，除此之外还有 11 种行为型模式和 7 种结构型模式，我们将在以后的文章中继续学习。 如何用「设计模式」制作珍珠奶茶？– 力扣（LeetCode） Taiwan]]></content>
      <categories>
        <category>Foundation</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Design Patterns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GGG]]></title>
    <url>%2F2019%2F05%2F11%2FGRE%2F</url>
    <content type="text"><![CDATA[GRE Study Plans and GuidesMagoosh GRE Blog GRE Study Plans and Guides Manhattan Prep PP1&amp;PP2官方送的兩次模考 Verbal: Google搜尋: 考满分巍哥填空機經1000題 Quant: 猴哥難題]]></content>
      <categories>
        <category>Application</category>
      </categories>
      <tags>
        <tag>Application</tag>
        <tag>GRE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java]]></title>
    <url>%2F2019%2F04%2F28%2FJava%2F</url>
    <content type="text"><![CDATA[JAVE SE乐观锁、悲观锁，这一篇就够了！ JAVE EEJava TutorialSpring Boot Tutoiral resource面镜 jvm虛擬機 Thinking in java 基础题目 牛客网Java面试宝典 [北航大佬收集的资源，里面有jvm虚拟机什么的]（https://space.bilibili.com/73012391）圣地 相關工程實作指導牛人计划——叶神Java知乎类资讯网站实战（高级） 牛人计划——叶神Java知乎类资讯网站实战（高级） 工程視頻講解[北航大佬收集的资源，里面有jvm虚拟机什么的]（https://space.bilibili.com/73012391/channel/detail?cid=71336）]]></content>
      <categories>
        <category>Diary</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithm]]></title>
    <url>%2F2019%2F04%2F19%2FAlgorithm%2F</url>
    <content type="text"><![CDATA[首先声明一点，面试是面试，做题是做题，做题是面试的必要条件。接下来 ，就我做了这些题的感悟，主要是给自己做个纪念，也分享下我的见闻。 1 说说我认识的刷题套装编辑器 ： vscode sublime 都行, 不过我偏好IDEA的原因是因为可以写单元测试,这对我复习,调试并验证我的代码正确性很重要。IDEA 也可以调成文本编辑模式， 点击IDEA右下角的帽子图标，取消code auto complete。取消syntax 或者 highlight都行。 250道包含内容：2个top系列为主+外加一些高频题目和自己认为薄弱的题目 2 leetcode外挂插件 ： 目前 有了已经开发了leetcode刷题插件，不需要取网页端浏览，直接编辑器里面浏览，自动生成。https://github.com/shuzijun/leetcode-editor 网页端的一个油猴插件 : 自动切换国区和美区 ， 搜索答案 ， 个人用的还算不错 。 具体功能自己装个油猴插件 ，自己玩玩吧https://greasyfork.org/zh-CN/scr … 3%E5%8A%A9%E6%89%8B 3 推荐参考答案： grandyang的文字解答 和 花花酱的视频 为主。还有 水中的鱼 , LEE215 等个人主观评价：花花酱做的视频基本很精品，覆盖的题目都比较全了，也做了分类。适合小白和一定刷题经验的人。每个视频时长基本控制在20min以内，讲的很好，好在除了 给你解题思路和复杂度简略分析，还会融会贯通，连带在视频内 提示并放出相关类似的题目的YouTube视频链接。花花酱本人的履历 我也算搜过， 看他的解答 很放心！答案的基本版本是 C++一定有。 Python和JAVA 现在也带上了。唯一缺点就是:没有评论区，YouTube视频下面贴代码也不太好。 然后再来说说，grandyang的， 文字描述功底 我认为早期版本可能不太行，后期版本都是不错的。他的文字性题解思路描述 可以 让你在5min内了解这道题目的大致解题思路，不用费心思看你可能认为20min很长会让你睡觉的视频解答。grandyang 尽量都提供一题多解，并在文章末尾附上原题链接和 JAVA C版本的vote数较高的答案。当然，我后说grangdyang，是因为我个人觉得他的部分答案，没讲到关键点子上。。。比如DP类型的 背包问题 ，举个例子 312 burst ballon 区间DP所以， grandyang的答案的缺点是在于， 有些经典题目 可能并没有 帮助你了解这类型问题的本质。最后，这只是我的个人看法，从心里面上来说，我很感谢两位提供这么棒的答案。 LEE215 不错了 ，不过没有思路讲解，吸收的养分比较少。但是代码写的是整洁！其他收费的视频，我直言很垃圾 ，缴纳智商税。。。。走捷径不是不可以，但是那些弯路你最后还是要走，为什么硬要把他们分离开，先走捷径呢？ 4 关于学习材料：除了leetcode还有什么可以看看的？这个问题，比较难回答。我之前也买了刘汝佳的算法竞赛入门经典（第2版） 还有配套答案和训练集。https://book.douban.com/subject/25902102/最后也没仔细去学，不过当做参考书也还是不错的。前期我还去了解了USACO CODEFORCE HDOJ POJ ZOJ TopCoder 等等是干啥的。至于编程之美和微软技术面试心得 剑指offer我没学过 好像有些经典题目就是从这里出的。 这里，我想推荐下 https://oi-wiki.org 这个面向初高中的OIER的网站， 网站发起人目测是THU的。。 这个网站，我获取了什么有用的信息？我从OI的视角，将leetcode题目置于 OI领域，看看主要考察什么。毕竟leetcode一定程度上就代表面试算法题部分的考察项目嘛dp分类 字符串处理 数论 基础的数据结构 位运算的基本和灵活应用，线段树 树状数组 区间DP 树形DP RMQ ST表等了解或理解 另外，就是崔添翼大佬的背包九讲V2，我个人的学习能力停留在第六章，第七章及以后的 听不太懂。。。前面几章相当经典，是培养我DP启蒙的一个小册子。感谢这位大佬 撒花🌸🌸🌸🌸🌸🌸🌸🌸暂时想到的就这些。 5 算法和数据结构学习应该有怎么样的顺序： 我个人犯的错误就是前期刷题质量和效率太低，埋了很多雷。首先 二分查找 左闭右开的lower_bound写法一定要理解 。这是一种思想。而不是简单的查找数值！！排序的话，快排 和快排的切分 默写程度吧，3向快排和归并排序 也要能默写咯 ，其他自己看着办吧 接下来谈谈 栈和队列的运用的基于栈LIFO的数据结构特点，DFS的非递归肯定用栈啦，单调性栈 的运用 这个自己去体会吧。队列的话 FIFO特点， BFS 肯定用得上了 。 BFS问题 比如课程表，接雨水Ⅱ 优先队列 用在哪里 ？ top k系列问题 以及 依赖于优先队列的BFS遍历二叉堆和二叉树 ，高度， 深度 ，叶子结点 ，非叶子节点 ，这个需要理清楚 。二叉树 基本上用递归为主了 。遍历方式：递归，非递归，morris遍历 ， 高度和深度计算 。链表的话 考察的比较少 环检测 翻转链表 必须会吧 ，哑节点dummynode的运用。树状数组 ST表 就是一个二进制倍增思想的运用吧，这个在崔添翼大佬的背包九讲里面有提及，我认为可以不用学，尝试下还行。UF的话 也比较常见，这个还好了，碰到的比较简单，要么连通性判断，要么连通图个数计算。 6 刷题用什么语言： 从功利性角度来看 JAVA C++比较稳了，毕竟leetcode答案 语言版本也是这2种最为常见。Python 答案 代码是少， 代码少并不代表 你就能容易理解这个答案。所以经常leetcode讨论区会有show 几行Python代码 solution 我觉得这并没有提供有效的信息。 7 说说leetcode的tag分类： 我认为唯一一点做的不好的是DP分类dp是一个比较宏大的概念，细分下来有很多种经典的DP，让人印象深刻的股票系列 烧气球 数组切割求最值问题其他tag归类我认为都okay以下内容需要积分高于 50 您已经可以浏览 8 leetcode用国区还是美区？我现在用国区。不过我倾向于还是用美区吧。有点自相矛盾哈哈美区毕竟有高质量的讨论，国区比较少，而且可以训练 英文算法题的 阅读理解嘛2333最近，国区出了一个很弱化的 app。 9 我的做题策略：5-10min不会，直接看答案，看grandyang或者花花酱的。起初，我还不好意思。后来，我发现你看了这道题目确实就会做了，以后碰到，大概率还是会做的，起码有思路，毕竟自己手抄或者理解过感悟：还是自己做的题目少，对题目的嗅觉不太行。力求某个YouTube培训机构讲的 争取做到一题多解和多题一解或者说通用解，通用模版 置于细化的做题策略： 个人经验比较少。基本路子 就是先想想看解题 思路 ，声明 数据结构变量，初始化赋值 （0，-1，+∞，-∞）。招到循环调节或者递归更新条件最后迭代下。。。 至于 担忧15min就放弃思考，以后出新题，你还是可能依旧做不出来？这个嘛，我认为一半对一半，15min以内想不出，就直接看答案，确实没有培养出解题不投降的意志力，但是也有好处，在于见多识广😄。 10 那些依旧恐惧的题目类型： 字符串的 模式匹配， 栈在计算器的复杂应用，数论题目（数论的题目，基本上属于会就是会，不会就是不会，死也想不出来）。DP套DP或者 2个DP的题目 ， 难呐 11 关于边界， cornercase 的敏感度， 我目前不太会想到，还是自己太菜了。数组我应该 base 0 还是 base 1 还有off by one error，这个没多少经验。 循环条件 到底 小于 还是 小于等于 ? 我就是用例证法，举个普通的例子，问题规模1到5个内为宜，去判定条件小于还是小于等于。 12 如何二刷，复习和回顾，这个做leetcode题目之前，就想要写单元测试。assert 自己答案的输入和输出 ，方便我以后快速回忆定位某类行题目的答案。因为leetcode网页版 提交记录里面找自己的答案 不方便。也有人做Excle, 记录自己的解题关键点。 13 理解和记忆：我目前脑子中记忆的就是 二分 快排切分 ，一些BFS，DFS,DP模版，JAVA常用数据结构的API，尽量理解典型类型的思路，做到万变不离其宗吧 2333，14 算法题不是数学题，推导可以，证明我还是放弃了 GG。。。。15 接下去 我要巩固积累，二刷三刷， 学会简要分析时空复杂度，写写自己想出来的test case。写的比较乱，想到哪里写到哪里，尽量写自己之前比较困惑或者纠结的点 ，记录自己的思考和实践。 最后强调一点就是 面试还是面试，做题还是做题。。。 推荐花花酱的，免费的做的还这么好。有机会，一定要支持下，还有grandyang的。~~撒花 🌸🌸🌸🌸🌸🌸~~ 最后，希望有人批判下我的思路感悟 祝愿大家刷题打BOSS 通关。走向人生巅峰哈哈 必知必会：数据结构与算法 Algorithms + Data Structures = Programs, — Niklaus Wirth 目前来说，程序员的面试门槛越来越高，很多一线互联网公司的技术面试，都或多或少会考察数据结构与算法相关的题目，掌握数据结构与算法尤为重要。如果你不想永远做一名“代码搬运工”，那就花点时间一起来学习吧。本项目涵盖数据结构与算法所有知识点，内容将在后续不断更新，欢迎持续关注项目最新动态。 数据结构与算法概述线性结构与非线性结构 线性结构 非线性结构 稀疏数据和队列稀疏数组 看一个实际的需求 基本介绍 应用实例 队列 队列的一个使用场景 队列介绍 数组模拟队列的思路 数组模拟环形队列 链表链表介绍单链表应用实例单链表大厂面试题双向链表应用实例单向环形链表应用场景单向环形链表介绍约瑟夫问题栈栈的一个实际需求栈的介绍栈的应用场景栈的快速入门栈实现综合计算器逆波兰计算器中缀表达式转换为后缀表达式递归递归与递归调用机制递归-迷宫问题递归-八皇后问题（回溯算法）排序算法排序算法介绍算法的时空复杂度冒泡排序选择排序插入排序希尔排序快速排序归并排序基数排序常用排序算法对比总结查找算法线性查找算法二分查找算法插值查找算法斐波那契（黄金分割法）查找算法哈希表哈希表的基本介绍Google 公司的一个上机题树结构二叉树 为什么需求树这种数据结构 二叉树遍历：前序、中序、后续 二叉树查找与删除 顺序存储二叉树 顺序存储二叉树的概念 顺序存储二叉树的遍历 顺序存储二叉树应用实例 线索化二叉树 先看一个问题 线索二叉树基本介绍 线索二叉树应用案例 遍历线索化二叉树 树结构应用堆排序赫夫曼树赫夫曼编码 数据压缩与解压 文件压缩与解压 二叉排序树平衡二叉树（AVL 树） 左旋 右旋 双旋转 多路查找树二叉树与 B 树树B 树、B+ 树和 B* 树图图基本介绍图的表示方式图的深度优先遍历图的广度优先遍历图的深度优先 VS 广度优先10 大常用算法二分查找算法（非递归）分治算法动态规划算法KMP 算法贪心算法普里姆算法克鲁斯卡尔算法迪杰斯特拉算法弗洛伊德算法马踏棋盘算法入門資料 UCB的神课 CS61B，CS61B这个课属于进阶版的java基础班（和CS61A是一个系列的，61A会讲一些基本JAVA的语法），主要讲数据结构，不过这课load还是很重的，作业和Pj都是精挑细选，经过岁月打磨出来的精品。 Solutions CS61B 2019 CS61B CS 61B一畝三分地討論交流 台灣目錄：演算法與資料結構 Cornell CS2110 UQER量化交易 簡單的演算法筆記 – 第一集 大佬們的刷題日記和講解关关刷题日记 https://blog.csdn.net/scarlett_guan/article/list/1?t=1&amp; Lucky貓的 UVA（ACM）園地 花花酱 leetcode刷题日记 有youtube视频 算法导论 第15章 动态规划 小旭讲解 LeetCode 53. Maximum Subarray 分治策略 參考資料和書籍📚《算法之美——隐匿在数据结构背后的语言》，全文目录、“45个算法”目录、“22个经典问题目录”。记录学习代码实现，参考：http://www.cnblogs.com/ranjiewen/p/6082573.html 這裡是刷題倉庫和相關資料[工作信息] 刷题经验贴 CPE TAIWAN Certificate UVA OJ UVa submit code的实况 相關活動交大算法冬令营 blog123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117真的畢業了! 找到適當的BLOG可以寫東西啦~~~就是GOOGLE的BLOGGER!有好多Plugin可以用、template可以自己設定, 在沒有網頁空間下, 覺得這蠻不錯的.此篇是參考NPSC補完計畫，結合其內容與我的種種解題的學習過程與方法～身邊的同學或學弟妹常會問如何學程式、提高程式設計能力或者如何解題。 我不是像中央MORRIS、清大楊易霖、台大以及其他各種怪物等國手，但是在這多年來解題的過程有許多說不完的心得與想法，在此分享給想挑戰程式設計比賽的人，當作一個學習途徑的參考。 以下內容是以程式解題方向為主的學習過程與方法，無法涵蓋所有程式設計的學習方法，但我想共通點是一樣的。1. 先熟練C/C++或JAVA基本語法： 找一本你覺得看起來最舒服的書，不要說去找什麼很有名的聖經本之類的，除非底子已經很好，可以再來研讀有深度的書。最最最最最基本的是需要以下（很重要所以強調）：懂標準輸入輸出、變數宣告、if-else、switch、while(do-while)、for等流程控制語法、陣列、字串、struct的使用（C/C++）、class的使用(JAVA、c++）以及簡單的排序法。進階一點就再學自定函數、遞迴函數等，這階段主要是學習程式的語法，讓你的想法可以很快地化成程式碼，不用馬上說想寫很困難的程式。2.進入線上程式解題系統練習學程式絕對不只是要用"看"的就能學會，學程式絕對不只是要用"看"的就能學會，學程式絕對不只是要用"看"的就能學會，學程式絕對不只是要用"看"的就能學會，學程式絕對不只是要用"看"的就能學會，（很重要所以我寫五行） 有些重要課程只有講理論而沒實際操刀寫程式，實在是無法深刻了解其中的奧妙而無法成長，特別是遇到需要 debug 的技巧是書上不會教的！因為沒有人會有那個耐心幫你檢查所有的程式是不是有 bug，所以找一個可以自動 Judge 的系統是很重要的～新手的話，推薦兩個平台第一個：「高中生程式解題系統」http://zerojudge.tw/ 歷史非常悠久的台灣中文解題系統，是由高雄師範大學經營，裡面的題庫大都是中文，也是高中職學生常用的解題訓練平台，許多TOI、IOI國手大都在這起步。可惜題目並沒有做難易度分類，即使在基礎題庫的題目也有很難的，需要有人指導會比較清楚。第二個：「ITSA的E-TUTOR」http://e-tutor.itsa.org.tw/e-Tutor/ 近年來新的中文解題系統，網站上有中英文的題目，每種題目又有分各類型的題目，更是有做難易度的區隔，讓學解題的使用者有個清楚的方向。可惜這平台缺點是常有題目的敘述不完整，比如輸入測資的範圍沒說明等，會給使用者額外的困擾。3.開始學習資料結構、演算法 基本題解到一個程度，會發現學的東西不夠用，這時候就要進入下一個階段,開始學習資料結構和演算法了。 這部分一樣是去書店找一本你看得順眼的書,以我個人而言，在資料結構的部分，除了有原文聖經本Ellis Horowitz寫的Fundamentals of Data Structures in C(或C++)我有另外買蔡明志的「資料結構--使用C++(也有C++、JAVA版)」另外有網友推薦胡昭民的「圖解資料結構」選一本即可，主要是看懂資料結構的觀念,書裡程式碼希望是能研讀，最好是實作。而有些樹的章節裡面, 只要看到二元樹(包括二元搜尋樹、Heap)就夠了,後面AVL-Tree、2-3-4 Tree、B-Tree等可以不用看，基本上解題不會用到。 演算法的書, 之前我上課原文書是用 Anany V. Levitin寫的Introduction to the Design &amp; Analysis of Algorithms，而中文書推薦蔡宗翰的「演算法：使用C++虛擬碼」，這本的內容讓我學到很多。解題的程式最常會用的演算法包含各個擊破法 （Divide-and-Conquer）、動態規劃(Dynamic Programming)、貪婪演算法(Greedy)、回溯(Backtracking)、分支界限法(Branch-and-Bound)等，有時解題遇到的問題可以用很多種演算法解。資料結構與演算法的書讀完後，還不足的可以到「演算法筆記」挖資料http://www.csie.ntnu.edu.tw/~u91029/這網站陪我好幾年，也有我幫站長debug文章的痕跡，可惜現在終止營運，有點可惜～演算法聖經本是MIT教授Cormen寫的Introduction to Algorithms，以台清交成資訊工程學生以及國手，幾乎都看這本學起，書的內容講的很完整，說是聖經本不為過，真的要讀可以啃這本，但不建議讀中文翻譯本，翻譯的很爛。4.使用進階的線上程式解題系統 第二段提到高中生程式解題系統(ZeroJudge)、E-TUTOR雖然裡面部分題目比較簡單，可以很容易建立自信心、學習基本解題方法。但到達某一程度後，有些題目會很難、甚至學習成長的幫助不大，此時可以改到其他網站練習。 首先最推薦的就是最多人用過， 俗稱 ACM 的 UVa Online Judge,http://uva.onlinejudge.org/而「Lucky貓的ACM園地」有提供一些題目的中譯還有難易度分級,http://luckycat.kshs.kh.edu.tw/可以搭配使用。當然是希望能看原文直接解題是最好，畢竟國際解題全都是用英文出題。 第 二個是Uhunt，這不是新的解題系統，而是UVa的實況系統，是由新加坡大學的解題團隊所建立的網站，提供現在全世界有哪些人在解題、解題狀況如何、排 名如何、程式執行時間多長，對我而言是個很刺激的網站，且長久下來會看見一些很奇怪的熟ID。而uhunt上中間有一個Competitive Programming Exercises，是新加坡解題團隊所分類的題目，有分好題目類型與難易度，也是提供使用者很完整的解題方向。5. 進階解題書籍 前面提的資料結構與演算法書籍，只是＂基礎知識＂而已，有時學完後還是無法對某些題目想出方法，此時推薦幾本書籍。第一是劉汝佳撰寫的「算法竞赛入门经典」跟「算法竞赛入门经典——训练指南」， 在台灣去年有代理出繁體版，名稱分別為《提升程式設計的邏輯思考力─國際程式設計競賽之演算法原理、題型、解題技巧與重點解析》與《提升程式設計的解題思 考力─國際演算法程式設計競賽訓練指南》。這兩本書而言，初學者先讀「算法竞赛入门经典」，讀完後再來讀「算法竞赛入门经典——训练指南」。書的內容就是 專門講解如何將基本的資料結構與演算法知識來解決程式解題的題目。以Uva而言，題目是變化多端，有些題目若沒有人指導確實很難自己想出來，而這些書提供 很多整合資料結構與演算法的概念，提升解題者的思路。另外一題，劉汝佳起初是中國的解題國手，現任中國專業解題教練與ACM-ICPC命題委員，中國資訊學生幾乎都聽過他名字。他寫了這些書更是帶動中國的解題氣氛，每年上海交通大學幾乎都會進到ACM-ICPC決賽的前幾名，真的是很恐怖。第二本是日本國手寫的プログラミングコンテストチャレンジブック，台灣也有代理成翻譯書，叫做《培養與鍛鍊程式設計的邏輯腦：世界級程式設計大賽的知識、心得與解題分享》，也是跟劉汝佳寫得差不多，只是這本書是拿POJ跟GCJ的題目來講解。6. 學海無涯 以解題而言，初學者最容易犯的錯，以為只看書就懂什麼叫做資料結構或演算法，甚至只挑簡單題來做，這樣是永遠不會成長。以我個人而言，大學的資料結構與演算 法都是有寫程式作業，且佔總成績很重，不寫好就是等著被當掉，因此有很多時間花在學好資料結構與演算法的理論與程式設計。從大二開始就跟著學長姐進入解題 比賽這一條不歸路（？），起初真的如同前面提到，即使課程學過資料結構與演算法的基礎知識，卻還是不會轉換成解題的方法，意思就是解題寫太少，且又碰得太 簡單，才沒有進步。之後到了大三，大概也才解了一百多題Uva題目，但覺得學的還是少。直到轉學至長榮，突然有個發神經的動力，開始瘋狂解題，真正體會到 資料結構與演算法的實作能力與奧妙之處，短短一年多解了４百題，這趟過程雖然辛苦，但是卻非常值得！ 從以前去中山、成大的全國大專程式競 賽、南區程式競賽等比賽，常常看見很熟悉的成大選手臉孔，直到現在遇到的同一輩與新一代的強選手，這趟比賽過程值得回憶。最後今年的ITSA桂冠賽仍沒獲 獎，但也還是值得了，至少跟成大同解數還蠻高興(?)。而CPE(大學程式能力檢定)在上禮拜二拿下A+的成績，也是了無遺憾！ 希望這篇文章有能幫助到有共同志趣在解題上的人，更希望能帶動程式解題氣氛，解題只有好處沒壞處，也如演算法筆記所述，解題能學到以下這五種能力： 一、智力思考：藉由智力測驗問題、益智遊戲（如數獨、孔明棋、倉庫番）、數學科普書等等，可以活絡大腦思路，培養觀察問題與分析問題的能力。 二、數學：從學校教科書可以學到很多數學概念、數學方法、甚至是數學公式，套用在問題上面來解決問題。 三、計算學：從學校教科書和網路上的資源，可以學到很多計算方法，套用在問題上面來解決問題。 四、程式語言：從程式語言的書籍（ C++ Primer 、 Effective C++ 、程式設計師的自我修養）、計算機概論等書中學習。 五、程式設計：從 open source 與其他人寫的程式碼中學習一些寫程式的原則以及漂亮的寫法。所以，解題Z&gt;B是百分百正確的!7. 疑問 也有人會問，做解題那麼多對實際撰寫專題（系統）有用嗎？這要回答「部分有用」，畢竟一個系統就是要解決一大堆問題集合的工程方法，而解題只有解一部分小問 題。但是學過演算法會知道，要想辦法把問題切成子問題來解決，做系統也一樣，每一個系統可以切成各種功能的子系統，每一子系統是針對特定問題作解決的方 案。因此一個子系統的功能完整，正是一個（數個）程式的執行能力，而程式又如一位Niklaus Wirth大師所說：「程式 ＝ 演算法＋資料結構」。好得程式可以整合出一個好的系統，這是我個人對系統實作的觀念，所以解題學的好，仍然對做系統有幫 助。只是有些是解題學不到的，比如如何使用API來做完成一個子系統的功能，必須要有閱讀文件的能力，解題上沒有閱讀文件的學習方法。-------- 2014/6/16補充--------- 這陣子接觸到2048 bot大賽，在這過程學到何謂對抗搜尋的branch-and-bound演算法，包含minimax、alpha-beta prune、expectimax、negascout等方法。目前ACM題目的解題我還沒遇到剪枝的題目，藉由這2048比賽的機會，學到了剪枝的精神！只是國內研究單位太強了，交大的居然能十幾%的16384 Tile....超好奇他們演算法能快狠準到此成績。 123456789101112131415161718191. 澄清问题(clarification) 重复问题，把白板分成三部分，第一部分列出所有的条件：输入输出是什么(类型，pattern)，数据大小等；第二部分用来做演算，第三部分用来写代码。2. 开始在白板第二部分研究面试官给你的例子，为面试官分析问题，比如要解决这个问题，我们需要解决哪些子问题，然后看能否得到一个brute force的解，这里就是检查所有的pair，O(n^2)的复杂度。3. 面试官肯定会叫你优化，这时你就要积极思考，同时说出你在想什么，比如可不可以不用检查pair，找每个数和target number的差值是否已经存在，这样只需要遍历一遍就行了呀，为了更快检查出来差值是否存在，可以用哈希表实现最好情况O(1)的查询速度。4. 面试官表示他认可你，这个时候你要总结一下你的解题步骤1,2,3，然后在每一个步骤下，书写对应的代码，中间不需要说太多话，每一个block写之前交代一下，写完后总结一下就行，每完成一个要求，在白板第一部分对应的地方打钩。5. 可以使用不同颜色的笔，标注不同的部分。6. 写完以后，跑几个有代表性的test case，时空复杂度分析。7. 整个过程中，注意好变量和函数的命名，少用全局变量，大的函数一定要拆分成若干子函数，分别负责不同的任务，这样代码可读性高，修改起来也非常方便，比如说面试官说你A函数里有个bug，你可以迅速定位到A函数的位置。大家可以搜索一些关于good coding practice的文章。实际碰到的题目可能不会这么简单，你的思路可能会卡住，不要慌。面试官想要看到的就是你的思考过程，你需要做的就是告诉面试官你的方向，你卡住的地方在哪里，而不是自己闷头想。你这么做释放了一个积极的沟通信号，那么面试官自然也会给你积极的回应。此外，如果面试官打断了你，问你what about doing something in this way....这很可能是一个提示告诉你的方法不对。请你一定，一定，一定按照面试官说的做！即便你觉得你的方法马上就要做出来了。要知道算法题就好比走迷宫，你用你的方法发现出口好像就在眼前，这个时候，面试官提醒你尝试另一种方案，而你需要往回走很多步。很多人这个时候根本就听不进面试官的话，觉得自己的方法肯定行，殊不知面试官知道整个迷宫是什么样的，而你看似正确的那条路，很可能最终是一条死路。如果你一意孤行，你的feedback绝对是不好的。]]></content>
      <categories>
        <category>Foundation</category>
      </categories>
      <tags>
        <tag>Algorithms</tag>
        <tag>Foundation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Application]]></title>
    <url>%2F2019%2F04%2F19%2FApplication%2F</url>
    <content type="text"><![CDATA[2019 Fall MS CS 中低GPA選校ADMISSION UT AUSTINhttps://www.1point3acres.com/bbs/thread-566249-1-1.html如何写好一篇推荐信的初稿 RoolingMS in CS@university of ChicagoMS in CS@BrownMS in CS@University of RochesterCS@Brandeis CONVERT GradE UCI CONVERT GUIDE LINE ASIAN Prof Guide After abroad THE MISTAKE WHEN U APPLY FOR U 選校定位經驗帖https://zhuanlan.zhihu.com/p/83669147美国学校排名 YOCKET Indian Application Recommend [申请总结] 19fall cs phd 退学重申/背景提升/选校策略/科研相关 定位 华五| SE | 中** | 大厂做Spark 3年 | 全聚德 求建议 School INFO Northwestern University CE/CS整体介绍&amp;不完全课程介绍（NWU, NU, 西北） 定位California &gt; Big Seattle &gt; Texas &gt; Boston 11: Dartmouth UCI NEU Tandon PennState Tufts UCD UMT UVA UCR NWU 5 NCSU UTD ASU UCSC UCR 彩票: CMU SV-SE, UCSD CS, Rice MCS (Stanford UCLA UCB cornell )3+4冲刺: UCSD ECE, Columbia CS, UMich CS, Tandon CS, Dartmouth Gatech CSE 6主申: USC CS28, NEU CS PennState ucdavis UvA umass sbu uci mcs UMT utah9保底: NEU CS-align syrauce ASU NCSU UCSC(utd osu)6+2 nwu 冲刺：MSE @CMU；MCS @UCSD；MCS @Rice；MSE @University of Michigan，Ann Arbor；MCS @USC主申：MCS @UCI；MCS @UCR；MCS @UW；MCS @NYU；MCS @NEU保底：MCS @Boston University；MCS @Syracuse；MCS @GWU https://www.mccormick.northwestern.edu/artificial-intelligence/admissions/ nwu msai POOL彩票(3)： CMU SV-SE EECS Meng UCB Stanford 冲刺(3) UCSD MSCS USC 28 Cornell CS Meng 主申(8)： Rice MCS中國人多，轉業友善，申請難度較低（猜是top 20最好上的）。收大概80–100個，女生據說FB全給實習面試。我丟MCS有上，MS是給念PhD的中途發的學位 UCI MCS/SE NYU MSCS我是说Tandon/NYU Computing, Entrepreneurship and Innovation NEU MSCSDoes have the Campus of SV Dartmouth MSCS Penn state UCD MCS 保底(7)： UvA UCSC MSCS ASU MSCS NCSU MCS UT Dellas UCR MCS/SE Rochester MSCS Career[找工就业] [工作信息] 30+公司 MLE 面试准备经验分享，已有Uber, DiDi, 蚂蚁Offer]]></content>
      <categories>
        <category>Application</category>
      </categories>
      <tags>
        <tag>Application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TOEFL]]></title>
    <url>%2F2019%2F04%2F19%2FTOEFL%2F</url>
    <content type="text"><![CDATA[不要加入自己的观点！！！托福是为了测试你的语言水平，而非GRE测试你的逻辑能力。 托福的难度大概相当于小学五年级学生的科普难度 托福大多数题材与纪律片相近，推荐科学美国人，以及The Story of US 等各种纪律片（虽然生物类看起来有一点无聊） 2019年暑假新东方资料 TOEFL考試資料庫 (新進同學請優先看) Listening ESL_Lab托福听力在线练习 Ted-ED 12345678910111213141516知道定位，记忆重点单词，精听TPO.Step 1: 直接把一篇听力题目做完，但是做完不要对答案。Step 2：阅读听力原文，划出其中的逻辑词。Step 3：对照题目，在原文中找到出题点的位置。（这一步你会发现大多数出题点都在逻辑词后面。）Step 4：题目选项分析，即找到了出题点之后再去仔细分析每一个选项，重新做每道题目(记得这时你还没有对答案）事实上这一步相当于在做阅读理解，在这一步中，如果你发现哪道题的答案和之前纯听的时候不一样，可以分析一下为什么不一样（多半是有地方没听明白，或者信息理解错位了）。Step 5：对答案，看看纯听的时候和做阅读理解时各自错了多少，仔细分析错题的原因。Step 6 : 仔细阅读听力原文，保证将其理解透彻（没有生词，没有读不懂的句子）Step 7：跟读，逐句模仿发音，然后整段跟读，直到脱稿。Step 8：精听原文，重点关注逻辑节点以及考点处的内容，反复听，直到完全吃透为止。托福每篇听力长3~6分钟，这样一套流程下来，每篇大概耗时45~60分钟。每天挑出整块的三个小时，练上那么3~4篇，半个月能练接近50篇，这样短期大密度的训练，才会有立杆见影的效果。有的筒子啊，隔天练那么一两篇，这是休闲..不是训练。 说总结自己的模版 黄金口语80题 7个你不能不知道的“英语连读”规则 口语网站 Reading定位 词汇：选意思相近的，不会再去套语境，利用词性来排除句子简化： 简化句子总结（六选三） ： 说的多是选项，太细节的一般不选推断题：从他的反面和正面来推断插入题：看语境，看连接处 类似As example, But, For some reason. ScienceDaily 写总结自己的模版你同意大学应该开什么课吗 独立写作 Do you agree or disagree with the following statement: Universities should require every graduation students to take public speaking courses. Give specific examples and details to support your answer. Sample Answer: As we all know, course settings of universities have always been a focal point of the public attention. Recently, it has become a hotly-debated question that whether or not college students should take compulsory public speaking classes. (背景引入)Some people argue that delivering speech in public can help a student develop an open personality filled with courage. So it is necessary for university students to take this course. (他人观点) However, in my opinion, turning public speaking course into a compulsory one can be a terrible decision. (我的观点)My view point is based on the following reasons and examples. (过渡句) To begin with, public speaking, as a kind of skill, is actually needed only in certain occupations. (分论点一)A politician or an entertainer may sometimes need to present himself facing a crowd of people, while other people such as engineers and programmers would have no opportunity to use this skill during his career life. (展开句)For example, one of my schoolmates who is now working in a mobile game company once shared his life with us during our meeting. He needs to spend almost all his working time facing his computer, coding and thinking. With such a heavy workload, only little time was left for him to social with his colleagues and friends. It is obvious that learning how to give an excellent speech in public is useless for him. Therefore, we can see that public speaking isn’t an essential skill needed by people who are responsible for certain kinds of jobs. (具体细节例证) Moreover, requiring students to take public speaking courses doesn’t mean they can successfully get this skill when the class is over. (分论点二)It is universally acknowledged that different individual owns different personality. Some people are naturally open and willing to give their opinion in public. In contrast, others may be shy and inclined to share their thoughts only to a small group of people. (展开句)When I was still a college student, I took part in a club which gathered a group of young people interested in psychology. Some club members were outgoing and good at social. Due to their nature, jobs related with broadcasting and external connection were usually assigned to them. In the club, there were also some students with introvertive personality. They were responsible for some rigorous tasks such as accounting and some strict paperwork. Both groups performed well. If we hand accounting jobs to the outgoing group or force the quiet group social, the operation of our club might turn into a mess. Similarly, if those people who are not open enough are forced to take public speaking course, it might just be a waste of time. (具体细节例证) Admittedly, public speaking course can help develop a personality which is required to be a leader. (承认反面观点有理)It is necessary for a leader to deliver a speech full of emotion and appeal to his team members. (展开)Take Jack Ma, the boss of Alibaba, as an example. We all know that Jack Ma established Alibaba, an e-commerce company when he was in obscure. At that time, he was a college English teacher and usually gave lectures in a class in front of hundreds of adult students. Adequate public teaching experience equipped him with a charming and attractive personality, which might contribute a lot as he recruiting people to set up his e-business. Most people didn’t held an optimistic attitude towards e-commerce, so I regarded the leadership of Jack Ma himself as a significant factor resulting in the success of their initial team building. (具体细节例证) To conclude, public speaking course is not a necessary one during students’ college years. (重述总论点)Not every students actually need this skill. In addition, not all the pupils can become a successful public speaker after such kind of training. (重述第一二个分论点)Nevertheless, for students who have the ambition to be a leader in his future, taking public speaking course can effectively help him to get an attractive figure.(重述让步段论点)李笑来的范文 托福寫作心得 TypeRacer (Writting 練打字速度用) XX XX 首段 表明你的观点(oﾟvﾟ)ノ 第二段 让步，说此观点还是有一定的合理性 第三段 单反例1（同样好或者更好） 第四段 单反例2（同样好或者更好） 尾端 总结 Vocabulary Barron’s 800 High-Frequency GRE Word List Course 考满分 Learn English FREE with USA Learns https://www.engvid.com/ 托福经常考到的几个点：12345678生物： 猛犸象 冰川，迁徙MIGRATION 还有ALLURE PREY USING BAIT BY PREDATOR。天文：尤其是木星和它最常被提到的三颗卫星，IO,历史：一般为美英和罗马历史。beaver和bison在美国历史上举足轻重的影响。anthropology考古：一般会说什么什么证明什么什么，然后教授又给出相反观点。常见口语和写作，还有苏美尔人发明文字。]]></content>
      <categories>
        <category>Application</category>
      </categories>
      <tags>
        <tag>Application</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mind Map In Java Environmentals]]></title>
    <url>%2F2019%2F03%2F31%2FMind-Map-In-Java-Environmentals%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[107_FALL]]></title>
    <url>%2F2019%2F03%2F22%2F107_FALL%2F</url>
    <content type="text"><![CDATA[TAIWAN TECH 107 FALL107 Transcripts GPA Calculator MOVIE LIST 關於HEXO超全的建站內容 Learn Git Branching Online 【录取数据-CS】卡耐基梅隆大学 CMU Computer Sciences Master计算机科学硕士（2018Fall)](https://www.douban.com/note/670723222/)利用Github分支备份Hexo源文件 Thinking In Java NCTU_CSIE_HANDBOOK Taiwan Tech HANDBOOK DATA STRUCTURE AND Algorithms https://regapp.nctu.edu.tw/Views/User/UserLogin交通大學線上提交申請文件 115家电子科技企业待遇 BurnDown chart CS2006301 計算機組織 Computer OrganizationMidterm 4.16Homework2 4.9PRACTICEKOREAN SOLUTIONHANDBOOKTAIWAN_TECH HANDBOOKCONVERT THE FLOAT NUMBER CS3001301 AlgorithmsMidterm 4.16Project2 4.10KOREAN ALGORITHMS HANDBOOK算法导论笔记动态规划DP详解-钢条切割的分析与实现 CS3007701 多媒體資訊系統導論 Introduction to MultimediaInformation SystemsMidterm 4.11HANDBOOKHistogram Equalization Histogram CDF PDF CS3010301 資料庫系統 Database SystemsCourse website5/28 Final will be held on 6/11 in class.5/14 Homework 4 posted4/30 Prof. Ming-Chih Hung of Northwest Missouri State University will give a talk titled “GIS, Graphs, and Relational Database” on 5/21 in class.4/26 Homework 3 posted.3/28 Mid-term will be held on 4/23 in class.3/28 Homework 2 posted.3/21 Homework 1 posted.2/19 First class CS3020301 Compiler DesignCourse websiteRegular OR NOT PKU印度🇮🇳 Neso Academy CS499A001 實務專題(上) Special Projects (I) CS5144701 深度學習實務 Practices of Deep Learning BA2911701 談判學 Negotiation CC1309301 經典與創意 Classics and Creativity PE139B053 體育(重量訓練)(下) Physical Education(Weight Training) (II) TCG029301 臨終關懷社區實習 Practical Training in Community for Hospice and Palliative CareMidterm report 5/1 本人對於台灣地區社區長照2.0計劃的看法和迷思 TCG047301 養生醫學 Fitness and Health for Good Life TCG068301 領導與生活 Leadership and LifeFinal 6/17Assignment2 5/20Group meeting 4/22Assignment1 4/1]]></content>
      <categories>
        <category>Diary</category>
      </categories>
      <tags>
        <tag>Taiwan</tag>
        <tag>Taiwan Tech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Core Java Volume I(10th Edition)]]></title>
    <url>%2F2019%2F02%2F10%2FCore-Java-Volume-I-10th-Edition%2F</url>
    <content type="text"><![CDATA[JAVA核心技术卷一 (第十版)下面是需要注意的： 只有方法名和参数类型叫做方法的签名， 不同的返回类型值不能作为方法的签名。(4.6.1) 这是域与局部变量的主要不同点。 必须明确地初始化方法中的局部变量。 但是，如果没有初始化类中的域， 将会被自动初始化为默认值（0、 false 或 null )。(4.6.2) 初始化块或静态的初始化块在创建对象的时候执行里面的代码。(4.6.7) 从编译器的角度来看， 嵌套的包之间没有任何关系。(4.7)例如：java.util 包与java.util.jar 包毫无关系。每一个都拥有独立的类集合。import java.util.* 语句不能导入java.util.jar包中的类. 标记为 public 的部分可以被任意的类使用；标记为 private 的部分只能被定义它们的类使用。如果没有指定 public 或 private, 这 个 部分（类、方法或变量）可以被同一个包中的所有方法访问。 使用super 调用构造器的语句必须是子类构造器的第一条语句。(5.1.3) 在覆盖一个方法的时候，子类方法不能低于超类方法的可见性。（5.1.6） 如果将一个类声明为 final， 只有其中的方法自动地成为 final, 而不包括域。(5.1.7) 如果方法很简短、 被频繁调用且没有真()正地被覆盖， 那么即时编译器就会将这个方法进行内联处理。(5.1.7) 将一个子类的引用赋给一个超类变量， 编译器是允许的。但将一个超类的引用赋给一个子类变量， 必须进行类型转换 。(5.1.8) 对本包和所有子类可见 —- protected。(5.1.10) instanceof通过返回一个布尔值来指出，这个对象是否是这个特定类或者是它的子类的一个实例。 Object类中的equals方法将判断两个对象是否具有相同的引用。但是对于大多数类来说并没有意义。(5.2.1) 数组继承了 object 类的 toString 方法，数组类型将按照旧的格式打印，生成字符串“ [I@la46e30” ，修正的方式是调用静态方法 Arrays.toString ArrayList 如果已经清楚或能够估计出数组可能存储的元素数量， 就可以在填充数组之前调ensureCapacity方法： 对象包装器类是不可变的，对象包装器类还是 final ,装箱和拆箱是编译器认可的。 允许将一个数组传递给可变参数方法的最后一个参数。main方法 javap是 Java class文件分解器，可以反编译（即对javac编译的文件进行反编译），也可以查看java编译器生成的字节码。用于分解class文件。 javap -p &lt;类文件&gt; Class类中的newlnstance( )调用默认的构造器，如果这个类没有默认的构造器， 就会抛出一个异常，如果想要提供参数，可以是使用Constructor中名字相同的的方法。 一个 Class 对象实际上表示的是一个类型， 而这个类型未必一定是一种类。 lambda 表达式中捕获的变量必须实际上是最终变量 lambda 表达式的体与嵌套块有相同的作用域。 强烈建议解耦合 try/catch 和 try/finally 语句块 Java 语 言 规 范 将 派 生 于 Error 类 或 RuntimeException 类的所有异常称为非受查( unchecked ) 异常， 所有其他的异常称为受查（checked) 异常。 for each 循环可以与任何实现了 Iterable 接口的对象一起工作, 但是Collection 接口扩展了 Iterable 接口。 四种循环 12345671. arrayList.iterator().forEachRemaining(System.out::println); 2. arrayList.forEach(System.out::println); 3. for (String str : arrayList) System.out.println(str); 4. Iterator it = arrayList.iterator(); while(it.hasNext()) System.out.println(it.next()); 标记接口 RandomAccess 用它来测试一个特定的集合是否支持高效的随机访问 在ArrayList的无参构造函数上的注释 Constructs an empty list with an initial capacity of ten. 初始化的时候并没有真正的创建10个空间，这是惰性初始模式对象，在这篇.和这篇文章中可以一探究竟。 内部类的对象有一个隐式引用， 它引用了实例化该内部对象的外围类对象。通过这个指针， 可以访问外围类对象的全部状态，但是static内部类并没有。 局部类还有一个优点。它们不仅能够访问包含它们的外部类， 还可以访问局部变量。不过， 那些局部变量必须事实上为 final 双括号初始化 一个方法不能修改一个基本数据类型的参数 一个方法可以改变一个对象参数的状态 一个方法不能让对象参数引用一个新的对象 add 方法只依赖于迭代器的位置， 而 remove 方法依赖于迭代器的状态。 Vector 类的所有方法都是同步的，synchronized 如果 a_equals(b) 为 true, a 与 b 必须具有相同的散列码。 作者： NeverTh出处：https://www.cnblogs.com/neverth/p/11760936.html]]></content>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
</search>
